import streamlit as st
import pandas as pd
import numpy as np
import io
import base64
import plotly.express as px
import plotly.graph_objects as go
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from scipy import stats
from eda import EDA

# OICT barevn치 paleta
OICT_COLORS = {
    'purple': '#574494',
    'yellow': '#FFE14F',
    'orange': '#E37222',
    'green': '#74ECA1',
    'black': '#000000',
    'white': '#FFFFFF'
}

OICT_PALETTE = [OICT_COLORS['purple'], OICT_COLORS['yellow'], OICT_COLORS['orange'], OICT_COLORS['green']]

def aplikuj_oict_styl():
    """Aplikuje vlastn칤 OICT stylov치n칤 na Streamlit aplikaci - modern칤 a v칳razn캩j코칤 verze"""
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    :root {
        --primary-color: #574494;
        --primary-dark: #463677;
        --primary-light: #6854a8;
        --secondary-color: #323232;
        --accent-yellow: #FFE14F;
        --accent-orange: #E37222;
        --accent-green: #74ECA1;
        --background-color: #f8f9fa;
        --card-color: #ffffff;
        --text-color: #333333;
        --text-light: #666666;
        --transition: all 0.3s ease;
    }
    
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }
    
    .main {
        background-color: var(--background-color);
        background-image: 
            linear-gradient(120deg, rgba(87, 68, 148, 0.03) 0%, rgba(255, 255, 255, 0) 100%),
            radial-gradient(circle at 90% 10%, rgba(231, 114, 34, 0.02) 0%, rgba(255, 255, 255, 0) 70%),
            radial-gradient(circle at 10% 90%, rgba(116, 236, 161, 0.02) 0%, rgba(255, 255, 255, 0) 70%);
        background-attachment: fixed;
    }
    
    /* Header styling */
    .title-container {
        text-align: center;
        padding: 2rem 0;
        margin-bottom: 2.5rem;
        position: relative;
        overflow: hidden;
    }
    
    .title-container::after {
        content: "";
        position: absolute;
        bottom: 0;
        left: 10%;
        width: 80%;
        height: 2px;
        background: linear-gradient(90deg, 
            rgba(87, 68, 148, 0), 
            rgba(87, 68, 148, 1) 20%, 
            rgba(87, 68, 148, 1) 80%, 
            rgba(87, 68, 148, 0) 100%);
    }
    
    .title-container h1 {
        color: var(--primary-color);
        font-size: 3rem;
        font-weight: 800;
        margin-bottom: 0.5rem;
        letter-spacing: -0.03em;
        transform: scale(1);
        transition: var(--transition);
    }
    
    .title-container h1:hover {
        transform: scale(1.02);
    }
    
    .subtitle {
        color: var(--text-light);
        font-size: 1.3rem;
        font-weight: 400;
        margin-top: 0;
        opacity: 0.9;
    }
    
    /* Logo styling */
    .logo-container {
        display: inline-block;
        background-color: var(--primary-color);
        color: white;
        padding: 0.5rem 1.2rem;
        border-radius: 6px;
        font-weight: bold;
        font-size: 2rem;
        margin-bottom: 1.2rem;
        box-shadow: 0 6px 20px rgba(87, 68, 148, 0.2);
        transform: perspective(400px) rotateX(0deg);
        transition: var(--transition);
    }
    
    .logo-container:hover {
        transform: perspective(400px) rotateX(5deg);
        box-shadow: 0 10px 25px rgba(87, 68, 148, 0.3);
    }
    
    /* Card styling */
    .card {
        background-color: white;
        border-radius: 16px;
        padding: 1.8rem;
        margin-bottom: 1.5rem;
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.07);
        transition: var(--transition);
        border-top: 5px solid transparent;
    }
    
    .card:hover {
        box-shadow: 0 12px 30px rgba(0, 0, 0, 0.1);
        transform: translateY(-3px);
    }
    
    .card.primary {
        border-top-color: var(--primary-color);
    }
    
    .card.yellow {
        border-top-color: var(--accent-yellow);
    }
    
    .card.orange {
        border-top-color: var(--accent-orange);
    }
    
    .card.green {
        border-top-color: var(--accent-green);
    }
    
    /* Metric cards styling */
    .metric-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
        gap: 1rem;
        margin-bottom: 1.5rem;
    }
    
    .metric-card {
        flex: 1;
        min-width: 130px;
        background-color: white;
        border-radius: 12px;
        padding: 1.5rem;
        text-align: center;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);
        transition: var(--transition);
        position: relative;
        overflow: hidden;
    }
    
    .metric-card::before {
        content: "";
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 4px;
        background: linear-gradient(90deg, 
            var(--primary-color),
            var(--accent-yellow),
            var(--accent-orange),
            var(--accent-green));
        transform: translateX(-100%);
        transition: var(--transition);
    }
    
    .metric-card:hover {
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.1);
        transform: translateY(-2px);
    }
    
    .metric-card:hover::before {
        transform: translateX(0);
    }
    
    .metric-title {
        font-size: 0.9rem;
        color: var(--text-light);
        margin-bottom: 0.8rem;
        font-weight: 500;
    }
    
    .metric-value {
        font-size: 1.8rem;
        font-weight: 700;
        color: var(--primary-color);
        margin-bottom: 0.3rem;
    }
    
    /* Button styling */
    .stButton > button {
        background-color: var(--primary-color) !important;
        color: white !important;
        border-radius: 8px !important;
        font-weight: 600 !important;
        padding: 0.5rem 1.5rem !important;
        transition: var(--transition) !important;
        border: none !important;
        box-shadow: 0 4px 12px rgba(87, 68, 148, 0.2) !important;
    }
    
    .stButton > button:hover {
        background-color: var(--primary-dark) !important;
        box-shadow: 0 6px 16px rgba(87, 68, 148, 0.3) !important;
        transform: translateY(-2px) !important;
    }
    
    .stButton > button:active {
        box-shadow: 0 2px 6px rgba(87, 68, 148, 0.2) !important;
        transform: translateY(0) !important;
    }
    
    /* Tabs styling */
    .stTabs [data-baseweb="tab-list"] {
        gap: 1rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        background-color: transparent !important;
        border-radius: 8px 8px 0 0 !important;
        padding: 0.5rem 1rem !important;
        transition: var(--transition) !important;
    }
    
    .stTabs [aria-selected="true"] {
        background-color: white !important;
        border-top: 3px solid var(--primary-color) !important;
    }
    
    /* Sidebar styling */
    .css-1aumxhk {
        background-color: #FFFFFF;
        border-right: 1px solid #EEEEEE;
    }
    
    /* Sliders and selectbox styling */
    .stSlider [data-baseweb="slider"] {
        margin-top: 1rem;
    }
    
    .stSlider [data-baseweb="thumb"] {
        background-color: var(--primary-color) !important;
        border-color: var(--primary-color) !important;
        transition: var(--transition) !important;
    }
    
    .stSlider [data-baseweb="thumb"]:hover {
        transform: scale(1.1) !important;
    }
    
    /* Radio buttons, checkboxes and toggle */
    .stRadio [data-baseweb="radio"] {
        transition: var(--transition) !important;
    }
    
    .stRadio [data-baseweb="radio"]:checked {
        background-color: var(--primary-color) !important;
        border-color: var(--primary-color) !important;
    }
    
    /* Expander styling */
    .streamlit-expanderHeader {
        font-weight: 600;
        color: var(--primary-color);
        background-color: #F7F7F9;
        border-radius: 8px;
        padding: 0.75rem 1rem !important;
    }
    
    /* Footer styling */
    footer {
        margin-top: 4rem;
        padding-top: 1.5rem;
        text-align: center;
        color: var(--text-light);
        font-size: 0.9rem;
        position: relative;
    }
    
    footer::before {
        content: "";
        position: absolute;
        top: 0;
        left: 20%;
        width: 60%;
        height: 1px;
        background: linear-gradient(90deg, 
            rgba(87, 68, 148, 0), 
            rgba(87, 68, 148, 0.3) 20%, 
            rgba(87, 68, 148, 0.3) 80%, 
            rgba(87, 68, 148, 0) 100%);
    }
    
    .footer-brand {
        font-weight: 700;
        color: var(--primary-color);
    }
    
    /* Chart containers */
    .chart-container {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.05);
        margin-bottom: 2rem;
        transition: var(--transition);
    }
    
    .chart-container:hover {
        box-shadow: 0 8px 30px rgba(0, 0, 0, 0.08);
    }
    
    /* Insight cards */
    .insight-card {
        background-color: #FCF9FF;
        border-left: 4px solid var(--primary-color);
        border-radius: 0 8px 8px 0;
        padding: 1rem 1.5rem;
        margin-bottom: 1rem;
        transition: var(--transition);
    }
    
    .insight-card:hover {
        background-color: #F5EFFF;
        transform: translateX(3px);
    }
    
    /* Section headings */
    h2 {
        color: var(--primary-color);
        font-weight: 700;
        letter-spacing: -0.01em;
        margin-top: 2rem;
        margin-bottom: 1.2rem;
        position: relative;
        padding-bottom: 0.5rem;
    }
    
    h2::after {
        content: "";
        position: absolute;
        bottom: 0;
        left: 0;
        width: 40px;
        height: 3px;
        background: linear-gradient(90deg, 
            var(--primary-color) 0%, 
            var(--accent-yellow) 100%);
    }
    
    /* Tables */
    .dataframe-container {
        border-radius: 12px;
        overflow: hidden;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
    }
    
    /* Alert and info boxes */
    .stAlert {
        border-radius: 8px !important;
        border: none !important;
    }
    
    /* Progress bars */
    .stProgress > div > div {
        background-color: var(--primary-color) !important;
    }
    
    /* Animations for key elements */
    @keyframes fadeIn {
        from {
            opacity: 0;
            transform: translateY(10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }
    
    .animate-fadeIn {
        animation: fadeIn 0.5s ease-out forwards;
    }
    
    /* Branded code blocks */
    .stCodeBlock {
        background-color: #2A2139 !important;
        border-radius: 8px !important;
        border-left: 3px solid var(--primary-color) !important;
    }
    </style>
    """, unsafe_allow_html=True)

def zobraz_data_filtering():
    """
    Display data filtering section allowing users to create filtered subsets of their data
    """
    create_section_header("Filtrace dat", icon="游댌", 
                         description="Vytvo콏te filtrovan칳 pohled na va코e data pomoc칤 u쬴vatelsky definovan칳ch podm칤nek")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Inicializace filtru v session state
    if "filter_conditions" not in st.session_state:
        st.session_state.filter_conditions = {}
    
    if "filtered_data" not in st.session_state:
        st.session_state.filtered_data = None
        st.session_state.filtered_eda = None
    
    # UI pro definov치n칤 filtr콢
    st.subheader("Definice filtra캜n칤ch podm칤nek")
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        column_types = {
            "V코echny sloupce": list(data.columns),
            "Numerick칠 sloupce": eda.numeric_cols,
            "Kategorick칠 sloupce": eda.categorical_cols,
            "Datum sloupce": eda.datetime_cols
        }
        
        column_type = st.radio("Typ sloupce", list(column_types.keys()))
        available_columns = column_types[column_type]
        
        selected_column = st.selectbox(
            "Vyberte sloupec pro filtrov치n칤",
            available_columns,
            key="filter_column"
        )
    
    with col2:
        if selected_column in eda.numeric_cols:
            # Numerick칳 filtr
            st.write(f"Definujte rozsah pro {selected_column}")
            
            # Zjist칤me rozsah hodnot
            min_val = data[selected_column].min()
            max_val = data[selected_column].max()
            
            # P콏id치me posuvn칤ky pro definov치n칤 rozsahu
            filter_range = st.slider(
                "Rozsah hodnot",
                min_value=float(min_val),
                max_value=float(max_val),
                value=(float(min_val), float(max_val))
            )
            
            # Tla캜칤tko pro p콏id치n칤 filtru
            if st.button("P콏idat filtr rozsahu"):
                st.session_state.filter_conditions[selected_column] = {
                    "type": "range",
                    "min": filter_range[0],
                    "max": filter_range[1]
                }
                st.success(f"Filtr pro {selected_column} p콏id치n: rozsah {filter_range[0]} a {filter_range[1]}")
        
        elif selected_column in eda.categorical_cols:
            # Kategorick칳 filtr
            unique_values = sorted(data[selected_column].dropna().unique())
            
            if len(unique_values) <= 10:
                # Pro men코칤 po캜et kategori칤 pou쬴jeme checkboxy
                st.write(f"Vyberte hodnoty pro {selected_column}")
                
                selected_values = {}
                for val in unique_values:
                    selected_values[str(val)] = st.checkbox(str(val), value=True, key=f"filter_{selected_column}_{val}")
                
                if st.button("P콏idat kategorick칳 filtr"):
                    selected = [val for val, is_selected in selected_values.items() if is_selected]
                    if selected:
                        st.session_state.filter_conditions[selected_column] = {
                            "type": "categorical",
                            "values": selected
                        }
                        st.success(f"Filtr pro {selected_column} p콏id치n: vybran칠 kategorie {', '.join(selected)}")
            else:
                # Pro v캩t코칤 po캜et kategori칤 pou쬴jeme multiselect
                st.write(f"Vyberte hodnoty pro {selected_column}")
                selected_values = st.multiselect(
                    "Vyberte hodnoty",
                    options=unique_values,
                    default=unique_values[:min(5, len(unique_values))]
                )
                
                if st.button("P콏idat kategorick칳 filtr"):
                    if selected_values:
                        st.session_state.filter_conditions[selected_column] = {
                            "type": "categorical",
                            "values": [str(val) for val in selected_values]
                        }
                        st.success(f"Filtr pro {selected_column} p콏id치n: vybran칠 kategorie {', '.join(str(v) for v in selected_values)}")
        
        elif selected_column in eda.datetime_cols:
            # Filtr pro datum
            st.write(f"Definujte rozsah dat pro {selected_column}")
            
            # Zjist칤me rozsah hodnot
            date_series = pd.to_datetime(data[selected_column])
            min_date = date_series.min().date()
            max_date = date_series.max().date()
            
            # P콏id치me v칳b캩r data
            start_date = st.date_input("Po캜치te캜n칤 datum", min_date)
            end_date = st.date_input("Koncov칠 datum", max_date)
            
            if st.button("P콏idat filtr data"):
                st.session_state.filter_conditions[selected_column] = {
                    "type": "date",
                    "start": start_date,
                    "end": end_date
                }
                st.success(f"Filtr pro {selected_column} p콏id치n: od {start_date} do {end_date}")
        
        else:
            # Textov칳 filtr
            st.write(f"Filtrujte text v {selected_column}")
            
            contains_text = st.text_input("Text obsahuje")
            
            if st.button("P콏idat textov칳 filtr"):
                if contains_text:
                    st.session_state.filter_conditions[selected_column] = {
                        "type": "text",
                        "contains": contains_text
                    }
                    st.success(f"Filtr pro {selected_column} p콏id치n: obsahuje '{contains_text}'")
    
    # Zobrazen칤 aktu치ln칤ch filtr콢
    if st.session_state.filter_conditions:
        st.subheader("Aktivn칤 filtry")
        
        for col, condition in st.session_state.filter_conditions.items():
            if condition["type"] == "range":
                st.markdown(f"- **{col}**: rozsah od {condition['min']} do {condition['max']}")
            elif condition["type"] == "categorical":
                st.markdown(f"- **{col}**: kategorie {', '.join(condition['values'])}")
            elif condition["type"] == "date":
                st.markdown(f"- **{col}**: od {condition['start']} do {condition['end']}")
            elif condition["type"] == "text":
                st.markdown(f"- **{col}**: obsahuje '{condition['contains']}'")
        
        # Tla캜칤tko pro odstran캩n칤 v코ech filtr콢
        if st.button("Vymazat v코echny filtry", type="secondary"):
            st.session_state.filter_conditions = {}
            st.session_state.filtered_data = None
            st.session_state.filtered_eda = None
            st.rerun()
    
    # Aplikov치n칤 filtr콢
    col1, col2 = st.columns(2)
    
    with col1:
        if st.session_state.filter_conditions and st.button("Aplikovat filtry", type="primary", use_container_width=True):
            # Vytvo콏en칤 filtrovac칤ch podm칤nek ve form치tu pro EDA.filter_data
            filters = {}
            
            for col, condition in st.session_state.filter_conditions.items():
                if condition["type"] == "range":
                    filters[col] = {"min": condition["min"], "max": condition["max"]}
                elif condition["type"] == "categorical":
                    filters[col] = {"in": condition["values"]}
                elif condition["type"] == "date":
                    filters[col] = {"min": pd.Timestamp(condition["start"]), 
                                  "max": pd.Timestamp(condition["end"])}
                elif condition["type"] == "text":
                    filters[col] = {"like": condition["contains"]}
            
            # Aplikov치n칤 filtr콢 pomoc칤 metody z EDA
            try:
                filtered_eda = eda.filter_data(filters)
                st.session_state.filtered_eda = filtered_eda
                st.session_state.filtered_data = filtered_eda.data
                st.success(f"Filtry 칰sp캩코n캩 aplikov치ny. V칳sledek: {len(filtered_eda.data)} 콏치dk콢 (p콢vodn캩 {len(data)} 콏치dk콢)")
                st.rerun()
            except Exception as e:
                st.error(f"Chyba p콏i aplikov치n칤 filtr콢: {str(e)}")
    
    with col2:
        if st.session_state.filtered_data is not None:
            if st.button("Pou쮂셦 filtrovan치 data jako hlavn칤 dataset", type="primary", use_container_width=True):
                st.session_state.data = st.session_state.filtered_data
                st.session_state.eda = st.session_state.filtered_eda
                st.session_state.filtered_data = None
                st.session_state.filtered_eda = None
                st.session_state.filter_conditions = {}
                st.success("Filtrovan치 data byla nastavena jako hlavn칤 dataset")
                st.rerun()
    
    # Zobrazen칤 filtrovan칳ch dat, pokud existuj칤
    if st.session_state.filtered_data is not None:
        st.subheader("N치hled filtrovan칳ch dat")
        
        # Vytvo콏en칤 z치lo쬰k pro r콢zn칠 pohledy
        preview_tab1, preview_tab2, preview_tab3 = st.tabs(["Tabulka", "Porovn치n칤 statistik", "Distribuce"])
        
        with preview_tab1:
            st.dataframe(st.session_state.filtered_data.head(10), use_container_width=True)
        
        with preview_tab2:
            if len(eda.numeric_cols) > 0:
                # Porovn치n칤 z치kladn칤ch statistik p콏ed a po filtraci
                st.markdown("#### Porovn치n칤 statistik p콏ed a po filtraci")
                
                # V칳b캩r sloupce pro porovn치n칤
                compare_col = st.selectbox(
                    "Vyberte sloupec pro porovn치n칤 statistik",
                    eda.numeric_cols
                )
                
                # Vytvo콏en칤 statistik
                orig_stats = data[compare_col].describe()
                filtered_stats = st.session_state.filtered_data[compare_col].describe()
                
                # Spojen칤 statistik do jedn칠 tabulky
                stats_comparison = pd.DataFrame({
                    'P콢vodn칤 data': orig_stats,
                    'Filtrovan치 data': filtered_stats,
                    'Rozd칤l': filtered_stats - orig_stats,
                    'Rozd칤l (%)': (filtered_stats - orig_stats) / orig_stats * 100
                })
                
                st.dataframe(stats_comparison, use_container_width=True)
        
        with preview_tab3:
            if len(eda.numeric_cols) > 0:
                # V칳b캩r sloupce pro vizualizaci
                viz_col = st.selectbox(
                    "Vyberte sloupec pro vizualizaci distribuc칤",
                    eda.numeric_cols,
                    key="viz_distrib_col"
                )
                
                # Vytvo콏en칤 histogram콢 pro porovn치n칤 distribuc칤
                fig = go.Figure()
                
                # Histogram p콢vodn칤ch dat
                fig.add_trace(go.Histogram(
                    x=data[viz_col],
                    name='P콢vodn칤 data',
                    opacity=0.7,
                    marker_color=OICT_COLORS['purple'],
                    nbinsx=30
                ))
                
                # Histogram filtrovan칳ch dat
                fig.add_trace(go.Histogram(
                    x=st.session_state.filtered_data[viz_col],
                    name='Filtrovan치 data',
                    opacity=0.7,
                    marker_color=OICT_COLORS['orange'],
                    nbinsx=30
                ))
                
                # 칔prava layoutu
                fig.update_layout(
                    title=f'Porovn치n칤 distribuce {viz_col} p콏ed a po filtraci',
                    xaxis_title=viz_col,
                    yaxis_title='캛etnost',
                    barmode='overlay'
                )
                
                st.plotly_chart(fig, use_container_width=True)

def zobraz_data_comparison():
    """
    Display data comparison section allowing users to compare two datasets
    """
    create_section_header("Porovn치n칤 dataset콢", icon="丘뒲잺", 
                         description="Porovnejte aktu치ln칤 dataset s jin칳m datasetem a identifikujte kl칤캜ov칠 rozd칤ly")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Inicializace pro druh칳 dataset v session state
    if "comparison_data" not in st.session_state:
        st.session_state.comparison_data = None
        st.session_state.comparison_eda = None
        st.session_state.comparison_results = None
    
    # UI pro nahr치n칤 druh칠ho datasetu
    st.subheader("Nahr치n칤 datasetu pro porovn치n칤")
    
    # Tabs pro r콢zn칠 zp콢soby z칤sk치n칤 druh칠ho datasetu
    source_tabs = st.tabs(["游늬 Soubor", "游 Uk치zkov칠 datasety", "游댃 Filtrovan치 data"])
    
    with source_tabs[0]:  # Nahr치n칤 souboru
        uploaded_file = st.file_uploader(
            "Vyberte CSV nebo Excel soubor pro porovn치n칤",
            type=["csv", "xlsx", "xls"]
        )
        
        if uploaded_file is not None:
            try:
                # Nastaven칤 importu
                with st.expander("Nastaven칤 importu", expanded=False):
                    if uploaded_file.name.endswith('.csv'):
                        separator = st.text_input("Odd캩lova캜", value=",")
                        encoding = st.selectbox("K칩dov치n칤", 
                                              options=["utf-8", "iso-8859-1", "windows-1250", "latin1", "latin2"],
                                              index=0)
                    else:  # Excel
                        sheet_name = st.text_input("N치zev listu (ponechte pr치zdn칠 pro prvn칤 list)", value="")
                
                # Nahr치n칤 dat
                if uploaded_file.name.endswith('.csv'):
                    comparison_data = pd.read_csv(uploaded_file, sep=separator, encoding=encoding)
                else:
                    if sheet_name.strip():
                        comparison_data = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                    else:
                        comparison_data = pd.read_excel(uploaded_file)
                
                if st.button("Pou쮂셦 pro porovn치n칤", key="use_uploaded"):
                    # Vytvo콏en칤 EDA objektu
                    from eda import EDA
                    comparison_eda = EDA(comparison_data)
                    
                    # Ulo쬰n칤 do session state
                    st.session_state.comparison_data = comparison_data
                    st.session_state.comparison_eda = comparison_eda
                    st.success(f"Dataset pro porovn치n칤 칰sp캩코n캩 nahr치n: {comparison_data.shape[0]} 콏치dk콢 a {comparison_data.shape[1]} sloupc콢")
                    
                    # Spu코t캩n칤 porovn치n칤 dataset콢
                    run_comparison()
                    st.rerun()
            except Exception as e:
                st.error(f"Chyba p콏i nahr치v치n칤 souboru: {str(e)}")
    
    with source_tabs[1]:  # Uk치zkov칠 datasety
        st.markdown("### Vyberte uk치zkov칳 dataset")
        
        # Uk치zkov칠 datasety v sloupcov칠m rozlo쬰n칤
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="card primary" style="height: 100%;">
                <h4>Iris kv캩tiny 游꺚</h4>
                <p>Klasick칳 dataset pro klasifikaci.</p>
                <p><strong>150 콏치dk콢, 5 sloupc콢</strong></p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t Iris dataset", key="comp_load_iris", use_container_width=True):
                try:
                    from sklearn.datasets import load_iris
                    iris = load_iris()
                    comparison_data = pd.DataFrame(iris.data, columns=iris.feature_names)
                    comparison_data['target'] = iris.target
                    
                    # Vytvo콏en칤 EDA objektu
                    from eda import EDA
                    comparison_eda = EDA(comparison_data)
                    
                    # Ulo쬰n칤 do session state
                    st.session_state.comparison_data = comparison_data
                    st.session_state.comparison_eda = comparison_eda
                    st.success("Dataset Iris 칰sp캩코n캩 nahr치n pro porovn치n칤")
                    
                    # Spu코t캩n칤 porovn치n칤
                    run_comparison()
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
        
        with col2:
            st.markdown("""
            <div class="card orange" style="height: 100%;">
                <h4>Pasa쮂뽠뗠 Titanicu 游뚹</h4>
                <p>Dataset pro anal칳zu p콏e쬴t칤 pasa쮂r콢.</p>
                <p><strong>891 콏치dk콢, 12 sloupc콢</strong></p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t Titanic dataset", key="comp_load_titanic", use_container_width=True):
                try:
                    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
                    comparison_data = pd.read_csv(url)
                    
                    # Vytvo콏en칤 EDA objektu
                    from eda import EDA
                    comparison_eda = EDA(comparison_data)
                    
                    # Ulo쬰n칤 do session state
                    st.session_state.comparison_data = comparison_data
                    st.session_state.comparison_eda = comparison_eda
                    st.success("Dataset Titanicu 칰sp캩코n캩 nahr치n pro porovn치n칤")
                    
                    # Spu코t캩n칤 porovn치n칤
                    run_comparison()
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
    
    with source_tabs[2]:  # Filtrovan치 data
        st.markdown("### Pou쬴t칤 filtrovan칳ch dat pro porovn치n칤")
        
        if "filtered_data" in st.session_state and st.session_state.filtered_data is not None:
            st.info(f"K dispozici jsou filtrovan치 data s {len(st.session_state.filtered_data)} 콏치dky.")
            
            if st.button("Pou쮂셦 filtrovan치 data pro porovn치n칤", key="use_filtered", use_container_width=True):
                # Ulo쬰n칤 filtrovan칳ch dat jako srovn치vac칤 dataset
                st.session_state.comparison_data = st.session_state.filtered_data
                st.session_state.comparison_eda = st.session_state.filtered_eda
                st.success("Filtrovan치 data 칰sp캩코n캩 nastavena pro porovn치n칤")
                
                # Spu코t캩n칤 porovn치n칤
                run_comparison()
                st.rerun()
        else:
            st.warning("콯치dn치 filtrovan치 data nejsou k dispozici. Nejprve pou쬴jte sekci 'Filtrace dat' pro vytvo콏en칤 filtrovan칠ho datasetu.")
    
    # Zobrazen칤 v칳sledk콢 porovn치n칤, pokud existuj칤
    if st.session_state.comparison_results is not None:
        display_comparison_results()

def run_comparison():
    """
    Run dataset comparison and store results in session state
    """
    if "data" in st.session_state and "comparison_data" in st.session_state:
        if st.session_state.data is not None and st.session_state.comparison_data is not None:
            try:
                # Z칤sk치n칤 v칳sledk콢 porovn치n칤 pomoc칤 metody EDA
                results = st.session_state.eda.compare_datasets(
                    st.session_state.comparison_eda,
                    name1="P콢vodn칤 dataset",
                    name2="Porovn치van칳 dataset"
                )
                
                # Ulo쬰n칤 v칳sledk콢 do session state
                st.session_state.comparison_results = results
                return True
            except Exception as e:
                st.error(f"Chyba p콏i porovn치v치n칤 dataset콢: {str(e)}")
                return False
    return False

def display_comparison_results():
    """
    Display comparison results between two datasets
    """
    results = st.session_state.comparison_results
    
    st.header("V칳sledky porovn치n칤 dataset콢")
    
    # Z치kladn칤 informace o velikosti
    st.subheader("Z치kladn칤 porovn치n칤 velikosti")
    
    size_data = pd.DataFrame({
        'Metrika': ['Po캜et 콏치dk콢', 'Po캜et sloupc콢'],
        'P콢vodn칤 dataset': [results['size']['P콢vodn칤 dataset']['rows'], 
                          results['size']['P콢vodn칤 dataset']['columns']],
        'Porovn치van칳 dataset': [results['size']['Porovn치van칳 dataset']['rows'], 
                              results['size']['Porovn치van칳 dataset']['columns']],
        'Rozd칤l': [results['size']['difference']['rows'], 
                  results['size']['difference']['columns']]
    })
    
    st.dataframe(size_data, use_container_width=True)
    
    # Porovn치n칤 sloupc콢
    st.subheader("Porovn치n칤 sloupc콢")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"**Spole캜n칠 sloupce ({len(results['columns']['common'])}):**")
        if results['columns']['common']:
            st.write(", ".join(sorted(results['columns']['common'])))
        else:
            st.write("콯치dn칠")
    
    with col2:
        st.markdown(f"**Rozd칤ln칠 sloupce:**")
        st.markdown(f"- Pouze v p콢vodn칤m datasetu ({len(results['columns']['only_in_P콢vodn칤 dataset'])}): "
                  f"{', '.join(sorted(results['columns']['only_in_P콢vodn칤 dataset'])) if results['columns']['only_in_P콢vodn칤 dataset'] else '콯치dn칠'}")
        st.markdown(f"- Pouze v porovn치van칠m datasetu ({len(results['columns']['only_in_Porovn치van칳 dataset'])}): "
                  f"{', '.join(sorted(results['columns']['only_in_Porovn치van칳 dataset'])) if results['columns']['only_in_Porovn치van칳 dataset'] else '콯치dn칠'}")
    
    # Porovn치n칤 distribuc칤 캜칤seln칳ch sloupc콢
    st.subheader("Porovn치n칤 distribuc칤 spole캜n칳ch sloupc콢")
    
    numeric_diffs = {k: v for k, v in results['distribution_differences'].items() 
                   if k in st.session_state.eda.numeric_cols and k in st.session_state.comparison_eda.numeric_cols}
    
    if numeric_diffs:
        # V칳b캩r sloupce pro vizualizaci
        num_cols = list(numeric_diffs.keys())
        selected_col = st.selectbox("Vyberte sloupec pro porovn치n칤 distribuc칤", num_cols)
        
        if selected_col:
            # Z칤sk치n칤 dat z obou dataset콢
            orig_data = st.session_state.data[selected_col].dropna()
            comp_data = st.session_state.comparison_data[selected_col].dropna()
            
            # Statistiky
            stats_data = pd.DataFrame({
                'Metrika': ['Pr콢m캩r', 'Medi치n', 'Sm캩r. odchylka', 'Min', 'Max'],
                'P콢vodn칤 dataset': [
                    orig_data.mean(),
                    orig_data.median(),
                    orig_data.std(),
                    orig_data.min(),
                    orig_data.max()
                ],
                'Porovn치van칳 dataset': [
                    comp_data.mean(),
                    comp_data.median(),
                    comp_data.std(),
                    comp_data.min(),
                    comp_data.max()
                ],
                'Absolutn칤 rozd칤l': [
                    abs(orig_data.mean() - comp_data.mean()),
                    abs(orig_data.median() - comp_data.median()),
                    abs(orig_data.std() - comp_data.std()),
                    abs(orig_data.min() - comp_data.min()),
                    abs(orig_data.max() - comp_data.max())
                ],
                'Relativn칤 rozd칤l (%)': [
                    abs((orig_data.mean() - comp_data.mean()) / comp_data.mean() * 100) if comp_data.mean() != 0 else 0,
                    abs((orig_data.median() - comp_data.median()) / comp_data.median() * 100) if comp_data.median() != 0 else 0,
                    abs((orig_data.std() - comp_data.std()) / comp_data.std() * 100) if comp_data.std() != 0 else 0,
                    abs((orig_data.min() - comp_data.min()) / comp_data.min() * 100) if comp_data.min() != 0 else 0,
                    abs((orig_data.max() - comp_data.max()) / comp_data.max() * 100) if comp_data.max() != 0 else 0,
                ]
            })
            
            st.dataframe(stats_data, use_container_width=True)
            
            # Vizualizace - porovn치n칤 histogram콢
            fig = go.Figure()
            
            # Histogram p콢vodn칤ho datasetu
            fig.add_trace(go.Histogram(
                x=orig_data,
                name='P콢vodn칤 dataset',
                opacity=0.7,
                marker_color=OICT_COLORS['purple'],
                nbinsx=30
            ))
            
            # Histogram porovn치van칠ho datasetu
            fig.add_trace(go.Histogram(
                x=comp_data,
                name='Porovn치van칳 dataset',
                opacity=0.7,
                marker_color=OICT_COLORS['orange'],
                nbinsx=30
            ))
            
            # 칔prava layoutu
            fig.update_layout(
                title=f'Porovn치n칤 distribuce {selected_col}',
                xaxis_title=selected_col,
                yaxis_title='캛etnost',
                barmode='overlay'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Box plot pro porovn치n칤
            fig2 = go.Figure()
            
            fig2.add_trace(go.Box(
                y=orig_data,
                name='P콢vodn칤 dataset',
                marker_color=OICT_COLORS['purple']
            ))
            
            fig2.add_trace(go.Box(
                y=comp_data,
                name='Porovn치van칳 dataset',
                marker_color=OICT_COLORS['orange']
            ))
            
            fig2.update_layout(
                title=f'Boxplot porovn치n칤 {selected_col}',
                yaxis_title=selected_col
            )
            
            st.plotly_chart(fig2, use_container_width=True)
    
    # Porovn치n칤 kategorick칳ch sloupc콢
    cat_diffs = {k: v for k, v in results['distribution_differences'].items() 
               if k in st.session_state.eda.categorical_cols and k in st.session_state.comparison_eda.categorical_cols}
    
    if cat_diffs:
        st.subheader("Porovn치n칤 kategorick칳ch sloupc콢")
        
        cat_cols = list(cat_diffs.keys())
        selected_cat = st.selectbox("Vyberte kategorick칳 sloupec pro porovn치n칤", cat_cols)
        
        if selected_cat:
            # Z칤sk치n칤 dat z obou dataset콢
            orig_counts = st.session_state.data[selected_cat].value_counts(normalize=True)
            comp_counts = st.session_state.comparison_data[selected_cat].value_counts(normalize=True)
            
            # Sjednocen칤 kategori칤
            all_categories = sorted(set(orig_counts.index) | set(comp_counts.index))
            
            # Vytvo콏en칤 srovn치vac칤 tabulky
            comparison_data = pd.DataFrame({
                'Kategorie': all_categories,
                'P콢vodn칤 dataset (%)': [orig_counts.get(cat, 0) * 100 for cat in all_categories],
                'Porovn치van칳 dataset (%)': [comp_counts.get(cat, 0) * 100 for cat in all_categories],
                'Rozd칤l (%)': [abs(orig_counts.get(cat, 0) - comp_counts.get(cat, 0)) * 100 for cat in all_categories]
            }).sort_values('Rozd칤l (%)', ascending=False)
            
            st.dataframe(comparison_data, use_container_width=True)
            
            # Vizualizace - sloupcov칳 graf
            fig = go.Figure()
            
            fig.add_trace(go.Bar(
                x=comparison_data['Kategorie'],
                y=comparison_data['P콢vodn칤 dataset (%)'],
                name='P콢vodn칤 dataset',
                marker_color=OICT_COLORS['purple']
            ))
            
            fig.add_trace(go.Bar(
                x=comparison_data['Kategorie'],
                y=comparison_data['Porovn치van칳 dataset (%)'],
                name='Porovn치van칳 dataset',
                marker_color=OICT_COLORS['orange']
            ))
            
            fig.update_layout(
                title=f'Porovn치n칤 rozlo쬰n칤 kategori칤 {selected_cat}',
                xaxis_title='Kategorie',
                yaxis_title='Procento (%)',
                barmode='group'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Vizualizace rozd칤l콢
            fig2 = px.bar(
                comparison_data,
                x='Kategorie',
                y='Rozd칤l (%)',
                title=f'Rozd칤ly v rozlo쬰n칤 kategori칤 {selected_cat}',
                color='Rozd칤l (%)',
                color_continuous_scale='Reds'
            )
            
            st.plotly_chart(fig2, use_container_width=True)
    
    # Z치v캩re캜n칠 shrnut칤
    st.subheader("Hlavn칤 rozd칤ly mezi datasety")
    
    # Vytvo콏en칤 seznamu hlavn칤ch rozd칤l콢
    differences = []
    
    # Rozd칤l ve velikosti
    size_diff_rows = abs(results['size']['difference']['rows'])
    size_diff_pct = abs(results['size']['difference']['rows'] / results['size']['P콢vodn칤 dataset']['rows'] * 100) if results['size']['P콢vodn칤 dataset']['rows'] > 0 else 0
    
    if size_diff_rows > 0:
        if results['size']['difference']['rows'] > 0:
            differences.append(f"P콢vodn칤 dataset m치 o **{size_diff_rows}** 콏치dk콢 v칤ce ({size_diff_pct:.1f}%).")
        else:
            differences.append(f"Porovn치van칳 dataset m치 o **{size_diff_rows}** 콏치dk콢 v칤ce ({size_diff_pct:.1f}%).")
    
    # Rozd칤l ve sloupc칤ch
    col_diff = len(results['columns']['only_in_P콢vodn칤 dataset']) + len(results['columns']['only_in_Porovn치van칳 dataset'])
    if col_diff > 0:
        differences.append(f"Datasety se li코칤 v **{col_diff}** sloupc칤ch.")
    
    # Nejv캩t코칤 rozd칤ly v 캜칤seln칳ch sloupc칤ch
    if numeric_diffs:
        max_diff_col = max(numeric_diffs.items(), key=lambda x: abs(x[1].get('mean_diff', 0)))
        differences.append(f"Nejv캩t코칤 rozd칤l pr콢m캩r콢 je ve sloupci **{max_diff_col[0]}** "
                          f"(absolutn칤 rozd칤l: {abs(max_diff_col[1].get('mean_diff', 0)):.2f}).")
    
    # Nejv캩t코칤 rozd칤ly v kategorick칳ch sloupc칤ch
    if cat_diffs:
        max_cat_diff_col = max(cat_diffs.items(), key=lambda x: x[1].get('total_variation_distance', 0))
        differences.append(f"Nejv캩t코칤 rozd칤l v kategorick칠m rozlo쬰n칤 je ve sloupci **{max_cat_diff_col[0]}** "
                          f"(total variation distance: {max_cat_diff_col[1].get('total_variation_distance', 0):.2f}).")
    
    # Zobrazen칤 seznamu rozd칤l콢
    if differences:
        for diff in differences:
            st.markdown(f"- {diff}")
    else:
        st.info("Datasety jsou velmi podobn칠, nebyly nalezeny v칳razn칠 rozd칤ly.")
    
    # Mo쬹ost exportu srovn치vac칤 zpr치vy
    if st.button("Exportovat srovn치vac칤 zpr치vu", type="primary"):
        try:
            report_html = vytvor_srovnavaci_report(st.session_state.data, st.session_state.comparison_data, results)
            b64 = base64.b64encode(report_html.encode()).decode()
            href = f'<a href="data:text/html;base64,{b64}" download="comparison_report.html" class="btn btn-primary">St치hnout HTML zpr치vu</a>'
            st.markdown(href, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"Chyba p콏i vytv치콏en칤 zpr치vy: {str(e)}")

def vytvor_srovnavaci_report(data1, data2, results):
    """
    Vytvo콏칤 HTML report s v칳sledky porovn치n칤 dvou dataset콢
    """
    import datetime
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>Comparison Report</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                margin: 30px;
                line-height: 1.6;
                color: #333;
            }}
            .header {{
                text-align: center;
                margin-bottom: 30px;
                border-bottom: 2px solid #574494;
                padding-bottom: 10px;
            }}
            .logo {{
                background-color: #574494;
                color: white;
                padding: 5px 15px;
                border-radius: 4px;
                font-weight: bold;
                font-size: 24px;
                display: inline-block;
                margin-bottom: 10px;
            }}
            h1, h2, h3 {{
                color: #574494;
            }}
            table {{
                border-collapse: collapse;
                width: 100%;
                margin-bottom: 20px;
            }}
            th, td {{
                border: 1px solid #ddd;
                padding: 8px;
                text-align: left;
            }}
            th {{
                background-color: #f2f2f2;
                font-weight: bold;
            }}
            .section {{
                margin-bottom: 30px;
                border-bottom: 1px solid #eee;
                padding-bottom: 20px;
            }}
            .highlight {{
                background-color: #ffffcc;
                padding: 2px 5px;
                border-radius: 3px;
            }}
            .footer {{
                margin-top: 50px;
                text-align: center;
                color: #666;
                font-size: 14px;
                border-top: 1px solid #eee;
                padding-top: 20px;
            }}
        </style>
    </head>
    <body>
        <div class="header">
            <div class="logo">oict.</div>
            <h1>Report porovn치n칤 dataset콢</h1>
            <p>Vygenerov치no: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M")}</p>
        </div>
        
        <div class="section">
            <h2>Z치kladn칤 porovn치n칤</h2>
            
            <h3>Velikost dataset콢</h3>
            <table>
                <tr>
                    <th>Metrika</th>
                    <th>P콢vodn칤 dataset</th>
                    <th>Porovn치van칳 dataset</th>
                    <th>Rozd칤l</th>
                </tr>
                <tr>
                    <td>Po캜et 콏치dk콢</td>
                    <td>{results['size']['P콢vodn칤 dataset']['rows']}</td>
                    <td>{results['size']['Porovn치van칳 dataset']['rows']}</td>
                    <td>{results['size']['difference']['rows']}</td>
                </tr>
                <tr>
                    <td>Po캜et sloupc콢</td>
                    <td>{results['size']['P콢vodn칤 dataset']['columns']}</td>
                    <td>{results['size']['Porovn치van칳 dataset']['columns']}</td>
                    <td>{results['size']['difference']['columns']}</td>
                </tr>
            </table>
            
            <h3>Porovn치n칤 sloupc콢</h3>
            <p><strong>Spole캜n칠 sloupce ({len(results['columns']['common'])}):</strong> {', '.join(sorted(results['columns']['common']))}</p>
            <p><strong>Pouze v p콢vodn칤m datasetu ({len(results['columns']['only_in_P콢vodn칤 dataset'])}):</strong> {', '.join(sorted(results['columns']['only_in_P콢vodn칤 dataset'])) if results['columns']['only_in_P콢vodn칤 dataset'] else '콯치dn칠'}</p>
            <p><strong>Pouze v porovn치van칠m datasetu ({len(results['columns']['only_in_Porovn치van칳 dataset'])}):</strong> {', '.join(sorted(results['columns']['only_in_Porovn치van칳 dataset'])) if results['columns']['only_in_Porovn치van칳 dataset'] else '콯치dn칠'}</p>
        </div>
    """
    
    # P콏id치n칤 sekce s numerick칳mi rozd칤ly
    numeric_diffs = {k: v for k, v in results['distribution_differences'].items() 
                   if isinstance(v, dict) and 'mean_diff' in v}
    
    if numeric_diffs:
        html += """
        <div class="section">
            <h2>Porovn치n칤 numerick칳ch sloupc콢</h2>
            <table>
                <tr>
                    <th>Sloupec</th>
                    <th>Rozd칤l pr콢m캩r콢</th>
                    <th>Rozd칤l v %</th>
                </tr>
        """
        
        for col, diff in numeric_diffs.items():
            if 'mean_diff' in diff and 'mean_pct_diff' in diff:
                html += f"""
                <tr>
                    <td>{col}</td>
                    <td>{diff['mean_diff']:.4f}</td>
                    <td>{diff['mean_pct_diff']:.2f}%</td>
                </tr>
                """
        
        html += """
            </table>
        </div>
        """
    
    # P콏id치n칤 sekce s kategorick칳mi rozd칤ly
    cat_diffs = {k: v for k, v in results['distribution_differences'].items() 
               if isinstance(v, dict) and 'total_variation_distance' in v}
    
    if cat_diffs:
        html += """
        <div class="section">
            <h2>Porovn치n칤 kategorick칳ch sloupc콢</h2>
            <table>
                <tr>
                    <th>Sloupec</th>
                    <th>Kategorie s nejv캩t코칤m rozd칤lem</th>
                    <th>Maxim치ln칤 rozd칤l (%)</th>
                    <th>Total Variation Distance</th>
                </tr>
        """
        
        for col, diff in cat_diffs.items():
            if 'max_diff_category' in diff and 'max_diff_pct' in diff and 'total_variation_distance' in diff:
                html += f"""
                <tr>
                    <td>{col}</td>
                    <td>{diff['max_diff_category']}</td>
                    <td>{diff['max_diff_pct']:.2f}%</td>
                    <td>{diff['total_variation_distance']:.4f}</td>
                </tr>
                """
        
        html += """
            </table>
        </div>
        """
    
    # P콏id치n칤 z치v캩re캜n칳ch shrnut칤
    html += """
        <div class="section">
            <h2>Z치v캩re캜n칠 shrnut칤</h2>
            <h3>Hlavn칤 rozd칤ly mezi datasety</h3>
            <ul>
    """
    
    # V칳po캜et a p콏id치n칤 hlavn칤ch rozd칤l콢
    size_diff_rows = abs(results['size']['difference']['rows'])
    size_diff_pct = abs(results['size']['difference']['rows'] / results['size']['P콢vodn칤 dataset']['rows'] * 100) if results['size']['P콢vodn칤 dataset']['rows'] > 0 else 0
    
    if size_diff_rows > 0:
        if results['size']['difference']['rows'] > 0:
            html += f"<li>P콢vodn칤 dataset m치 o <span class='highlight'>{size_diff_rows}</span> 콏치dk콢 v칤ce ({size_diff_pct:.1f}%).</li>"
        else:
            html += f"<li>Porovn치van칳 dataset m치 o <span class='highlight'>{size_diff_rows}</span> 콏치dk콢 v칤ce ({size_diff_pct:.1f}%).</li>"
    
    col_diff = len(results['columns']['only_in_P콢vodn칤 dataset']) + len(results['columns']['only_in_Porovn치van칳 dataset'])
    if col_diff > 0:
        html += f"<li>Datasety se li코칤 v <span class='highlight'>{col_diff}</span> sloupc칤ch.</li>"
    
    if numeric_diffs:
        max_diff_col = max(numeric_diffs.items(), key=lambda x: abs(x[1].get('mean_diff', 0)))
        html += f"<li>Nejv캩t코칤 rozd칤l pr콢m캩r콢 je ve sloupci <span class='highlight'>{max_diff_col[0]}</span> (absolutn칤 rozd칤l: {abs(max_diff_col[1].get('mean_diff', 0)):.2f}).</li>"
    
    if cat_diffs:
        max_cat_diff_col = max(cat_diffs.items(), key=lambda x: x[1].get('total_variation_distance', 0))
        html += f"<li>Nejv캩t코칤 rozd칤l v kategorick칠m rozlo쬰n칤 je ve sloupci <span class='highlight'>{max_cat_diff_col[0]}</span> (total variation distance: {max_cat_diff_col[1].get('total_variation_distance', 0):.2f}).</li>"
    
    # Dokon캜en칤 HTML
    html += """
            </ul>
        </div>
        
        <div class="footer">
            <p>Powered by OICT</p>
            <p>춸 2023</p>
        </div>
    </body>
    </html>
    """
    
    return html

def zobraz_o_aplikaci():
    st.header("O aplikaci")
    
    st.markdown("""
    <div class="card primary">
        <h3>V칤tejte v aplikaci AutoEDA</h3>
        <p>
            AuroEDA je n치stroj, kter칳 v치m pom콢쬰 rychle a efektivn캩 analyzovat va코e data, 
            objevit skryt칠 vzory a z칤skat cenn칠 podnikatelsk칠 poznatky. N치stroj je ur캜en jak pro 
            datov칠 analytiky, tak pro business u쬴vatele, kte콏칤 pot콏ebuj칤 rychle prozkoumat a 
            porozum캩t sv칳m dat콢m.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("Jak za캜칤t")
    
    st.markdown("""
    <div class="insight-card">
        <h4>Rychl칳 n치vod pro pr치ci s n치strojem</h4>
        <ol>
            <li><strong>Nahrajte data</strong> - za캜n캩te nahr치n칤m CSV nebo Excel souboru v sekci "Nahr치n칤 dat"</li>
            <li><strong>Prozkoumejte p콏ehled</strong> - pod칤vejte se na z치kladn칤 charakteristiky va코ich dat v sekci "P콏ehled dat"</li>
            <li><strong>Analyzujte detaily</strong> - vyu쬴jte specializovan칠 sekce pro hlub코칤 anal칳zu</li>
            <li><strong>Generujte poznatky</strong> - vyu쬴jte pokro캜il칠 funkce pro z칤sk치n칤 hodnotn칳ch informac칤</li>
        </ol>
    </div>
    """, unsafe_allow_html=True)
    
    # Struktura aplikace
    st.subheader("Struktura aplikace")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="card primary">
            <h4>Z치kladn칤 anal칳za</h4>
            <p>Z치kladn칤 pr콢zkum a pochopen칤 struktury dat</p>
            <ul>
                <li>Nahr치n칤 dat</li>
                <li>P콏ehled dat</li>
                <li>Chyb캩j칤c칤 hodnoty</li>
                <li>Distribuce</li>
                <li>Korelace</li>
                <li>Odlehl칠 hodnoty</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="card orange">
            <h4>Pokro캜il치 anal칳za</h4>
            <p>Hlub코칤 statistick치 anal칳za a modelov치n칤</p>
            <ul>
                <li>Redukce dimenz칤</li>
                <li>Clustering</li>
                <li>Statistick칠 testy</li>
                <li>N치vrhy 칰prav</li>
                <li>Rychl칠 modelov치n칤</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="card green">
            <h4>Byznys anal칳za</h4>
            <p>Anal칳zy zam캩콏en칠 na podnikatelsk칠 pot콏eby</p>
            <ul>
                <li>캛asov칠 콏ady</li>
                <li>Cross tabulky</li>
                <li>KPI dashboard</li>
                <li>Kohortn칤 anal칳za</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    # Podrobn칳 popis sekc칤
    st.subheader("Podrobn칳 popis funkc칤")
    
    # Z치kladn칤 anal칳za
    with st.expander("Z치kladn칤 anal칳za", expanded=False):
        st.markdown("""
        ### Nahr치n칤 dat
        Umo쮄갓je nahr치t data ve form치tu CSV nebo Excel. M콢쬰te tak칠 vyu쮂셦 uk치zkov칠 datasety pro testov치n칤 funkcionalit.
        
        **Jak to pom치h치:** Jednoduch칳 vstupn칤 bod pro va코e data s podporou r콢zn칳ch form치t콢.
        
        ### P콏ehled dat
        Poskytuje z치kladn칤 informace o datasetu - po캜et 콏치dk콢, sloupc콢, typech dat, a kvalit캩 dat.
        
        **Jak to pom치h치:**
        - Rychl칳 p콏ehled o struktu콏e a kvalit캩 dat
        - Automatick치 detekce datov칳ch typ콢
        - Hodnocen칤 celkov칠 kvality dat
        
        ### Chyb캩j칤c칤 hodnoty
        Anal칳za a vizualizace chyb캩j칤c칤ch hodnot v jednotliv칳ch sloupc칤ch.
        
        **Jak to pom치h치:**
        - Identifikace sloupc콢 s nekompletn칤mi daty
        - Doporu캜en칤 pro 콏e코en칤 chyb캩j칤c칤ch hodnot
        - Vzorce pro imputaci chyb캩j칤c칤ch hodnot
        
        ### Distribuce
        Zkoum치 rozlo쬰n칤 hodnot v jednotliv칳ch sloupc칤ch pomoc칤 histogram콢 a statistik.
        
        **Jak to pom치h치:**
        - Pochopen칤 typick칠ho rozsahu hodnot
        - Identifikace ze코ikmen칤 a dal코칤ch vlastnost칤 distribuce
        - Vizualizace 캜etnost칤 kategori칤
        
        ### Korelace
        Anal칳za vztah콢 mezi numerick칳mi prom캩nn칳mi.
        
        **Jak to pom치h치:**
        - Identifikace siln캩 korelovan칳ch prom캩nn칳ch
        - Odhalen칤 potenci치ln칤ch kauz치ln칤ch vztah콢
        - Detekce multikolinearity, kter치 m콢쬰 ovlivnit modely
        
        ### Odlehl칠 hodnoty
        Detekce a anal칳za odlehl칳ch hodnot v numerick칳ch sloupc칤ch.
        
        **Jak to pom치h치:**
        - Identifikace potenci치ln칤ch chyb v datech
        - Anal칳za extr칠mn칤ch p콏칤pad콢
        - Doporu캜en칤 pro zpracov치n칤 odlehl칳ch hodnot
        """)
    
    # Pokro캜il치 anal칳za
    with st.expander("Pokro캜il치 anal칳za", expanded=False):
        st.markdown("""
        ### Redukce dimenz칤 (PCA)
        Anal칳za hlavn칤ch komponent pro sn칤쬰n칤 dimenzionality dat.
        
        **Jak to pom치h치:**
        - Redukce po캜tu prom캩nn칳ch se zachov치n칤m informa캜n칤 hodnoty
        - Vizualizace v칤cerozm캩rn칳ch dat ve 2D prostoru
        - Identifikace hlavn칤ch sm캩r콢 variability v datech
        
        ### Clustering
        Shlukov치n칤 podobn칳ch dat do skupin pomoc칤 algoritm콢 strojov칠ho u캜en칤.
        
        **Jak to pom치h치:**
        - Segmentace dat do p콏irozen칳ch skupin
        - Identifikace podobn칳ch vzor콢 v datech
        - Anal칳za profilu jednotliv칳ch shluk콢
        
        ### Statistick칠 testy
        R콢zn칠 statistick칠 testy pro ov캩콏en칤 hypot칠z o datech.
        
        **Jak to pom치h치:**
        - Testov치n칤 normality distribuce
        - Ov캩콏en칤 v칳znamnosti rozd칤l콢 mezi skupinami
        - Testov치n칤 nez치vislosti kategorick칳ch prom캩nn칳ch
        
        ### N치vrhy 칰prav
        Doporu캜en칤 pro transformaci a p콏칤pravu dat pro dal코칤 anal칳zu.
        
        **Jak to pom치h치:**
        - Identifikace potenci치ln칤ch transformac칤 pro zlep코en칤 distribuce
        - Doporu캜en칤 pro k칩dov치n칤 kategorick칳ch prom캩nn칳ch
        - Strategie pro 콏e코en칤 probl칠m콢 s kvalitou dat
        
        ### Rychl칠 modelov치n칤
        Automatick칠 vytvo콏en칤 prediktivn칤ho modelu na z치klad캩 vybran칳ch dat.
        
        **Jak to pom치h치:**
        - Rychl칠 otestov치n칤 prediktivn칤 s칤ly prom캩nn칳ch
        - Identifikace nejd콢le쬴t캩j코칤ch prediktor콢
        - Z치kladn칤 evaluace v칳konnosti modelu
        """)
    
    # Byznys anal칳za
    with st.expander("Byznys anal칳za", expanded=False):
        st.markdown("""
        ### 캛asov칠 콏ady
        Anal칳za dat v pr콢b캩hu 캜asu, identifikace trend콢 a sez칩nnosti.
        
        **Jak to pom치h치:**
        - Vizualizace trend콢 v 캜ase
        - Detekce sez칩nn칤ch vzor콢
        - Anal칳za r콢stu nebo poklesu metrik
        
        ### Cross tabulky
        Anal칳za vztah콢 mezi kategorick칳mi prom캩nn칳mi pomoc칤 kontingen캜n칤ch tabulek.
        
        **Jak to pom치h치:**
        - Pochopen칤 souvislost칤 mezi kategoriemi
        - Testov치n칤 nez치vislosti kategorick칳ch prom캩nn칳ch
        - Vizualizace rozlo쬰n칤 hodnot mezi kategoriemi
        
        ### KPI dashboard
        Vytvo콏en칤 p콏ehledov칠ho dashboardu s kl칤캜ov칳mi ukazateli v칳konnosti.
        
        **Jak to pom치h치:**
        - Sledov치n칤 nejd콢le쬴t캩j코칤ch metrik na jednom m칤st캩
        - Porovn치n칤 v칳konnosti v콢캜i c칤l콢m
        - Vizualizace kl칤캜ov칳ch ukazatel콢
        
        ### Kohortn칤 anal칳za
        Sledov치n칤 chov치n칤 skupin u쬴vatel콢 v pr콢b캩hu 캜asu.
        
        **Jak to pom치h치:**
        - Anal칳za retence u쬴vatel콢
        - Porovn치n칤 v칳konnosti r콢zn칳ch kohort
        - Identifikace dlouhodob칳ch trend콢 v chov치n칤 u쬴vatel콢
        """)
    
    # Tipy a triky
    st.subheader("Tipy a triky")
    
    st.markdown("""
    <div class="card yellow">
        <h4>Osv캩d캜en칠 postupy p콏i anal칳ze dat</h4>
        <ul>
            <li><strong>V쬯y za캜n캩te pr콢zkumem dat</strong> - pou쬴jte "P콏ehled dat" k pochopen칤 z치kladn칤 struktury dat</li>
            <li><strong>Zkontrolujte kvalitu dat</strong> - v캩nujte pozornost chyb캩j칤c칤m hodnot치m a odlehl칳m hodnot치m</li>
            <li><strong>Vizualizujte p콏ed modelov치n칤m</strong> - pou쬴jte distribu캜n칤 a korela캜n칤 anal칳zy p콏ed pokro캜il칳mi metodami</li>
            <li><strong>Interpretujte, nejen po캜칤tejte</strong> - ka쬯치 anal칳za by m캩la v칠st k pochopen칤 a akci</li>
            <li><strong>Iterujte</strong> - 캜asto je pot콏eba vyzkou코et v칤ce p콏칤stup콢 a metod</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # P콏칤klady pou쬴t칤
    st.subheader("P콏칤klady pou쬴t칤")
    
    tab1, tab2, tab3 = st.tabs(["Marketingov치 anal칳za", "Finan캜n칤 anal칳za", "Opera캜n칤 anal칳za"])
    
    with tab1:
        st.markdown("""
        ### Marketingov치 anal칳za
        
        **Sc칠n치콏:** Anal칳za v칳konnosti marketingov칳ch kampan칤
        
        **Doporu캜en칳 postup:**
        1. **Nahr치n칤 dat** - importujte data o kampan칤ch
        2. **P콏ehled dat** - z칤skejte rychl칳 n치hled na strukturu a kvalitu dat
        3. **Distribuce** - analyzujte rozlo쬰n칤 v칳konnostn칤ch metrik
        4. **Korelace** - identifikujte vztahy mezi v칳daji a v칳sledky
        5. **캛asov칠 콏ady** - sledujte v칳konnost kampan칤 v 캜ase
        6. **KPI dashboard** - vytvo콏te p콏ehled kl칤캜ov칳ch metrik
        
        **O캜ek치van칠 v칳stupy:**
        - Kter칠 kan치ly maj칤 nejvy코코칤 ROI
        - Jak se v칳konnost kampan칤 m캩n칤 v 캜ase
        - Jak칠 faktory nejv칤ce ovliv켿uj칤 칰sp캩코nost kampan칤
        """)
    
    with tab2:
        st.markdown("""
        ### Finan캜n칤 anal칳za
        
        **Sc칠n치콏:** Anal칳za finan캜n칤ch v칳sledk콢 a progn칩za
        
        **Doporu캜en칳 postup:**
        1. **Nahr치n칤 dat** - importujte finan캜n칤 data
        2. **P콏ehled dat** - zkontrolujte strukturu dat
        3. **캛asov칠 콏ady** - analyzujte finan캜n칤 ukazatele v 캜ase
        4. **Odlehl칠 hodnoty** - identifikujte neobvykl칠 finan캜n칤 v칳kyvy
        5. **Statistick칠 testy** - prove캞te testy pro ov캩콏en칤 hypot칠z
        6. **Rychl칠 modelov치n칤** - vytvo콏te prediktivn칤 model pro progn칩zu
        
        **O캜ek치van칠 v칳stupy:**
        - Trendy v p콏칤jmech a v칳daj칤ch
        - Identifikace anom치li칤 ve finan캜n칤ch datech
        - Predikce budouc칤ch finan캜n칤ch v칳sledk콢
        """)
    
    with tab3:
        st.markdown("""
        ### Opera캜n칤 anal칳za
        
        **Sc칠n치콏:** Optimalizace provozn칤ch proces콢
        
        **Doporu캜en칳 postup:**
        1. **Nahr치n칤 dat** - importujte opera캜n칤 data
        2. **P콏ehled dat** - z칤skejte p콏ehled o datech
        3. **Distribuce** - analyzujte rozlo쬰n칤 opera캜n칤ch metrik
        4. **Odlehl칠 hodnoty** - identifikujte problematick칠 procesy
        5. **Clustering** - seskupte podobn칠 procesy
        6. **Cross tabulky** - analyzujte vztahy mezi kategoriemi
        
        **O캜ek치van칠 v칳stupy:**
        - Identifikace 칰zk칳ch m칤st v procesech
        - Segmentace proces콢 podle v칳konnosti
        - Vztahy mezi r콢zn칳mi opera캜n칤mi faktory
        """)
    
    # Kontakt a podpora
    st.subheader("Kontakt a podpora")
    
    st.markdown("""
    <div class="card">
        <p>Pro v칤ce informac칤 nebo podporu kontaktujte:</p>
        <p><strong>Email:</strong> podporadata@golemio.cz</p>
        <p><strong>Dokumentace:</strong> <a href="https://golemio.cz/docs" target="_blank">https://golemio.cz/docs</a></p>
    </div>
    """, unsafe_allow_html=True)

def main():
    st.set_page_config(page_title="OICT Auto EDA", layout="wide")
    aplikuj_oict_styl()
    
    st.markdown("""
    <div class="title-container animate-fadeIn">
        <h1>Golemio Auto EDA</h1>
        <p class="subtitle">Automatick치 explorativn칤 anal칳za dat</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize session state
    if "active_section" not in st.session_state:
        st.session_state.active_section = "zakladni"
    
    # Use the modern navigation
    aktivni_sekce, stranka = create_navigation()
    
    # Initialize data session state
    if "data" not in st.session_state:
        st.session_state.data = None
    if "eda" not in st.session_state:
        st.session_state.eda = None
    
    # Main content area
    with st.container():
        # Display the appropriate page based on navigation
        if aktivni_sekce == "zakladni":
            if stranka == "Nahr치n칤 dat":
                zobraz_nahrani_dat()
            elif st.session_state.data is not None and st.session_state.eda is not None:
                if stranka == "P콏ehled dat":
                    zobraz_prehled_dat()
                elif stranka == "Chyb캩j칤c칤 hodnoty":
                    zobraz_chybejici_hodnoty()
                elif stranka == "Distribuce":
                    zobraz_distribuce()
                elif stranka == "Korelace":
                    zobraz_korelace()
                elif stranka == "Odlehl칠 hodnoty":
                    zobraz_odlehle_hodnoty()
            else:
                st.warning("Pros칤m, nejprve nahrajte data")
                zobraz_nahrani_dat()
        
        elif aktivni_sekce == "pokrocile":
            if st.session_state.data is not None and st.session_state.eda is not None:
                if stranka == "Redukce dimenz칤":
                    zobraz_pca()
                elif stranka == "Clustering":
                    zobraz_clustering()
                elif stranka == "Statistick칠 testy":
                    zobraz_statisticke_testy()
                elif stranka == "N치vrhy 칰prav":
                    zobraz_navrhy_uprav()
                elif stranka == "Rychl칠 modelov치n칤":
                    zobraz_rychle_modelovani()
            else:
                st.warning("Pros칤m, nejprve nahrajte data")
                zobraz_nahrani_dat()
        
        elif aktivni_sekce == "byznys":
            if st.session_state.data is not None and st.session_state.eda is not None:
                if stranka == "캛asov칠 콏ady":
                    zobraz_casove_rady()
                elif stranka == "Cross tabulky":
                    zobraz_cross_tabulky()
                elif stranka == "KPI dashboard":
                    zobraz_kpi_dashboard()
                elif stranka == "Kohortn칤 anal칳za":
                    zobraz_kohortni_analyza()
            else:
                st.warning("Pros칤m, nejprve nahrajte data")
                zobraz_nahrani_dat()
        
        elif aktivni_sekce == "porovnani":
            if stranka == "Filtrace dat":
                zobraz_data_filtering()
            elif stranka == "Porovn치n칤 dataset콢":
                zobraz_data_comparison()
            else:
                zobraz_data_filtering()
        
        else:  # o aplikaci
            zobraz_o_aplikaci()
    
    # Footer with Golemio logo
    st.markdown("""
    <footer>
        <div style="display: flex; justify-content: center; align-items: center; margin-bottom: 15px;">
            <p style="margin-right: 15px;">Powered by <span class="footer-brand">OICT</span></p>
        </div>
        <div style="text-align: center; margin-bottom: 15px;">
           </div>
        <p>춸 2025 Vytvo콏eno s 仇벒잺 v Praze</p>
    </footer>
    """, unsafe_allow_html=True)

def create_navigation():
    """Create a modern navigation system in the sidebar with vertical layout"""
    
    with st.sidebar:
        # Logo header
        st.markdown("""
        <div style="text-align: center; padding: 25px 0; margin-bottom: 25px; border-bottom: 1px solid #eaeaea;">
            <h2 style="color: #574494; margin: 12px 0 0 0; font-size: 1.5rem; font-weight: 700;">
                Golemio AutoEDA
            </h2>
            <div style="width: 40px; height: 3px; background: linear-gradient(90deg, #574494 0%, #FFE14F 100%); margin: 12px auto;"></div>
        </div>
        """, unsafe_allow_html=True)
        
        # Main navigation using visual selectors instead of radio buttons
        st.markdown("### Navigace")
        
        # Use session state to track the active section
        if "active_section" not in st.session_state:
            st.session_state.active_section = "zakladni"
        
        # Create visual section buttons
        sections = {
            "zakladni": {"name": "Z치kladn칤 anal칳za", "icon": "游늵", "color": "#574494"},
            "pokrocile": {"name": "Pokro캜il치 anal칳za", "icon": "游", "color": "#E37222"},
            "byznys": {"name": "Byznys anal칳za", "icon": "游눺", "color": "#74ECA1"},
            "porovnani": {"name": "Porovn치n칤 a filtrace", "icon": "游댌", "color": "#FFE14F"},
            "o_aplikaci": {"name": "O aplikaci", "icon": "좶잺", "color": "#FFE14F"}
        }
        
        # Create modern section selector tiles
        st.markdown("""
        <style>
        .section-tile {
            display: block;
            padding: 14px 16px;
            margin-bottom: 10px;
            border-radius: 8px;
            transition: all 0.2s ease;
            text-decoration: none;
            color: #333;
            background: white;
            border-left: 5px solid transparent;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }
        .section-tile:hover {
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.15);
            transform: translateX(2px);
        }
        .section-tile.active {
            border-left-width: 5px;
            font-weight: bold;
            background: #f8f9fa;
        }
        .section-icon {
            display: inline-block;
            margin-right: 10px;
            font-size: 1.2rem;
        }
        </style>
        """, unsafe_allow_html=True)
        
        for section_id, section_info in sections.items():
            is_active = st.session_state.active_section == section_id
            
            # Create the HTML for the section tile
            html = f"""
            <div class="section-tile{'  active' if is_active else ''}" 
                 style="border-left-color: {section_info['color']};">
                <span class="section-icon">{section_info['icon']}</span>
                {section_info['name']}
            </div>
            """
            
            # Use a button with a unique key
            if st.markdown(html, unsafe_allow_html=True):
                pass  # Markdown doesn't have click events, we'll use buttons below
            
            # The actual button - invisible but clickable, placed on top of the HTML
            if st.button(section_info['name'], key=f"btn_{section_id}", 
                       use_container_width=True, 
                       type="secondary" if is_active else "secondary",
            ):
                st.session_state.active_section = section_id
                # Reset subsection when changing main section
                if section_id == "zakladni":
                    st.session_state.zakladni_stranka = "Nahr치n칤 dat"
                elif section_id == "pokrocile":
                    st.session_state.pokrocile_stranka = "Redukce dimenz칤"
                elif section_id == "byznys":
                    st.session_state.byznys_stranka = "캛asov칠 콏ady"
                elif section_id == "porovnani":
                    st.session_state.porovnani_stranka = "Filtrace dat"
                st.rerun()
        
        # Divider
        st.markdown("<hr style='margin: 20px 0;'>", unsafe_allow_html=True)
        
        # Get the active section for subsection navigation
        aktivni_sekce = st.session_state.active_section
        
        # Subsection navigation with vertical buttons
        if aktivni_sekce == "zakladni":
            st.markdown("""
            <div style="margin-bottom: 15px;">
                <h3 style="color: #574494; display: flex; align-items: center;">
                    <span style="margin-right: 8px;">游늵</span> Z치kladn칤 anal칳za
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize subsection if not in session state
            if "zakladni_stranka" not in st.session_state:
                st.session_state.zakladni_stranka = "Nahr치n칤 dat"
            
            # Define subsections
            subsections = [
                {"id": "Nahr치n칤 dat", "icon": "游닋", "name": "Nahr치n칤 dat"},
                {"id": "P콏ehled dat", "icon": "游늶", "name": "P콏ehled dat"},
                {"id": "Chyb캩j칤c칤 hodnoty", "icon": "仇", "name": "Chyb캩j칤c칤 hodnoty"},
                {"id": "Distribuce", "icon": "游늳", "name": "Distribuce"},
                {"id": "Korelace", "icon": "游댃", "name": "Korelace"},
                {"id": "Odlehl칠 hodnoty", "icon": "丘멆잺", "name": "Odlehl칠 hodnoty"}
            ]
            
            # Create vertical buttons for subsections
            for subsection in subsections:
                is_active = st.session_state.zakladni_stranka == subsection["id"]
                
                # Create button with icon
                button_text = f"{subsection['icon']} {subsection['name']}"
                
                if st.button(button_text, key=f"btn_basic_{subsection['id']}",
                           use_container_width=True,
                           type="primary" if is_active else "secondary"):
                    st.session_state.zakladni_stranka = subsection["id"]
                    st.rerun()
            
            stranka = st.session_state.zakladni_stranka
            
        elif aktivni_sekce == "pokrocile":
            st.markdown("""
            <div style="margin-bottom: 15px;">
                <h3 style="color: #E37222; display: flex; align-items: center;">
                    <span style="margin-right: 8px;">游</span> Pokro캜il치 anal칳za
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize subsection if not in session state
            if "pokrocile_stranka" not in st.session_state:
                st.session_state.pokrocile_stranka = "Redukce dimenz칤"
            
            # Define subsections
            subsections = [
                {"id": "Redukce dimenz칤", "icon": "游빌", "name": "Redukce dimenz칤"},
                {"id": "Clustering", "icon": "游댌", "name": "Clustering"},
                {"id": "Statistick칠 testy", "icon": "游댧", "name": "Statistick칠 testy"},
                {"id": "N치vrhy 칰prav", "icon": "游멆잺", "name": "N치vrhy 칰prav"},
                {"id": "Rychl칠 modelov치n칤", "icon": "游뱄", "name": "Rychl칠 modelov치n칤"}
            ]
            
            # Create vertical buttons for subsections
            for subsection in subsections:
                is_active = st.session_state.pokrocile_stranka == subsection["id"]
                
                # Create button with icon
                button_text = f"{subsection['icon']} {subsection['name']}"
                
                if st.button(button_text, key=f"btn_adv_{subsection['id']}",
                           use_container_width=True,
                           type="primary" if is_active else "secondary"):
                    st.session_state.pokrocile_stranka = subsection["id"]
                    st.rerun()
            
            stranka = st.session_state.pokrocile_stranka
            
        elif aktivni_sekce == "byznys":
            st.markdown("""
            <div style="margin-bottom: 15px;">
                <h3 style="color: #74ECA1; display: flex; align-items: center;">
                    <span style="margin-right: 8px;">游눺</span> Byznys anal칳za
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize subsection if not in session state
            if "byznys_stranka" not in st.session_state:
                st.session_state.byznys_stranka = "캛asov칠 콏ady"
            
            # Define subsections
            subsections = [
                {"id": "캛asov칠 콏ady", "icon": "游늰", "name": "캛asov칠 콏ady"},
                {"id": "Cross tabulky", "icon": "游늵", "name": "Cross tabulky"},
                {"id": "KPI dashboard", "icon": "游꿢", "name": "KPI dashboard"},
                {"id": "Kohortn칤 anal칳za", "icon": "游논", "name": "Kohortn칤 anal칳za"}
            ]
            
            # Create vertical buttons for subsections
            for subsection in subsections:
                is_active = st.session_state.byznys_stranka == subsection["id"]
                
                # Create button with icon
                button_text = f"{subsection['icon']} {subsection['name']}"
                
                if st.button(button_text, key=f"btn_biz_{subsection['id']}",
                           use_container_width=True,
                           type="primary" if is_active else "secondary"):
                    st.session_state.byznys_stranka = subsection["id"]
                    st.rerun()
            
            stranka = st.session_state.byznys_stranka

        elif aktivni_sekce == "porovnani":
            st.markdown("""
            <div style="margin-bottom: 15px;">
                <h3 style="color: #FFE14F; display: flex; align-items: center;">
                    <span style="margin-right: 8px;">游댌</span> Porovn치n칤 a filtrace
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Initialize subsection if not in session state
            if "porovnani_stranka" not in st.session_state:
                st.session_state.porovnani_stranka = "Filtrace dat"
            
            # Define subsections
            subsections = [
                {"id": "Filtrace dat", "icon": "游댌", "name": "Filtrace dat"},
                {"id": "Porovn치n칤 dataset콢", "icon": "丘뒲잺", "name": "Porovn치n칤 dataset콢"},
            ]
            
            # Create vertical buttons for subsections
            for subsection in subsections:
                is_active = st.session_state.porovnani_stranka == subsection["id"]
                
                # Create button with icon
                button_text = f"{subsection['icon']} {subsection['name']}"
                
                if st.button(button_text, key=f"btn_comp_{subsection['id']}",
                           use_container_width=True,
                           type="primary" if is_active else "secondary"):
                    st.session_state.porovnani_stranka = subsection["id"]
                    st.rerun()
            
            stranka = st.session_state.porovnani_stranka
            
        else:  # o aplikaci
            st.markdown("""
            <div style="margin-bottom: 15px;">
                <h3 style="color: #FFE14F; display: flex; align-items: center;">
                    <span style="margin-right: 8px;">좶잺</span> O aplikaci
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            stranka = "O aplikaci"
               
    return aktivni_sekce, stranka

def create_section_header(section_title, icon="游늵", description=None):
    """Create a modern section header with icon and optional description"""
    st.markdown(f"""
    <div style="padding: 1rem 0 0.5rem 0; margin-bottom: 1rem;">
        <h1>{icon} {section_title}</h1>
        {f'<p style="color: #666; font-size: 1.1rem; margin-top: 0.5rem;">{description}</p>' if description else ''}
    </div>
    """, unsafe_allow_html=True)
    
def create_dashboard_card(title, value, delta=None, color="#574494", icon=None):
    """Create a modern dashboard metric card with title, value, and optional delta"""
    delta_html = ""
    if delta is not None:
        delta_color = "green" if delta >= 0 else "red"
        delta_icon = "" if delta >= 0 else ""
        delta_html = f'<div style="color: {delta_color}; font-size: 0.9rem; margin-top: 0.25rem;">{delta_icon} {abs(delta):.1f}%</div>'
    
    icon_html = f'<div style="font-size: 1.5rem; margin-bottom: 0.5rem;">{icon}</div>' if icon else ''
    
    st.markdown(f"""
    <div style="background-color: white; border-radius: 0.75rem; padding: 1.25rem; box-shadow: 0 0.125rem 0.25rem rgba(0, 0, 0, 0.075); 
                border-top: 3px solid {color}; text-align: center; height: 100%;">
        {icon_html}
        <div style="font-size: 0.875rem; color: #666; text-transform: uppercase; letter-spacing: 0.05em; margin-bottom: 0.5rem;">{title}</div>
        <div style="font-size: 1.75rem; font-weight: 700; color: #333;">{value}</div>
        {delta_html}
    </div>
    """, unsafe_allow_html=True)
    
def create_metric_row(metrics):
    """Create a row of metric cards
    
    Parameters:
    metrics (list): List of dicts with keys: title, value, delta (optional), color (optional), icon (optional)
    """
    cols = st.columns(len(metrics))
    for i, metric in enumerate(metrics):
        with cols[i]:
            create_dashboard_card(
                title=metric['title'],
                value=metric['value'],
                delta=metric.get('delta'),
                color=metric.get('color', "#574494"),
                icon=metric.get('icon')
            )

def create_tab_navigation(tabs_dict, key_prefix="tab_nav"):
    """Create a modern tab navigation
    
    Parameters:
    tabs_dict (dict): Dict with tab names as keys and tab contents (callable functions) as values
    key_prefix (str): Prefix for session state keys to avoid conflicts
    
    Returns:
    str: The selected tab name
    """
    # Generate a unique key for this tab navigation
    state_key = f"{key_prefix}_selected"
    
    # Initialize the selected tab if not present
    if state_key not in st.session_state:
        st.session_state[state_key] = list(tabs_dict.keys())[0]
    
    # Create tab-style buttons
    cols = st.columns(len(tabs_dict))
    
    for i, (tab_name, _) in enumerate(tabs_dict.items()):
        # Determine if this tab is selected
        is_selected = st.session_state[state_key] == tab_name
        button_style = "primary" if is_selected else "secondary"
        
        # Create the button
        if cols[i].button(tab_name, key=f"{key_prefix}_{i}", 
                         use_container_width=True, type=button_style):
            st.session_state[state_key] = tab_name
            st.rerun()
    
    # Add a separator
    st.markdown('<hr style="margin: 0.5rem 0 1.5rem 0; border: none; height: 1px; background-color: #f0f0f0;">', 
              unsafe_allow_html=True)
    
    # Return the selected tab
    return st.session_state[state_key]

def create_modern_radio(label, options, default=None, horizontal=True, key=None):
    """Create a more modern-looking radio button alternative using buttons
    
    Parameters:
    label (str): The label for the radio group
    options (list): List of options
    default (str): Default selected option
    horizontal (bool): Whether to display horizontally
    key (str): Unique key for session state
    
    Returns:
    str: The selected option
    """
    if key not in st.session_state:
        st.session_state[key] = default if default else options[0]
    
    st.markdown(f"**{label}**")
    
    # Create columns if horizontal
    if horizontal:
        cols = st.columns(len(options))
    else:
        # For vertical, create a single column for each option
        cols = [st for _ in range(len(options))]
    
    for i, option in enumerate(options):
        is_selected = st.session_state[key] == option
        button_style = "primary" if is_selected else "secondary"
        
        if cols[i].button(option, key=f"{key}_{i}", 
                         use_container_width=True, 
                         type=button_style):
            st.session_state[key] = option
            st.rerun()
    
    return st.session_state[key]

def zobraz_nahrani_dat():
    create_section_header("Nahr치n칤 dat", icon="游닋", 
                         description="Importujte data z r콢zn칳ch zdroj콢")
    
    # Create tabs for different data sources
    source_tabs = st.tabs(["游늬 Soubor", "游깷 API", "游 Uk치zkov칠 datasety"])
    
    with source_tabs[0]:  # File upload tab
        # Sub-tabs for different file types
        file_tabs = st.tabs(["CSV/Excel", "JSON", "Parquet"])
        
        with file_tabs[0]:  # CSV/Excel
            col1, col2 = st.columns([2, 1])
            
            with col1:
                uploaded_file = st.file_uploader(
                    "Vyberte CSV nebo Excel soubor", 
                    type=["csv", "xlsx", "xls"], 
                    label_visibility="collapsed"
                )
                
                if uploaded_file is not None:
                    try:
                        # Options for CSV/Excel
                        with st.expander("Nastaven칤 importu", expanded=False):
                            if uploaded_file.name.endswith('.csv'):
                                separator = st.text_input("Odd캩lova캜", value=",")
                                encoding = st.selectbox("K칩dov치n칤", 
                                                      options=["utf-8", "iso-8859-1", "windows-1250", "latin1", "latin2"],
                                                      index=0)
                            else:  # Excel
                                sheet_name = st.text_input("N치zev listu (ponechte pr치zdn칠 pro prvn칤 list)", value="")
                        
                        # Load the data
                        if uploaded_file.name.endswith('.csv'):
                            data = pd.read_csv(uploaded_file, sep=separator, encoding=encoding)
                        else:
                            if sheet_name.strip():
                                data = pd.read_excel(uploaded_file, sheet_name=sheet_name)
                            else:
                                data = pd.read_excel(uploaded_file)
                        
                        # Set session state
                        st.session_state.data = data
                        st.session_state.eda = EDA(data)
                        
                        st.success(f"九 칔sp캩코n캩 nahr치no {data.shape[0]} 콏치dk콢 a {data.shape[1]} sloupc콢")
                        
                    except Exception as e:
                        st.error(f"Chyba: {str(e)}")
            
            with col2:
                st.markdown("""
                <div class="card">
                    <h4>CSV a Excel</h4>
                    <ul>
                        <li>CSV (.csv)</li>
                        <li>Excel (.xlsx, .xls)</li>
                    </ul>
                    <p>Podporuje r콢zn칠 odd캩lova캜e a k칩dov치n칤.</p>
                </div>
                """, unsafe_allow_html=True)
        
        with file_tabs[1]:  # JSON
            col1, col2 = st.columns([2, 1])
            
            with col1:
                uploaded_json = st.file_uploader(
                    "Vyberte JSON soubor", 
                    type=["json"], 
                    label_visibility="collapsed",
                    key="json_uploader"
                )
                
                if uploaded_json is not None:
                    try:
                        # Options for JSON
                        with st.expander("Nastaven칤 importu", expanded=False):
                            orient = st.selectbox(
                                "Orientace JSON", 
                                options=["records", "split", "index", "columns", "values"],
                                index=0,
                                help="Ur캜uje strukturu JSON dat."
                            )
                            lines = st.checkbox("JSON Lines form치t", value=False, 
                                             help="Za코krtn캩te, pokud ka쬯칳 콏치dek je samostatn칳 JSON objekt.")
                        
                        # Load the data
                        if lines:
                            data = pd.read_json(uploaded_json, lines=True)
                        else:
                            data = pd.read_json(uploaded_json, orient=orient)
                        
                        # Normalizace nested JSON
                        if st.checkbox("Normalizovat vno콏en치 JSON data", value=False,
                                    help="Rozbal칤 vno콏en칠 JSON objekty do samostatn칳ch sloupc콢"):
                            # Find columns that contain lists or dicts
                            complex_columns = []
                            for col in data.columns:
                                if data[col].dtype == 'object':
                                    if any(isinstance(x, (dict, list)) for x in data[col].dropna()):
                                        complex_columns.append(col)
                            
                            if complex_columns:
                                col_to_normalize = st.selectbox("Vyberte sloupec pro normalizaci", complex_columns)
                                try:
                                    # Normalize the selected column
                                    normalized = pd.json_normalize(data[col_to_normalize])
                                    # Create prefixed column names to avoid duplicates
                                    normalized.columns = [f"{col_to_normalize}.{c}" for c in normalized.columns]
                                    # Drop the original column and join the normalized data
                                    data = data.drop(columns=[col_to_normalize]).reset_index(drop=True)
                                    data = pd.concat([data, normalized], axis=1)
                                except Exception as e:
                                    st.warning(f"Nelze normalizovat sloupec: {str(e)}")
                        
                        # Set session state
                        st.session_state.data = data
                        st.session_state.eda = EDA(data)
                        
                        st.success(f"九 칔sp캩코n캩 nahr치no {data.shape[0]} 콏치dk콢 a {data.shape[1]} sloupc콢")
                        
                    except Exception as e:
                        st.error(f"Chyba p콏i na캜칤t치n칤 JSON: {str(e)}")
            
            with col2:
                st.markdown("""
                <div class="card">
                    <h4>JSON form치t</h4>
                    <p>Podporuje:</p>
                    <ul>
                        <li>Standardn칤 JSON</li>
                        <li>JSON Lines (.jsonl)</li>
                        <li>Vno콏en칠 objekty</li>
                        <li>R콢zn칠 orientace</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
        
        with file_tabs[2]:  # Parquet
            col1, col2 = st.columns([2, 1])
            
            with col1:
                uploaded_parquet = st.file_uploader(
                    "Vyberte Parquet soubor", 
                    type=["parquet", "pq"], 
                    label_visibility="collapsed",
                    key="parquet_uploader"
                )
                
                if uploaded_parquet is not None:
                    try:
                        # Check if pyarrow is installed
                        try:
                            import pyarrow.parquet as pq
                            has_pyarrow = True
                        except ImportError:
                            has_pyarrow = False
                            st.warning("Knihovna PyArrow nen칤 nainstalov치na. Zkus칤me na캜칤st pomoc칤 fastparquet.")
                        
                        # Options for Parquet
                        with st.expander("Nastaven칤 importu", expanded=False):
                            engine = "pyarrow" if has_pyarrow else "fastparquet"
                            st.info(f"Pou쬴t칳 engine: {engine}")
                            
                            # If using PyArrow, allow column selection
                            if has_pyarrow:
                                # Create a temporary file to analyze
                                import tempfile
                                with tempfile.NamedTemporaryFile(delete=False, suffix='.parquet') as tmp:
                                    tmp.write(uploaded_parquet.getvalue())
                                    tmp_path = tmp.name
                                
                                # Get schema
                                table = pq.read_table(tmp_path)
                                all_columns = table.column_names
                                
                                # Let user select columns
                                selected_columns = st.multiselect(
                                    "Vyberte sloupce (ponechte pr치zdn칠 pro v코echny)",
                                    options=all_columns,
                                    default=[]
                                )
                            else:
                                selected_columns = None
                        
                        # Load the data
                        if selected_columns:
                            data = pd.read_parquet(uploaded_parquet, engine=engine, columns=selected_columns)
                        else:
                            data = pd.read_parquet(uploaded_parquet, engine=engine)
                        
                        # Set session state
                        st.session_state.data = data
                        st.session_state.eda = EDA(data)
                        
                        st.success(f"九 칔sp캩코n캩 nahr치no {data.shape[0]} 콏치dk콢 a {data.shape[1]} sloupc콢")
                        
                    except Exception as e:
                        st.error(f"Chyba p콏i na캜칤t치n칤 Parquet: {str(e)}")
            
            with col2:
                st.markdown("""
                <div class="card">
                    <h4>Parquet form치t</h4>
                    <p>Vysoce v칳konn칳 sloupcov칳 form치t. Podporuje:</p>
                    <ul>
                        <li>Efektivn칤 komprese</li>
                        <li>Rychl칠 na캜칤t치n칤</li>
                        <li>V칳b캩r sloupc콢</li>
                    </ul>
                    <p><em>Vy쬬duje PyArrow nebo fastparquet</em></p>
                </div>
                """, unsafe_allow_html=True)
    
    with source_tabs[1]:  # API Connection
        st.markdown("""
        <div class="card primary">
            <h4>Na캜ten칤 dat z API</h4>
            <p>P콏ipojte se k REST API a importujte data p콏칤mo do aplikace.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # API connection form
        with st.container():
            api_url = st.text_input("URL API", placeholder="https://api.example.com/data")
            
            # API Method & Auth
            col1, col2 = st.columns(2)
            with col1:
                api_method = st.selectbox(
                    "HTTP Metoda", 
                    options=["GET", "POST"],
                    index=0
                )
            
            with col2:
                api_auth_type = st.selectbox(
                    "Autentizace", 
                    options=["콯치dn치", "API Key", "Bearer Token", "Basic Auth"],
                    index=0
                )
            
            # Show auth fields based on selected type
            if api_auth_type == "API Key":
                col1, col2 = st.columns(2)
                with col1:
                    api_key_name = st.text_input("N치zev API kl칤캜e", value="api-key")
                with col2:
                    api_key_value = st.text_input("Hodnota API kl칤캜e", type="password")
                api_key_location = st.radio("Um칤st캩n칤 API kl칤캜e", ["Header", "Query Parameter"], horizontal=True)
            
            elif api_auth_type == "Bearer Token":
                bearer_token = st.text_input("Bearer Token", type="password")
            
            elif api_auth_type == "Basic Auth":
                col1, col2 = st.columns(2)
                with col1:
                    basic_username = st.text_input("U쬴vatelsk칠 jm칠no")
                with col2:
                    basic_password = st.text_input("Heslo", type="password")
            
            # Advanced options with expander
            with st.expander("Pokro캜il칠 nastaven칤"):
                # Headers
                st.subheader("HTTP Hlavi캜ky")
                add_headers = st.checkbox("P콏idat vlastn칤 hlavi캜ky", value=False)
                headers = {}
                
                if add_headers:
                    header_count = st.number_input("Po캜et hlavi캜ek", min_value=1, max_value=10, value=1)
                    for i in range(int(header_count)):
                        col1, col2 = st.columns(2)
                        with col1:
                            header_name = st.text_input(f"N치zev hlavi캜ky {i+1}", key=f"header_name_{i}")
                        with col2:
                            header_value = st.text_input(f"Hodnota hlavi캜ky {i+1}", key=f"header_value_{i}")
                        if header_name:
                            headers[header_name] = header_value
                
                # Request body for POST
                if api_method == "POST":
                    st.subheader("T캩lo po쬬davku")
                    body_type = st.radio("Typ t캩la", ["JSON", "Form Data"], horizontal=True)
                    
                    if body_type == "JSON":
                        request_body = st.text_area("JSON t캩lo", value="{}")
                    else:  # Form Data
                        form_count = st.number_input("Po캜et parametr콢", min_value=1, max_value=10, value=1)
                        form_data = {}
                        for i in range(int(form_count)):
                            col1, col2 = st.columns(2)
                            with col1:
                                form_name = st.text_input(f"N치zev parametru {i+1}", key=f"form_name_{i}")
                            with col2:
                                form_value = st.text_input(f"Hodnota parametru {i+1}", key=f"form_value_{i}")
                            if form_name:
                                form_data[form_name] = form_value
                
                # Response options
                st.subheader("Nastaven칤 odpov캩di")
                json_path = st.text_input("JSON cesta k dat콢m", 
                                        placeholder="data.results", 
                                        help="Cesta k dat콢m v JSON odpov캩di, nap콏. 'data.items'")
                flatten_nested = st.checkbox("Rozbalit vno콏en칠 objekty", value=True)
                normalize_arrays = st.checkbox("Normalizovat pole", value=True)
            
            # Execute API call
            if st.button("Na캜칤st data z API", type="primary", use_container_width=True):
                if not api_url:
                    st.error("Zadejte URL API endpoint-u")
                else:
                    try:
                        import requests
                        import json
                        
                        # Prepare request
                        request_kwargs = {"headers": {}}
                        
                        # Add authentication
                        if api_auth_type == "API Key":
                            if api_key_location == "Header":
                                request_kwargs["headers"][api_key_name] = api_key_value
                            else:  # Query Parameter
                                if "?" in api_url:
                                    api_url += f"&{api_key_name}={api_key_value}"
                                else:
                                    api_url += f"?{api_key_name}={api_key_value}"
                        
                        elif api_auth_type == "Bearer Token":
                            request_kwargs["headers"]["Authorization"] = f"Bearer {bearer_token}"
                        
                        elif api_auth_type == "Basic Auth":
                            from requests.auth import HTTPBasicAuth
                            request_kwargs["auth"] = HTTPBasicAuth(basic_username, basic_password)
                        
                        # Add custom headers
                        if headers:
                            request_kwargs["headers"].update(headers)
                        
                        # Add request body for POST
                        if api_method == "POST":
                            if body_type == "JSON":
                                request_kwargs["json"] = json.loads(request_body)
                            else:  # Form Data
                                request_kwargs["data"] = form_data
                        
                        # Make the request
                        with st.spinner("Odes칤l치m po쬬davek..."):
                            if api_method == "GET":
                                response = requests.get(api_url, **request_kwargs)
                            else:  # POST
                                response = requests.post(api_url, **request_kwargs)
                            
                            # Check status
                            response.raise_for_status()
                            
                            # Parse response
                            response_json = response.json()
                            
                            # Navigate to nested data if needed
                            if json_path:
                                try:
                                    path_parts = json_path.split('.')
                                    data_obj = response_json
                                    for part in path_parts:
                                        data_obj = data_obj[part]
                                    response_json = data_obj
                                except (KeyError, TypeError) as e:
                                    st.error(f"Chyba p콏i navigaci JSON cestou: {str(e)}")
                                    st.json(response_json)
                                    return
                            
                            # Convert to DataFrame
                            if isinstance(response_json, list):
                                data = pd.json_normalize(response_json) if flatten_nested else pd.DataFrame(response_json)
                            elif isinstance(response_json, dict):
                                if normalize_arrays:
                                    # Find list fields to normalize
                                    array_fields = [k for k, v in response_json.items() if isinstance(v, list)]
                                    if array_fields and len(array_fields) == 1:
                                        # If there's a single array field, normalize it
                                        data = pd.json_normalize(response_json[array_fields[0]]) if flatten_nested else pd.DataFrame(response_json[array_fields[0]])
                                    else:
                                        # Otherwise treat as a single record
                                        data = pd.json_normalize([response_json]) if flatten_nested else pd.DataFrame([response_json])
                                else:
                                    data = pd.json_normalize([response_json]) if flatten_nested else pd.DataFrame([response_json])
                            else:
                                st.error("Odpov캩캞 API nen칤 ve form치tu JSON listu nebo objektu")
                                st.write(response_json)
                                return
                            
                            # Set session state
                            st.session_state.data = data
                            st.session_state.eda = EDA(data)
                            
                            st.success(f"九 칔sp캩코n캩 na캜teno {data.shape[0]} 콏치dk콢 a {data.shape[1]} sloupc콢 z API")
                    
                    except requests.exceptions.RequestException as e:
                        st.error(f"Chyba po쬬davku API: {str(e)}")
                    except ValueError as e:
                        st.error(f"Chyba p콏i zpracov치n칤 JSON: {str(e)}")
                    except Exception as e:
                        st.error(f"Neo캜ek치van치 chyba: {str(e)}")
    
    with source_tabs[2]:  # Sample datasets
        st.markdown("### Vyberte uk치zkov칳 dataset")
        
        # Use cards for sample datasets with a more modern layout
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="card primary" style="height: 100%;">
                <h4>Iris kv캩tiny 游꺚</h4>
                <p>Klasick칳 dataset pro klasifikaci.</p>
                <p><strong>150 콏치dk콢, 5 sloupc콢</strong></p>
                <p>Obsahuje: d칠lku a 코칤콏ku okv캩tn칤ch l칤stk콢 a kali코n칤ch l칤stk콢, druh</p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t Iris dataset", key="load_iris", use_container_width=True):
                try:
                    from sklearn.datasets import load_iris
                    iris = load_iris()
                    data = pd.DataFrame(iris.data, columns=iris.feature_names)
                    data['target'] = iris.target
                    
                    st.session_state.data = data
                    st.session_state.eda = EDA(data)
                    
                    st.success("九 Nahr치n dataset Iris")
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
        
        with col2:
            st.markdown("""
            <div class="card orange" style="height: 100%;">
                <h4>Pasa쮂뽠뗠 Titanicu 游뚹</h4>
                <p>Dataset pro anal칳zu p콏e쬴t칤 pasa쮂r콢.</p>
                <p><strong>891 콏치dk콢, 12 sloupc콢</strong></p>
                <p>Obsahuje: v캩k, pohlav칤, t콏칤du, cenu l칤stku, p콏e쬴t칤</p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t Titanic dataset", key="load_titanic", use_container_width=True):
                try:
                    url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'
                    data = pd.read_csv(url)
                    
                    st.session_state.data = data
                    st.session_state.eda = EDA(data)
                    
                    st.success("九 Nahr치n dataset Titanicu")
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            <div class="card green" style="height: 100%;">
                <h4>Boston Housing 游</h4>
                <p>Dataset cen nemovitost칤.</p>
                <p><strong>506 콏치dk콢, 14 sloupc콢</strong></p>
                <p>Obsahuje: kriminalitu, po캜et pokoj콢, st치콏칤, vzd치lenosti</p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t Boston dataset", key="load_boston", use_container_width=True):
                try:
                    url = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'
                    data = pd.read_csv(url)
                    
                    st.session_state.data = data
                    st.session_state.eda = EDA(data)
                    
                    st.success("九 Nahr치n dataset Boston Housing")
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
        
        with col2:
            st.markdown("""
            <div class="card yellow" style="height: 100%;">
                <h4>COVID-19 Data 游</h4>
                <p>캛asov치 콏ada COVID p콏칤pad콢 a 칰mrt칤.</p>
                <p><strong>~200 zem칤, denn칤 data</strong></p>
                <p>Obsahuje: po캜ty p콏칤pad콢, 칰mrt칤, data podle zem칤</p>
            </div>
            """, unsafe_allow_html=True)
            if st.button("Nahr치t COVID dataset", key="load_covid", use_container_width=True):
                try:
                    url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'
                    data = pd.read_csv(url)
                    
                    st.session_state.data = data
                    st.session_state.eda = EDA(data)
                    
                    st.success("九 Nahr치n dataset COVID-19")
                    st.rerun()
                except Exception as e:
                    st.error(f"Chyba p콏i nahr치v치n칤 uk치zkov칠ho datasetu: {str(e)}")
    
    # Display preview if data exists
    if st.session_state.data is not None:
        st.markdown("---")
        st.subheader("N치hled dat")
        
        # Create tabs for different data views
        preview_tab1, preview_tab2, preview_tab3 = st.tabs(["Tabulka", "Informace", "Statistiky"])
        
        with preview_tab1:
            st.dataframe(st.session_state.data.head(10), use_container_width=True)
        
        with preview_tab2:
            buffer = io.StringIO()
            st.session_state.data.info(buf=buffer)
            st.text(buffer.getvalue())
        
        with preview_tab3:
            if len(st.session_state.eda.numeric_cols) > 0:
                st.dataframe(st.session_state.data[st.session_state.eda.numeric_cols].describe(), use_container_width=True)
            else:
                st.info("Nejsou k dispozici 쮂멳n칠 numerick칠 sloupce pro statistickou anal칳zu")
        
        # Quick analysis button
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("Spustit rychlou anal칳zu", type="primary", use_container_width=True):
                with st.spinner("Analyzuji data..."):
                    poznatky = st.session_state.eda.run_full_analysis()
                    st.success("Anal칳za dokon캜ena!")
                    st.subheader("Kl칤캜ov칠 poznatky")
                    
                    # Display insights in a card
                    insights_html = "<div class='insight-card'><ul>"
                    for poznatek in poznatky:
                        insights_html += f"<li>{poznatek}</li>"
                    insights_html += "</ul></div>"
                    
                    st.markdown(insights_html, unsafe_allow_html=True)
        
        with col2:
            if st.button("Pokra캜ovat na p콏ehled dat", type="primary", use_container_width=True):
                st.session_state.zakladni_stranka = "P콏ehled dat"
                st.rerun()
    
def zobraz_prehled_dat():
    st.header("P콏ehled dat")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Spustit anal칳zu, pokud je코t캩 nebyla provedena
    if not hasattr(eda, 'missing_analysis'):
        eda.analyze_missing_values()
    if not hasattr(eda, 'correlation_matrix') and len(eda.numeric_cols) >= 2:
        eda.analyze_correlations()
    if not hasattr(eda, 'outlier_summary'):
        eda.detect_outliers()
    
    # Kl칤캜ov칠 metriky
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("콎치dky", data.shape[0])
    with col2:
        st.metric("Sloupce", data.shape[1])
    with col3:
        missing_percent = (data.isnull().sum().sum() / (data.shape[0] * data.shape[1])) * 100
        st.metric("Chyb캩j칤c칤 hodnoty", f"{missing_percent:.2f}%")
    with col4:
        duplicate_count, _ = eda.get_duplicate_rows()
        st.metric("Duplicitn칤 콏치dky", duplicate_count)
    
    # Kvalita dat
    st.subheader("Hodnocen칤 kvality dat")
    try:
        # Zde m콢쬰me implementovat funkci pro v칳po캜et sk칩re kvality dat
        if hasattr(eda, 'calculate_data_quality_score'):
            quality_score = eda.calculate_data_quality_score()
            
            # Vizualizace sk칩re kvality
            col1, col2 = st.columns([1, 3])
            with col1:
                if quality_score['overall_score'] >= 0.9:
                    st.markdown(f"<h1 style='text-align: center; color: green;'>{quality_score['grade']}</h1>", unsafe_allow_html=True)
                elif quality_score['overall_score'] >= 0.8:
                    st.markdown(f"<h1 style='text-align: center; color: #8BC34A;'>{quality_score['grade']}</h1>", unsafe_allow_html=True)
                elif quality_score['overall_score'] >= 0.7:
                    st.markdown(f"<h1 style='text-align: center; color: #FFC107;'>{quality_score['grade']}</h1>", unsafe_allow_html=True)
                elif quality_score['overall_score'] >= 0.6:
                    st.markdown(f"<h1 style='text-align: center; color: #FF9800;'>{quality_score['grade']}</h1>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<h1 style='text-align: center; color: red;'>{quality_score['grade']}</h1>", unsafe_allow_html=True)
            
            with col2:
                metrics_df = pd.DataFrame({
                    'Metrika': list(quality_score['metrics'].keys()),
                    'Sk칩re': list(quality_score['metrics'].values())
                })
                
                fig = px.bar(
                    metrics_df,
                    x='Sk칩re',
                    y='Metrika',
                    orientation='h',
                    color='Sk칩re',
                    color_continuous_scale=['red', OICT_COLORS['purple']],
                    range_color=[0, 1],
                    title='Sk칩re kvality dat'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                st.markdown(f"**Celkov칠 sk칩re kvality dat:** {quality_score['overall_score']:.2f} (Zn치mka {quality_score['grade']})")
        else:
            # Jednodu코코칤 alternativa pro kvalitu dat
            completeness = 1 - (data.isnull().sum().sum() / (data.shape[0] * data.shape[1]))
            duplicate_rate = duplicate_count / data.shape[0]
            overall_quality = (completeness * 0.7) + ((1 - duplicate_rate) * 0.3)
            
            st.progress(overall_quality, text=f"Celkov치 kvalita dat: {overall_quality:.2f}")
            
    except Exception as e:
        st.warning(f"Nelze spo캜칤tat sk칩re kvality dat: {str(e)}")
    
    # Rozd캩len칤 typ콢 sloupc콢
    st.subheader("Typy sloupc콢")
    
    col_type_data = pd.DataFrame({
        'Typ': ['Numerick칠', 'Kategorick칠', 'Datum/캜as'],
        'Po캜et': [len(eda.numeric_cols), len(eda.categorical_cols), len(eda.datetime_cols)]
    })
    
    fig = px.bar(
        col_type_data, 
        x='Typ', 
        y='Po캜et',
        color='Typ',
        color_discrete_sequence=OICT_PALETTE,
        title="Rozd캩len칤 typ콢 sloupc콢"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Seznam sloupc콢
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("##### Numerick칠 sloupce")
        st.write(", ".join(eda.numeric_cols) if eda.numeric_cols else "콯치dn칠")
        
        st.markdown("##### Datum/캜as sloupce")
        st.write(", ".join(eda.datetime_cols) if eda.datetime_cols else "콯치dn칠")
    
    with col2:
        st.markdown("##### Kategorick칠 sloupce")
        st.write(", ".join(eda.categorical_cols) if eda.categorical_cols else "콯치dn칠")
    
    # Kl칤캜ov칠 poznatky
    st.subheader("Kl칤캜ov칠 poznatky")
    insights = eda.generate_insights()
    for insight in insights:
        st.markdown(f"- {insight}")
    
    # Uk치zka dat
    with st.expander("Uk치zka dat", expanded=False):
        st.dataframe(data.head(10))
    
    # Info o datech
    with st.expander("Informace o datech", expanded=False):
        buffer = io.StringIO()
        data.info(buf=buffer)
        st.text(buffer.getvalue())
        
    # Mo쬹ost st치hnout report
    st.subheader("St치hnout report")
    if st.button("Vygenerovat HTML report"):
        report_html = vytvor_html_report(data, eda)
        b64 = base64.b64encode(report_html.encode()).decode()
        href = f'<a href="data:text/html;base64,{b64}" download="eda_report.html" class="btn btn-primary">St치hnout HTML report</a>'
        st.markdown(href, unsafe_allow_html=True)

def zobraz_chybejici_hodnoty():
    st.header("Anal칳za chyb캩j칤c칤ch hodnot")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Spustit anal칳zu, pokud je코t캩 nebyla provedena
    if not hasattr(eda, 'missing_analysis'):
        eda.analyze_missing_values()
    
    # Celkov칳 pohled na chyb캩j칤c칤 hodnoty
    total_missing = data.isnull().sum().sum()
    total_values = data.shape[0] * data.shape[1]
    missing_percent = (total_missing / total_values) * 100
    
    st.markdown(f"**Celkov칠 chyb캩j칤c칤 hodnoty:** {total_missing} z {total_values} ({missing_percent:.2f}%)")
    
    # Chyb캩j칤c칤 hodnoty podle sloupc콢
    missing_cols = eda.missing_analysis[eda.missing_analysis['Missing Values'] > 0]
    
    if len(missing_cols) > 0:
        st.subheader(f"Sloupce s chyb캩j칤c칤mi hodnotami ({len(missing_cols)})")
        
        # Graf chyb캩j칤c칤ch hodnot
        missing_df = missing_cols.reset_index()
        missing_df.columns = ['Sloupec', 'Chyb캩j칤c칤 hodnoty', 'Procento chyb캩j칤c칤ch']
        
        fig = px.bar(
            missing_df.sort_values('Procento chyb캩j칤c칤ch', ascending=False),
            x='Procento chyb캩j칤c칤ch',
            y='Sloupec',
            orientation='h',
            color='Procento chyb캩j칤c칤ch',
            color_continuous_scale=['#eff1fe', OICT_COLORS['purple']],
            title='Chyb캩j칤c칤 hodnoty podle sloupc콢',
            labels={'Procento chyb캩j칤c칤ch': 'Procento chyb캩j칤c칤ch (%)', 'Sloupec': 'N치zev sloupce'}
        )
        fig.update_layout(xaxis_ticksuffix='%')
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabulka chyb캩j칤c칤ch hodnot
        st.dataframe(missing_df)
        
        # Doporu캜en칤
        st.subheader("Doporu캜en칤")
        
        high_missing = missing_df[missing_df['Procento chyb캩j칤c칤ch'] > 50]
        if len(high_missing) > 0:
            st.markdown(f"- Zva쬾e odstran캩n칤 sloupc콢 s > 50% chyb캩j칤c칤ch hodnot: {', '.join(high_missing['Sloupec'])}")
        
        medium_missing = missing_df[(missing_df['Procento chyb캩j칤c칤ch'] <= 50) & (missing_df['Procento chyb캩j칤c칤ch'] > 10)]
        if len(medium_missing) > 0:
            st.markdown(f"- Zva쬾e imputaci chyb캩j칤c칤ch hodnot pro sloupce s 10-50% chyb캩j칤c칤mi hodnotami: {', '.join(medium_missing['Sloupec'])}")
        
        low_missing = missing_df[missing_df['Procento chyb캩j칤c칤ch'] <= 10]
        if len(low_missing) > 0:
            st.markdown(f"- Bezpe캜n칠 dopln캩n칤 sloupc콢 s < 10% chyb캩j칤c칤mi hodnotami: {', '.join(low_missing['Sloupec'])}")
        
        st.markdown("- Pro numerick칠 sloupce pou쬴jte dopln캩n칤 pr콢m캩rem nebo medi치nem")
        st.markdown("- Pro kategorick칠 sloupce pou쬴jte modus nebo vytvo콏te kategorii 'Chyb캩j칤c칤'")
        
        # Vzorce pro dopln캩n칤 chyb캩j칤c칤ch hodnot
        st.subheader("Vzorce pro dopln캩n칤 chyb캩j칤c칤ch hodnot")
        
        code_tab1, code_tab2 = st.tabs(["Python", "R"])
        
        with code_tab1:
            st.code("""
# Dopln캩n칤 numerick칳ch sloupc콢 medi치nem
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())

# Dopln캩n칤 kategorick칳ch sloupc콢 modem
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])
            """)
            
        with code_tab2:
            st.code("""
# Dopln캩n칤 numerick칳ch sloupc콢 medi치nem
df[numeric_cols] <- lapply(df[numeric_cols], function(x) {
  x[is.na(x)] <- median(x, na.rm = TRUE)
  return(x)
})

# Dopln캩n칤 kategorick칳ch sloupc콢 modem
for (col in categorical_cols) {
  mode_val <- names(sort(table(df[[col]]), decreasing = TRUE))[1]
  df[[col]][is.na(df[[col]])] <- mode_val
}
            """)
            
    else:
        st.success("V datasetu nebyly nalezeny 쮂멳n칠 chyb캩j칤c칤 hodnoty!")

def zobraz_distribuce():
    create_section_header("Distribuce dat", icon="游늵", 
                         description="Anal칳za rozlo쬰n칤 hodnot v jednotliv칳ch sloupc칤ch")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Create tabs for numeric vs categorical
    tab1, tab2 = st.tabs(["游늳 Numerick칠 sloupce", "游늵 Kategorick칠 sloupce"])
    
    with tab1:
        if len(eda.numeric_cols) > 0:
            # Souhrnn칠 statistiky
            with st.expander("游늶 Souhrnn칠 statistiky", expanded=False):
                st.dataframe(eda.analyze_distributions(), use_container_width=True)
            
            # Visualization container
            st.markdown("""
            <div class="chart-container">
                <h3>Anal칳za numerick칠 distribuce</h3>
            """, unsafe_allow_html=True)
            
            # V칳b캩r sloupce pro vizualizaci
            col1, col2 = st.columns([3, 1])
            
            with col1:
                selected_num_col = st.selectbox("Vyberte numerick칳 sloupec", eda.numeric_cols)
            
            with col2:
                # Add visualization options
                show_boxplot = st.checkbox("Zobrazit boxplot", value=True)
            
            # Vytvo콏en칤 histogramu
            fig = px.histogram(
                data,
                x=selected_num_col,
                color_discrete_sequence=[OICT_COLORS['purple']],
                marginal="box" if show_boxplot else None,
                title=f"Distribuce sloupce {selected_num_col}",
                opacity=0.7,
                histnorm="percent"
            )
            
            # P콏id치n칤 vertik치ln칤 캜치ry pro pr콢m캩r
            fig.add_vline(
                x=data[selected_num_col].mean(),
                line_dash="dash",
                line_color=OICT_COLORS['orange'],
                annotation_text="Pr콢m캩r",
                annotation_position="top right"
            )
            
            # P콏id치n칤 vertik치ln칤 캜치ry pro medi치n
            fig.add_vline(
                x=data[selected_num_col].median(),
                line_dash="dash",
                line_color=OICT_COLORS['green'],
                annotation_text="Medi치n",
                annotation_position="top left"
            )
            
            # Enhance layout
            fig.update_layout(
                xaxis_title=selected_num_col,
                yaxis_title="Procento v칳skyt콢 (%)",
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)',
                hovermode='closest'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Close container
            st.markdown("</div>", unsafe_allow_html=True)
            
            # Create a two-column layout for metrics
            col1, col2, col3, col4 = st.columns(4)
            
            # Create metric cards
            metrics = [
                {"title": "Pr콢m캩r", "value": f"{data[selected_num_col].mean():.2f}", "icon": "游늺", 
                 "color": OICT_COLORS['purple']},
                {"title": "Medi치n", "value": f"{data[selected_num_col].median():.2f}", "icon": "游늵", 
                 "color": OICT_COLORS['yellow']},
                {"title": "Sm캩r. odchylka", "value": f"{data[selected_num_col].std():.2f}", "icon": "游늳", 
                 "color": OICT_COLORS['orange']},
                {"title": "IQR", "value": f"{(data[selected_num_col].quantile(0.75) - data[selected_num_col].quantile(0.25)):.2f}", 
                 "icon": "游늴", "color": OICT_COLORS['green']}
            ]
            
            create_metric_row(metrics)
            
            # Advanced statistics
            with st.expander("游댧 Pokro캜il칠 statistiky", expanded=False):
                try:
                    skewness = data[selected_num_col].skew()
                    kurtosis = data[selected_num_col].kurtosis()
                    shapiro_test = stats.shapiro(data[selected_num_col].dropna())
                    
                    st.markdown(f"""
                    <div class="card">
                        <h4>말kmost a 코pi캜atost</h4>
                        <p><strong>말kmost (skewness):</strong> {skewness:.4f} - 
                           {'Pravostrann캩 ze코ikmen칠' if skewness > 0.5 else 'Levostrann캩 ze코ikmen칠' if skewness < -0.5 else 'P콏ibli쬹캩 symetrick칠'}</p>
                        <p><strong>맗i캜atost (kurtosis):</strong> {kurtosis:.4f} - 
                           {'V칤ce 코pi캜at칠 ne norm치ln칤 rozd캩len칤' if kurtosis > 0.5 else 
                            'Plo코코칤 ne norm치ln칤 rozd캩len칤' if kurtosis < -0.5 else 
                            'Podobn칠 norm치ln칤mu rozd캩len칤'}</p>
                        <p><strong>Test normality (Shapiro-Wilk):</strong></p>
                        <ul>
                            <li>Statistika: {shapiro_test[0]:.4f}</li>
                            <li>p-hodnota: {shapiro_test[1]:.4f}</li>
                            <li>Z치v캩r: {'Norm치ln칤 rozd캩len칤 nelze vylou캜it' if shapiro_test[1] >= 0.05 else 'Data pravd캩podobn캩 nejsou z norm치ln칤ho rozd캩len칤'}</li>
                        </ul>
                    </div>
                    """, unsafe_allow_html=True)
                except:
                    st.warning("N캩kter칠 statistiky nelze vypo캜칤tat pro tento sloupec")
    
    with tab2:
        if len(eda.categorical_cols) > 0:
            # Visualization container
            st.markdown("""
            <div class="chart-container">
                <h3>Anal칳za kategorick칠 distribuce</h3>
            """, unsafe_allow_html=True)
            
            # V칳b캩r sloupce a nastaven칤
            col1, col2 = st.columns([3, 1])
            
            with col1:
                selected_cat_col = st.selectbox("Vyberte kategorick칳 sloupec", eda.categorical_cols)
            
            with col2:
                # Add visualization options
                sort_by = st.radio("콎azen칤", ["캛etnost", "Abecedn캩"], horizontal=True)
            
            # Z칤sk치n칤 po캜tu hodnot
            cat_summaries = eda.get_categorical_summaries()
            value_counts = cat_summaries[selected_cat_col]
            
            # Sort if requested
            if sort_by == "캛etnost":
                value_counts = value_counts.sort_values("Count", ascending=False)
            else:
                value_counts = value_counts.sort_values(selected_cat_col)
            
            # Check number of categories
            if len(value_counts) > 15:
                st.info(f"Zobrazeno prvn칤ch 15 kategori칤 z celkov칳ch {len(value_counts)}")
                value_counts = value_counts.head(15)
            
            # Enhanced bar chart
            fig = px.bar(
                value_counts,
                x=selected_cat_col,
                y='Count',
                color=selected_cat_col,
                color_discrete_sequence=OICT_PALETTE * 3,
                title=f"Distribuce sloupce {selected_cat_col}",
                text='Percentage',
                opacity=0.8
            )
            
            # Formatting
            fig.update_traces(
                texttemplate='%{text:.1f}%', 
                textposition='outside',
                hovertemplate='<b>%{x}</b><br>Po캜et: %{y}<br>Procento: %{text:.1f}%'
            )
            
            # Enhance layout
            fig.update_layout(
                xaxis_title=selected_cat_col,
                yaxis_title="Po캜et",
                showlegend=False,
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Add pie chart as an alternative view
            show_pie = st.checkbox("Zobrazit jako kol치캜ov칳 graf", value=False)
            
            if show_pie:
                pie_fig = px.pie(
                    value_counts, 
                    values='Count', 
                    names=selected_cat_col,
                    title=f"Rozlo쬰n칤 kategori칤 v {selected_cat_col}",
                    color=selected_cat_col,
                    color_discrete_sequence=OICT_PALETTE * 3,
                    hole=0.4
                )
                
                st.plotly_chart(pie_fig, use_container_width=True)
            
            # Close container
            st.markdown("</div>", unsafe_allow_html=True)
            
            # Summary metrics for categorical
            total_count = value_counts['Count'].sum()
            unique_count = len(value_counts)
            max_category = value_counts.iloc[0][selected_cat_col] if not value_counts.empty else "N/A"
            max_percent = value_counts['Percentage'].max() if not value_counts.empty else 0
            
            metrics = [
                {"title": "Po캜et kategori칤", "value": unique_count, "icon": "游댝", 
                 "color": OICT_COLORS['purple']},
                {"title": "Celkov칳 po캜et", "value": total_count, "icon": "游늵", 
                 "color": OICT_COLORS['yellow']},
                {"title": "Nej캜ast캩j코칤 kategorie", "value": max_category, "icon": "游끥", 
                 "color": OICT_COLORS['orange']},
                {"title": "Max. zastoupen칤", "value": f"{max_percent:.1f}%", "icon": "游늳", 
                 "color": OICT_COLORS['green']}
            ]
            
            create_metric_row(metrics)
            
            # Detailed table
            with st.expander("游늶 Detailn칤 tabulka", expanded=False):
                st.dataframe(value_counts, use_container_width=True)

def zobraz_korelace():
    create_section_header("Anal칳za korelac칤", icon="游댃", 
                         description="Zkoum치n칤 vz치jemn칳ch vztah콢 mezi numerick칳mi prom캩nn칳mi")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.numeric_cols) < 2:
        st.warning("Pro anal칳zu korelac칤 jsou pot콏eba alespo켿 2 numerick칠 sloupce")
        return
    
    # Use tabs for different correlation views
    tab1, tab2, tab3 = st.tabs(["游늵 Korela캜n칤 matice", "游늳 P치rov칠 korelace", "游늶 Vysok칠 korelace"])
    
    with tab1:
        # Container for correlation matrix
        st.markdown("""
        <div class="chart-container">
            <h3>Korela캜n칤 matice</h3>
        """, unsafe_allow_html=True)
        
        # Spustit anal칳zu, pokud je코t캩 nebyla provedena
        if not hasattr(eda, 'correlation_matrix'):
            eda.analyze_correlations()
        
        # Enhanced controls
        col1, col2, col3 = st.columns([2, 2, 3])
        
        with col1:
            # Metoda korelace as modern radio
            corr_method = create_modern_radio(
                "Metoda korelace:",
                ["Pearson", "Spearman"],
                key="corr_method"
            )
        
        with col2:
            # Nastaven칤 filtru prahov칠 hodnoty
            threshold = st.slider(
                "Pr치h korelace (abs)",
                min_value=0.0,
                max_value=1.0,
                value=0.0,
                step=0.05
            )
        
        with col3:
            # Add column selector
            all_selected = st.checkbox("Vybrat v코echny sloupce", value=True)
            if all_selected:
                selected_columns = eda.numeric_cols
            else:
                selected_columns = st.multiselect(
                    "Vyberte sloupce pro korela캜n칤 matici",
                    eda.numeric_cols,
                    default=eda.numeric_cols[:min(8, len(eda.numeric_cols))]
                )
        
        # P콏epo캜칤tat korelaci, pokud se metoda zm캩nila
        if corr_method.lower() != "pearson" or not all_selected:
            # Generate correlation only for selected columns
            correlation_matrix = data[selected_columns].corr(method=corr_method.lower())
        else:
            correlation_matrix = eda.correlation_matrix
        
        # Filtrovat podle prahu
        if threshold > 0:
            mask = np.abs(correlation_matrix) > threshold
            filtered_corr = correlation_matrix.where(mask, 0)
        else:
            filtered_corr = correlation_matrix
        
        # Enhanced heatmap
        fig = px.imshow(
            filtered_corr,
            color_continuous_scale='RdBu_r',
            zmin=-1, zmax=1,
            title=f'{corr_method} korela캜n칤 matice (pr치h: {threshold})',
            aspect="auto"
        )
        
        # Improve heatmap appearance
        fig.update_layout(
            height=600,
            xaxis_title="",
            yaxis_title="",
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        # Add text annotations to heatmap
        annotations = []
        for i, row in enumerate(filtered_corr.index):
            for j, col in enumerate(filtered_corr.columns):
                value = filtered_corr.iloc[i, j]
                # Only show text for non-zero values
                if value != 0:
                    text_color = "white" if abs(value) > 0.4 else "black"
                    annotations.append({
                        "x": j,
                        "y": i,
                        "text": f"{value:.2f}",
                        "showarrow": False,
                        "font": {
                            "color": text_color,
                            "size": 10
                        }
                    })
        
        fig.update_layout(annotations=annotations)
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Close container
        st.markdown("</div>", unsafe_allow_html=True)
    
    with tab2:
        # Container for scatter plots
        st.markdown("""
        <div class="chart-container">
            <h3>P치rov칠 korelace</h3>
        """, unsafe_allow_html=True)
        
        # Two column selection
        col1, col2 = st.columns(2)
        
        with col1:
            x_var = st.selectbox("Prom캩nn치 X", eda.numeric_cols, key="pair_x")
        
        with col2:
            remaining_cols = [col for col in eda.numeric_cols if col != x_var]
            y_var = st.selectbox("Prom캩nn치 Y", remaining_cols, key="pair_y")
        
        # Create enhanced scatter plot
        scatter_fig = px.scatter(
            data,
            x=x_var,
            y=y_var,
            trendline="ols",
            color_discrete_sequence=[OICT_COLORS['purple']],
            opacity=0.7,
            title=f"Korelace: {x_var} vs {y_var}"
        )
        
        # Enhanced layout
        scatter_fig.update_layout(
            xaxis_title=x_var,
            yaxis_title=y_var,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        # Calculate correlation statistics
        valid_data = data[[x_var, y_var]].dropna()
        pearson_r, pearson_p = stats.pearsonr(valid_data[x_var], valid_data[y_var])
        spearman_r, spearman_p = stats.spearmanr(valid_data[x_var], valid_data[y_var])
        
        # Add correlation info to the plot
        scatter_fig.add_annotation(
            xref="paper", yref="paper",
            x=0.02, y=0.98,
            text=f"Pearson r: {pearson_r:.4f} (p={pearson_p:.4f})<br>Spearman 픠: {spearman_r:.4f} (p={spearman_p:.4f})",
            showarrow=False,
            bgcolor="rgba(255, 255, 255, 0.8)",
            bordercolor=OICT_COLORS['purple'],
            borderwidth=1,
            borderpad=4
        )
        
        st.plotly_chart(scatter_fig, use_container_width=True)
        
        # Add correlation interpretation
        corr_strength = abs(pearson_r)
        if corr_strength < 0.3:
            strength = "slab치"
            color = "#FFC107"  # Yellow
        elif corr_strength < 0.6:
            strength = "st콏edn칤"
            color = "#FF9800"  # Orange
        elif corr_strength < 0.8:
            strength = "siln치"
            color = "#F44336"  # Red
        else:
            strength = "velmi siln치"
            color = "#9C27B0"  # Purple
        
        direction = "pozitivn칤" if pearson_r > 0 else "negativn칤"
        
        st.markdown(f"""
        <div class="insight-card">
            <p>Mezi prom캩nn칳mi <strong>{x_var}</strong> a <strong>{y_var}</strong> existuje 
            <span style="color: {color}; font-weight: bold;">{strength} {direction}</span> korelace 
            (r = {pearson_r:.4f}).</p>
            
            <p>Korelace je statisticky {pearson_p < 0.05 and "v칳znamn치" or "nev칳znamn치"} 
            (p {pearson_p < 0.05 and "<" or "곤"} 0.05).</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Close container
        st.markdown("</div>", unsafe_allow_html=True)
    
    with tab3:
        # Container for high correlations
        st.markdown("""
        <div class="chart-container">
            <h3>Siln칠 korelace</h3>
        """, unsafe_allow_html=True)
        
        # High correlations
        if hasattr(eda, 'high_correlations') and len(eda.high_correlations) > 0:
            # Enhanced visualization of high correlations
            high_corr_fig = px.bar(
                eda.high_correlations.sort_values('Correlation', ascending=False),
                x='Correlation',
                y=eda.high_correlations.apply(lambda x: f"{x['Feature 1']} & {x['Feature 2']}", axis=1),
                orientation='h',
                color='Correlation',
                color_continuous_scale=['blue', 'white', 'red'],
                range_color=[-1, 1],
                title='P치ry s vysokou korelac칤 (|r| 곤 0.7)'
            )
            
            # Enhance bar chart
            high_corr_fig.update_layout(
                yaxis_title="",
                xaxis_title="Korela캜n칤 koeficient",
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            
            st.plotly_chart(high_corr_fig, use_container_width=True)
            
            # Enhanced high correlations table
            st.markdown("#### Tabulka siln칳ch korelac칤")
            
            # Format the table with colors
            def highlight_correlation(val):
                color = 'red' if val > 0.9 else 'orange' if val > 0.8 else 'green'
                return f'color: {color}; font-weight: bold'
            
            styled_high_corrs = eda.high_correlations.style.format({
                'Correlation': '{:.4f}'
            }).map(highlight_correlation, subset=['Correlation'])
            
            st.dataframe(styled_high_corrs, use_container_width=True)
            
            # Add recommendations in a card
            st.markdown("#### Doporu캜en칤")
            
            very_high_corr = eda.high_correlations[eda.high_correlations['Correlation'].abs() > 0.9]
            if len(very_high_corr) > 0:
                st.markdown("""
                <div class="card orange">
                    <h4>Prom캩nn칠 s velmi silnou korelac칤 (|r| > 0.9)</h4>
                    <p>Zva쬾e odstran캩n칤 jedn칠 z ka쬯칠ho p치ru, abyste p콏ede코li multikolinearit캩:</p>
                    <ul>
                """, unsafe_allow_html=True)
                
                for _, row in very_high_corr.iterrows():
                    st.markdown(f"""
                    <li><strong>{row['Feature 1']}</strong> & <strong>{row['Feature 2']}</strong> 
                    (r = {row['Correlation']:.3f})</li>
                    """, unsafe_allow_html=True)
                
                st.markdown("</ul></div>", unsafe_allow_html=True)
            
            else:
                st.markdown("""
                <div class="card green">
                    <h4>Nebyla nalezena 쮂멳n치 extr칠mn캩 siln치 korelace</h4>
                    <p>V datech nebyly nalezeny p치ry s velmi silnou korelac칤 (|r| > 0.9), 
                    co je pozitivn칤 z hlediska p콏edch치zen칤 multikolinearit캩 v modelech.</p>
                </div>
                """, unsafe_allow_html=True)
        
        else:
            st.info("Nebyly nalezeny 쮂멳n칠 vysok칠 korelace (|r| 곤 0.7)")
        
        # Close container
        st.markdown("</div>", unsafe_allow_html=True)


def zobraz_odlehle_hodnoty():
    st.header("Anal칳za odlehl칳ch hodnot")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.numeric_cols) == 0:
        st.warning("Pro anal칳zu odlehl칳ch hodnot jsou pot콏eba numerick칠 sloupce")
        return
    
    # Spustit anal칳zu, pokud je코t캩 nebyla provedena
    if not hasattr(eda, 'outlier_summary'):
        eda.detect_outliers()
    
    # V칳b캩r sloupce pro vizualizaci
    selected_col = st.selectbox("Vyberte numerick칳 sloupec", eda.numeric_cols)
    
    # Vytvo콏en칤 boxplotu
    fig = px.box(
        data,
        y=selected_col,
        title=f"Boxplot pro {selected_col}",
        color_discrete_sequence=[OICT_COLORS['purple']]
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Informace o odlehl칳ch hodnot치ch
    if selected_col in eda.outlier_summary:
        outlier_info = eda.outlier_summary[selected_col]
        
        st.markdown(f"**Zji코t캩n칠 odlehl칠 hodnoty:** {outlier_info['count']} ({outlier_info['percent']:.2f}% hodnot)")
        st.markdown(f"**Doln칤 hranice:** {outlier_info['lower_bound']:.2f}")
        st.markdown(f"**Horn칤 hranice:** {outlier_info['upper_bound']:.2f}")
        
        # Vytvo콏it histogram se zv칳razn캩n칤m odlehl칳ch hodnot
        clean_data = data[selected_col].dropna()
        is_outlier = (clean_data < outlier_info['lower_bound']) | (clean_data > outlier_info['upper_bound'])
        
        hist_data = pd.DataFrame({
            'value': clean_data,
            'is_outlier': is_outlier
        })
        
        fig = px.histogram(
            hist_data,
            x='value',
            color='is_outlier',
            color_discrete_map={True: OICT_COLORS['orange'], False: OICT_COLORS['purple']},
            title=f'Distribuce se zv칳razn캩n칳mi odlehl칳mi hodnotami (oran쬺v치)',
            barmode='overlay',
            opacity=0.7
        )
        
        # P콏idat vertik치ln칤 캜치ry pro hranice
        fig.add_vline(x=outlier_info['lower_bound'], line_dash="dash", line_color="black")
        fig.add_vline(x=outlier_info['upper_bound'], line_dash="dash", line_color="black")
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Doporu캜en칤
        st.subheader("Doporu캜en칤")
        
        if outlier_info['percent'] < 1:
            st.markdown("- Odlehl칠 hodnoty tvo콏칤 velmi mal칠 procento dat a mohou b칳t skute캜n칠 anom치lie")
            st.markdown("- Zva쬾e prozkoum치n칤 jednotliv칳ch odlehl칳ch bod콢, abyste pochopili jejich p콢vod")
        elif outlier_info['percent'] < 5:
            st.markdown("- Odlehl칠 hodnoty tvo콏칤 mal칠 procento dat")
            st.markdown("- Mo쬹osti, jak s nimi nalo쬴t:")
            st.markdown("  1. Omezit odlehl칠 hodnoty na doln칤/horn칤 hranice (winsorization)")
            st.markdown("  2. Odstranit odlehl칠 hodnoty, pokud se jedn치 o chyby m캩콏en칤")
            st.markdown("  3. Vytvo콏it bin치rn칤 p콏칤znak indikuj칤c칤 p콏칤tomnost odlehl칳ch hodnot")
        else:
            st.markdown("- Distribuce je pravd캩podobn캩 ze코ikmen치 nebo m치 v칳znamn칳 po캜et odlehl칳ch hodnot")
            st.markdown("- Zva쬾e aplikaci transformac칤 (log, sqrt) pro normalizaci distribuce")
            st.markdown("- P콏ehodno콘te definici odlehl칳ch hodnot pro tuto prom캩nnou - metoda IQR nemus칤 b칳t vhodn치")
    else:
        st.success(f"V {selected_col} nebyly zji코t캩ny 쮂멳n칠 odlehl칠 hodnoty")
    
    # Souhrnn칳 p콏ehled odlehl칳ch hodnot
    st.subheader("Souhrnn칳 p콏ehled odlehl칳ch hodnot")
    
    if hasattr(eda, 'outlier_summary') and len(eda.outlier_summary) > 0:
        outlier_data = []
        for col, info in eda.outlier_summary.items():
            outlier_data.append({
                'Sloupec': col,
                'Po캜et odlehl칳ch hodnot': info['count'],
                'Procento odlehl칳ch hodnot': info['percent']
            })
        
        outlier_df = pd.DataFrame(outlier_data)
        outlier_df = outlier_df.sort_values('Procento odlehl칳ch hodnot', ascending=False)
        
        fig = px.bar(
            outlier_df,
            x='Sloupec',
            y='Procento odlehl칳ch hodnot',
            color='Procento odlehl칳ch hodnot',
            color_continuous_scale=['#eff1fe', OICT_COLORS['purple']],
            title='Procento odlehl칳ch hodnot podle sloupce'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        st.dataframe(outlier_df)
    else:
        st.success("V 쮂멳n칠m numerick칠m sloupci nebyly zji코t캩ny odlehl칠 hodnoty")

def zobraz_pca():
    st.header("Redukce dimenz칤 (PCA)")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.numeric_cols) < 3:
        st.warning("Pro PCA jsou pot콏eba alespo켿 3 numerick칠 sloupce.")
        return
    
    # Nastaven칤 PCA
    st.subheader("Nastaven칤 PCA")
    
    # V칳b캩r sloupc콢 pro PCA
    selected_features = st.multiselect(
        "Vyberte sloupce pro PCA",
        eda.numeric_cols,
        default=eda.numeric_cols[:min(10, len(eda.numeric_cols))]
    )
    
    n_components = st.slider("Po캜et komponent", 2, min(10, len(selected_features)), 2)
    
    if len(selected_features) < 3:
        st.warning("Vyberte alespo켿 3 sloupce pro proveden칤 PCA")
        return
    
    # Tla캜칤tko pro spu코t캩n칤 PCA
    run_pca = st.button("Spustit PCA")
    
    if run_pca:
        with st.spinner("Prov치d칤m PCA..."):
            # P콏칤prava dat
            pca_data = data[selected_features].dropna()
            
            if len(pca_data) < 10:
                st.error("Nedostatek dat pro PCA po odstran캩n칤 chyb캩j칤c칤ch hodnot")
                return
            
            # Standardizace
            scaler = StandardScaler()
            scaled_data = scaler.fit_transform(pca_data)
            
            # Aplikace PCA
            pca = PCA(n_components=n_components)
            transformed_data = pca.fit_transform(scaled_data)
            
            # Vytvo콏en칤 v칳sledn칠ho dataframe
            result_df = pd.DataFrame(
                transformed_data,
                columns=[f'PC{i+1}' for i in range(n_components)],
                index=pca_data.index
            )
            
            # Zobrazen칤 v칳sledk콢
            st.subheader("V칳sledky PCA")
            
            # Vysv캩tlen칳 rozptyl
            explained_variance = pca.explained_variance_ratio_
            total_variance = sum(explained_variance)
            
            st.markdown(f"**Celkov칳 vysv캩tlen칳 rozptyl:** {total_variance:.2%}")
            
            # Graf vysv캩tlen칠ho rozptylu
            variance_data = pd.DataFrame({
                'Komponenta': [f'PC{i+1}' for i in range(len(explained_variance))],
                'Vysv캩tlen칳 rozptyl': explained_variance,
                'Kumulativn칤 rozptyl': np.cumsum(explained_variance)
            })
            
            fig = px.bar(
                variance_data,
                x='Komponenta',
                y='Vysv캩tlen칳 rozptyl',
                title='Vysv캩tlen칳 rozptyl podle komponent',
                text=variance_data['Vysv캩tlen칳 rozptyl'].apply(lambda x: f'{x:.1%}')
            )
            
            # P콏idat 캜치ru kumulativn칤ho rozptylu
            fig.add_scatter(
                x=variance_data['Komponenta'],
                y=variance_data['Kumulativn칤 rozptyl'],
                mode='lines+markers',
                name='Kumulativn칤 rozptyl',
                line=dict(color=OICT_COLORS['orange']),
                yaxis='y2'
            )
            
            fig.update_layout(
                yaxis2=dict(
                    title='Kumulativn칤 rozptyl',
                    overlaying='y',
                    side='right',
                    range=[0, 1.1],
                    tickformat='.0%',
                    showgrid=False
                ),
                yaxis_tickformat='.0%'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Zobrazen칤 PCA v prostoru prvn칤ch dvou komponent
            if n_components >= 2:
                st.subheader("Projekce PCA (prvn칤 dv캩 komponenty)")
                
                # Obarven칤 bod콢 podle kategorie, pokud je k dispozici
                if len(eda.categorical_cols) > 0:
                    color_by = st.selectbox(
                        "Obarvit podle kategorie",
                        ["콯치dn칠"] + eda.categorical_cols
                    )
                    
                    if color_by != "콯치dn칠":
                        pca_df = result_df.copy()
                        pca_df[color_by] = data.loc[pca_df.index, color_by]
                        
                        fig = px.scatter(
                            pca_df,
                            x='PC1',
                            y='PC2',
                            color=color_by,
                            title=f'PCA: Prvn칤 dv캩 komponenty (vysv캩tleno {(explained_variance[0] + explained_variance[1]):.1%} rozptylu)',
                            opacity=0.7
                        )
                    else:
                        fig = px.scatter(
                            result_df,
                            x='PC1',
                            y='PC2',
                            title=f'PCA: Prvn칤 dv캩 komponenty (vysv캩tleno {(explained_variance[0] + explained_variance[1]):.1%} rozptylu)',
                            color_discrete_sequence=[OICT_COLORS['purple']],
                            opacity=0.7
                        )
                else:
                    fig = px.scatter(
                        result_df,
                        x='PC1',
                        y='PC2',
                        title=f'PCA: Prvn칤 dv캩 komponenty (vysv캩tleno {(explained_variance[0] + explained_variance[1]):.1%} rozptylu)',
                        color_discrete_sequence=[OICT_COLORS['purple']],
                        opacity=0.7
                    )
                
                fig.update_layout(
                    xaxis_title=f'PC1 ({explained_variance[0]:.1%} rozptylu)',
                    yaxis_title=f'PC2 ({explained_variance[1]:.1%} rozptylu)'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # V치hy p콏칤znak콢 (loadings)
                st.subheader("V치hy p콏칤znak콢 (loadings)")
                
                loadings = pd.DataFrame(
                    pca.components_.T,
                    columns=[f'PC{i+1}' for i in range(n_components)],
                    index=selected_features
                )
                
                loadings_melted = pd.melt(
                    loadings.reset_index(),
                    id_vars='index',
                    var_name='Komponenta',
                    value_name='V치ha'
                )
                
                fig = px.imshow(
                    loadings,
                    color_continuous_scale='RdBu_r',
                    title='V치hy p콏칤znak콢'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Tabulka vah
                st.dataframe(loadings)

def zobraz_clustering():
    st.header("Shlukov치 anal칳za (clustering)")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.numeric_cols) < 2:
        st.warning("Pro shlukovou anal칳zu jsou pot콏eba alespo켿 2 numerick칠 sloupce.")
        return
    
    # Nastaven칤 shlukov칠 anal칳zy
    st.subheader("Nastaven칤 shlukov칠 anal칳zy")
    
    # V칳b캩r sloupc콢
    selected_features = st.multiselect(
        "Vyberte sloupce pro shlukovou anal칳zu",
        eda.numeric_cols,
        default=eda.numeric_cols[:min(5, len(eda.numeric_cols))]
    )
    
    # Po캜et shluk콢
    n_clusters = st.slider("Po캜et shluk콢", 2, 10, 3)
    
    # Metoda shlukov치n칤
    clustering_method = st.radio(
        "Metoda shlukov치n칤",
        ["K-means", "Hierarchick칠 shlukov치n칤"],
        horizontal=True
    )
    
    if len(selected_features) < 2:
        st.warning("Vyberte alespo켿 2 sloupce pro shlukovou anal칳zu")
        return
    
    # Tla캜칤tko pro spu코t캩n칤 shlukov칠 anal칳zy
    run_clustering = st.button("Spustit shlukovou anal칳zu")
    
    if run_clustering:
        with st.spinner("Prov치d칤m shlukovou anal칳zu..."):
            # P콏칤prava dat
            cluster_data = data[selected_features].dropna()
            
            if len(cluster_data) < n_clusters * 3:
                st.error(f"Nedostatek dat pro {n_clusters} shluk콢. Pot콏ebujete alespo켿 {n_clusters * 3} 콏치dk콢 bez chyb캩j칤c칤ch hodnot.")
                return
            
            # Standardizace
            scaler = StandardScaler()
            scaled_data = scaler.fit_transform(cluster_data)
            
            # Aplikace shlukov칠 anal칳zy
            if clustering_method == "K-means":
                from sklearn.cluster import KMeans
                
                # K-means
                kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                clusters = kmeans.fit_predict(scaled_data)
                
                # Elbow method (pro zobrazen칤 optim치ln칤ho po캜tu shluk콢)
                inertia = []
                for k in range(1, min(11, len(cluster_data) // 3)):
                    km = KMeans(n_clusters=k, random_state=42, n_init=10)
                    km.fit(scaled_data)
                    inertia.append(km.inertia_)
                
                elbow_data = pd.DataFrame({
                    'Po캜et shluk콢': range(1, len(inertia) + 1),
                    'Inertia': inertia
                })
                
                fig = px.line(
                    elbow_data,
                    x='Po캜et shluk콢',
                    y='Inertia',
                    title='Elbow Method pro ur캜en칤 optim치ln칤ho po캜tu shluk콢',
                    markers=True
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
            else:
                from sklearn.cluster import AgglomerativeClustering
                
                # Hierarchick칠 shlukov치n칤
                hc = AgglomerativeClustering(n_clusters=n_clusters)
                clusters = hc.fit_predict(scaled_data)
            
            # P콏id치n칤 informace o shluc칤ch k dat콢m
            cluster_results = cluster_data.copy()
            cluster_results['Shluk'] = clusters
            
            # Zobrazen칤 v칳sledk콢
            st.subheader("V칳sledky shlukov칠 anal칳zy")
            
            # Distribuce shluk콢
            cluster_counts = pd.Series(clusters).value_counts().sort_index()
            cluster_counts_df = cluster_counts.reset_index()
            cluster_counts_df.columns = ['Shluk', 'Po캜et']
            
            fig = px.bar(
                cluster_counts_df,
                x='Shluk',
                y='Po캜et',
                color='Shluk',
                title='Distribuce shluk콢'
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Profily shluk콢
            st.subheader("Profily shluk콢")
            
            # V칳po캜et pr콢m캩r콢 pro ka쬯칳 shluk
            cluster_means = cluster_results.groupby('Shluk').mean()
            
            # Standardizace pr콢m캩r콢 pro lep코칤 vizualizaci
            cluster_means_scaled = (cluster_means - cluster_means.mean()) / cluster_means.std()
            
            # Heatmapa profil콢 shluk콢
            fig = px.imshow(
                cluster_means_scaled,
                color_continuous_scale='RdBu_r',
                title='Profily shluk콢 (standardizovan칠 pr콢m캩ry p콏칤znak콢)',
                labels={'index': 'Shluk', 'variable': 'P콏칤znak', 'value': 'Standardizovan치 hodnota'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Tabulka pr콢m캩r콢 pro shluky
            st.markdown("#### Pr콢m캩ry p콏칤znak콢 podle shluk콢")
            st.dataframe(cluster_means)
            
            # Vizualizace shluk콢 v 2D prostoru
            if len(selected_features) >= 2:
                st.subheader("Vizualizace shluk콢")
                
                if len(selected_features) == 2:
                    # P콏칤m치 vizualizace, pokud m치me jen 2 p콏칤znaky
                    viz_data = cluster_results.copy()
                    
                    fig = px.scatter(
                        viz_data,
                        x=selected_features[0],
                        y=selected_features[1],
                        color='Shluk',
                        title=f'Shluky v prostoru {selected_features[0]} vs {selected_features[1]}',
                        opacity=0.7
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                else:
                    # Pou쬴t칤 PCA pro vizualizaci ve 2D
                    pca = PCA(n_components=2)
                    pca_result = pca.fit_transform(scaled_data)
                    
                    pca_df = pd.DataFrame({
                        'PC1': pca_result[:, 0],
                        'PC2': pca_result[:, 1],
                        'Shluk': clusters
                    })
                    
                    fig = px.scatter(
                        pca_df,
                        x='PC1',
                        y='PC2',
                        color='Shluk',
                        title='Shluky v PCA prostoru',
                        opacity=0.7
                    )
                    
                    st.plotly_chart(fig, use_container_width=True)
            
            # Charakteristiky jednotliv칳ch shluk콢
            st.subheader("Charakteristiky shluk콢")
            
            for cluster_id in range(n_clusters):
                with st.expander(f"Shluk {cluster_id}"):
                    # Po캜et z치znam콢 ve shluku
                    cluster_size = (clusters == cluster_id).sum()
                    st.markdown(f"**Po캜et z치znam콢:** {cluster_size} ({cluster_size / len(clusters):.1%} z celku)")
                    
                    # Typick칠 hodnoty
                    st.markdown("**Typick칠 hodnoty:**")
                    
                    # Ur캜en칤 v칳zna캜n칳ch vlastnost칤
                    profile = cluster_means_scaled.loc[cluster_id]
                    significant_high = profile[profile > 0.5].sort_values(ascending=False)
                    significant_low = profile[profile < -0.5].sort_values()
                    
                    if not significant_high.empty:
                        st.markdown("*Nadpr콢m캩rn칠 hodnoty:*")
                        for feature, value in significant_high.items():
                            st.markdown(f"- {feature}: {value:.2f} sm캩r. odchylek nad pr콢m캩rem (hodnota: {cluster_means.loc[cluster_id, feature]:.2f})")
                    
                    if not significant_low.empty:
                        st.markdown("*Podpr콢m캩rn칠 hodnoty:*")
                        for feature, value in significant_low.items():
                            st.markdown(f"- {feature}: {-value:.2f} sm캩r. odchylek pod pr콢m캩rem (hodnota: {cluster_means.loc[cluster_id, feature]:.2f})")

def zobraz_statisticke_testy():
    st.header("Statistick칠 testy")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # V칳b캩r typu testu
    test_type = st.selectbox(
        "Vyberte typ statistick칠ho testu",
        ["Test normality", "Testy korelace", "t-test", "ANOVA", "Chi-kvadr치t"]
    )
    
    if test_type == "Test normality":
        # Test normality
        st.subheader("Test normality")
        
        if len(eda.numeric_cols) == 0:
            st.warning("Pro test normality jsou pot콏eba numerick칠 sloupce")
            return
        
        col = st.selectbox("Vyberte sloupec pro test normality", eda.numeric_cols)
        
        clean_data = data[col].dropna()
        if len(clean_data) < 3:
            st.error("Nedostatek dat pro test normality")
            return
        
        # Limit po캜tu hodnot pro test Shapiro-Wilk (max 5000)
        if len(clean_data) > 5000:
            st.warning(f"Pro test Shapiro-Wilk bude pou쬴t vzorek 5000 hodnot z celkov칳ch {len(clean_data)}")
            sample_data = clean_data.sample(5000, random_state=42)
        else:
            sample_data = clean_data
        
        # Proveden칤 testu Shapiro-Wilk
        shapiro_test = stats.shapiro(sample_data)
        
        # Vizualizace histogramu s p콏ekrytou norm치ln칤 distribuc칤
        fig = px.histogram(
            sample_data,
            nbins=30,
            histnorm='probability density',
            title=f"Distribuce {col} s norm치ln칤 k콏ivkou"
        )
        
        # P콏id치n칤 norm치ln칤 k콏ivky
        x = np.linspace(min(sample_data), max(sample_data), 100)
        mean, std = sample_data.mean(), sample_data.std()
        pdf = stats.norm.pdf(x, mean, std)
        fig.add_scatter(x=x, y=pdf, mode='lines', name='Norm치ln칤 distribuce')
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Vytvo콏en칤 Q-Q plotu
        fig = px.scatter(
            x=np.sort(stats.norm.ppf(np.linspace(0.01, 0.99, len(sample_data)))),
            y=np.sort(sample_data),
            title="Q-Q Plot (norm치ln칤 distribuce)",
            labels={"x": "Teoretick칠 kvantily", "y": "Vzorov칠 kvantily"}
        )
        
        # P콏id치n칤 referen캜n칤 캜치ry
        fig.add_scatter(
            x=[min(sample_data), max(sample_data)],
            y=[min(sample_data), max(sample_data)],
            mode='lines',
            line=dict(color='red', dash='dash'),
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # V칳sledky testu
        st.subheader("V칳sledky testu normality")
        st.markdown(f"**Test Shapiro-Wilk:**")
        st.markdown(f"- Statistika: {shapiro_test[0]:.4f}")
        st.markdown(f"- p-hodnota: {shapiro_test[1]:.4f}")
        
        if shapiro_test[1] < 0.05:
            st.markdown("**Z치v캩r: Data NEJSOU norm치ln캩 distribuov치na (p < 0.05)**")
        else:
            st.markdown("**Z치v캩r: Data MOHOU B칗T norm치ln캩 distribuov치na (p 곤 0.05)**")
        
        # 말kmost a 코pi캜atost
        skewness = stats.skew(sample_data)
        kurtosis = stats.kurtosis(sample_data)
        
        st.markdown(f"**말kmost (Skewness):** {skewness:.4f}")
        if abs(skewness) < 0.5:
            st.markdown("Distribuce je p콏ibli쬹캩 symetrick치")
        elif abs(skewness) < 1:
            st.markdown("Distribuce je m칤rn캩 ze코ikmen치")
        else:
            st.markdown("Distribuce je siln캩 ze코ikmen치")
        
        st.markdown(f"**맗i캜atost (Kurtosis):** {kurtosis:.4f}")
        if abs(kurtosis) < 0.5:
            st.markdown("맗i캜atost je podobn치 norm치ln칤 distribuci")
        elif kurtosis > 0:
            st.markdown("Distribuce je 코pi캜at캩j코칤 ne norm치ln칤 (leptokurtick치)")
        else:
            st.markdown("Distribuce je plo코코칤 ne norm치ln칤 (platykurtick치)")
        
    elif test_type == "Testy korelace":
        # Testy korelace
        st.subheader("Testy korelace")
        
        if len(eda.numeric_cols) < 2:
            st.warning("Pro testy korelace jsou pot콏eba alespo켿 2 numerick칠 sloupce")
            return
        
        col1, col2 = st.columns(2)
        
        with col1:
            x_col = st.selectbox("Vyberte prvn칤 prom캩nnou", eda.numeric_cols, key="x_col")
        
        with col2:
            y_col = st.selectbox("Vyberte druhou prom캩nnou", [col for col in eda.numeric_cols if col != x_col], key="y_col")
        
        # Odstran캩n칤 chyb캩j칤c칤ch hodnot
        clean_data = data[[x_col, y_col]].dropna()
        if len(clean_data) < 3:
            st.error("Nedostatek dat pro test korelace")
            return
        
        # Vizualizace scatter plotu
        fig = px.scatter(
            clean_data,
            x=x_col,
            y=y_col,
            trendline="ols",
            title=f"Vztah mezi {x_col} a {y_col}"
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Proveden칤 test콢 korelace
        pearson_r, pearson_p = stats.pearsonr(clean_data[x_col], clean_data[y_col])
        spearman_r, spearman_p = stats.spearmanr(clean_data[x_col], clean_data[y_col])
        
        # V칳sledky test콢
        st.subheader("V칳sledky test콢 korelace")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Pearsonova korelace:**")
            st.markdown(f"- Koeficient r: {pearson_r:.4f}")
            st.markdown(f"- p-hodnota: {pearson_p:.4f}")
            if pearson_p < 0.05:
                st.markdown("- Z치v캩r: Statisticky v칳znamn치 line치rn칤 korelace (p < 0.05)")
            else:
                st.markdown("- Z치v캩r: 콯치dn치 statisticky v칳znamn치 line치rn칤 korelace (p 곤 0.05)")
        
        with col2:
            st.markdown("**Spearmanova korelace:**")
            st.markdown(f"- Koeficient rho: {spearman_r:.4f}")
            st.markdown(f"- p-hodnota: {spearman_p:.4f}")
            if spearman_p < 0.05:
                st.markdown("- Z치v캩r: Statisticky v칳znamn치 po콏adov치 korelace (p < 0.05)")
            else:
                st.markdown("- Z치v캩r: 콯치dn치 statisticky v칳znamn치 po콏adov치 korelace (p 곤 0.05)")
        
        # Interpretace s칤ly korelace
        st.subheader("Interpretace s칤ly korelace")
        
        corr_strength = abs(pearson_r)
        if corr_strength < 0.3:
            strength = "slab치"
        elif corr_strength < 0.6:
            strength = "st콏edn칤"
        elif corr_strength < 0.8:
            strength = "siln치"
        else:
            strength = "velmi siln치"
        
        direction = "pozitivn칤" if pearson_r > 0 else "negativn칤"
        
        st.markdown(f"Mezi prom캩nn칳mi **{x_col}** a **{y_col}** existuje **{strength} {direction}** korelace.")
        
    elif test_type == "t-test":
        # t-test
        st.subheader("t-test")
        
        # V칳b캩r typu t-testu
        t_test_type = st.radio(
            "Vyberte typ t-testu",
            ["Jednov칳b캩rov칳 t-test", "Dvouv칳b캩rov칳 t-test (nez치visl칠 vzorky)", "P치rov칳 t-test"],
            horizontal=True
        )
        
        if t_test_type == "Jednov칳b캩rov칳 t-test":
            if len(eda.numeric_cols) == 0:
                st.warning("Pro jednov칳b캩rov칳 t-test jsou pot콏eba numerick칠 sloupce")
                return
            
            col = st.selectbox("Vyberte sloupec pro test", eda.numeric_cols)
            
            # Referen캜n칤 hodnota
            ref_value = st.number_input("Zadejte referen캜n칤 hodnotu pro porovn치n칤", value=0.0)
            
            # Odstran캩n칤 chyb캩j칤c칤ch hodnot
            clean_data = data[col].dropna()
            if len(clean_data) < 3:
                st.error("Nedostatek dat pro t-test")
                return
            
            # Proveden칤 t-testu
            t_stat, p_value = stats.ttest_1samp(clean_data, ref_value)
            
            # Vizualizace distribuce s referen캜n칤 hodnotou
            fig = px.histogram(
                clean_data,
                title=f"Distribuce {col} s referen캜n칤 hodnotou",
                histnorm='probability density'
            )
            
            # P콏id치n칤 referen캜n칤 hodnoty
            fig.add_vline(x=ref_value, line_dash="dash", line_color="red", annotation_text="Referen캜n칤 hodnota")
            
            # P콏id치n칤 pr콢m캩ru vzorku
            fig.add_vline(x=clean_data.mean(), line_dash="dash", line_color="green", annotation_text="Pr콢m캩r vzorku")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # V칳sledky testu
            st.subheader("V칳sledky jednov칳b캩rov칠ho t-testu")
            st.markdown(f"**Testovan치 hypot칠za:** Pr콢m캩r sloupce *{col}* je roven {ref_value}")
            st.markdown(f"- t-statistika: {t_stat:.4f}")
            st.markdown(f"- p-hodnota: {p_value:.4f}")
            
            if p_value < 0.05:
                st.markdown("**Z치v캩r: Zam칤t치me nulovou hypot칠zu (p < 0.05)**")
                if t_stat > 0:
                    st.markdown(f"Pr콢m캩r sloupce *{col}* je statisticky v칳znamn캩 **v캩t코칤 ne** {ref_value}")
                else:
                    st.markdown(f"Pr콢m캩r sloupce *{col}* je statisticky v칳znamn캩 **men코칤 ne** {ref_value}")
            else:
                st.markdown("**Z치v캩r: Nem콢쬰me zam칤tnout nulovou hypot칠zu (p 곤 0.05)**")
                st.markdown(f"Nem치me dostatek d콢kaz콢, 쬰 pr콢m캩r sloupce *{col}* se li코칤 od {ref_value}")
            
        elif t_test_type == "Dvouv칳b캩rov칳 t-test (nez치visl칠 vzorky)":
            if len(eda.numeric_cols) == 0:
                st.warning("Pro dvouv칳b캩rov칳 t-test jsou pot콏eba numerick칠 sloupce")
                return
            
            # V칳b캩r numerick칠ho sloupce
            num_col = st.selectbox("Vyberte numerick칳 sloupec", eda.numeric_cols)
            
            # V칳b캩r kategorie pro rozd캩len칤 do skupin
            if len(eda.categorical_cols) == 0:
                st.warning("Pro rozd캩len칤 do skupin pot콏ebujete kategorick칳 sloupec")
                return
            
            cat_col = st.selectbox("Vyberte kategorick칳 sloupec pro definici skupin", eda.categorical_cols)
            
            # Z칤sk치n칤 unik치tn칤ch hodnot v kategorick칠m sloupci
            unique_cats = data[cat_col].dropna().unique()
            
            if len(unique_cats) < 2:
                st.error("Kategorick칳 sloupec mus칤 m칤t alespo켿 2 unik치tn칤 hodnoty")
                return
            
            # V칳b캩r dvou skupin pro porovn치n칤
            col1, col2 = st.columns(2)
            
            with col1:
                group1 = st.selectbox("Vyberte prvn칤 skupinu", unique_cats, index=0)
            
            with col2:
                remaining_cats = [cat for cat in unique_cats if cat != group1]
                group2 = st.selectbox("Vyberte druhou skupinu", remaining_cats, index=0)
            
            # P콏칤prava dat pro test
            group1_data = data[data[cat_col] == group1][num_col].dropna()
            group2_data = data[data[cat_col] == group2][num_col].dropna()
            
            if len(group1_data) < 3 or len(group2_data) < 3:
                st.error("Ob캩 skupiny mus칤 m칤t alespo켿 3 hodnoty")
                return
            
            # Proveden칤 Leveneova testu pro rovnost rozptyl콢
            levene_stat, levene_p = stats.levene(group1_data, group2_data)
            
            # Proveden칤 t-testu
            equal_var = levene_p >= 0.05  # Rovnost rozptyl콢, pokud p-hodnota Leveneova testu je >= 0.05
            t_stat, p_value = stats.ttest_ind(group1_data, group2_data, equal_var=equal_var)
            
            # Vizualizace distribuc칤 obou skupin
            hist_data = pd.DataFrame({
                num_col: pd.concat([group1_data, group2_data]),
                'Skupina': [group1] * len(group1_data) + [group2] * len(group2_data)
            })
            
            fig = px.histogram(
                hist_data,
                x=num_col,
                color='Skupina',
                barmode='overlay',
                histnorm='probability density',
                title=f"Distribuce {num_col} pro skupiny {group1} a {group2}"
            )
            
            # P콏id치n칤 pr콢m캩r콢 skupin
            fig.add_vline(x=group1_data.mean(), line_dash="dash", line_color="blue", 
                        annotation_text=f"Pr콢m캩r {group1}")
            fig.add_vline(x=group2_data.mean(), line_dash="dash", line_color="red", 
                        annotation_text=f"Pr콢m캩r {group2}")
            
            st.plotly_chart(fig, use_container_width=True)
            
            # V칳sledky testu
            st.subheader("V칳sledky dvouv칳b캩rov칠ho t-testu")
            
            # Z치kladn칤 statistiky
            st.markdown("**Z치kladn칤 statistiky:**")
            stats_df = pd.DataFrame({
                'Skupina': [group1, group2],
                'Po캜et': [len(group1_data), len(group2_data)],
                'Pr콢m캩r': [group1_data.mean(), group2_data.mean()],
                'Sm캩r. odchylka': [group1_data.std(), group2_data.std()],
                'Min': [group1_data.min(), group2_data.min()],
                'Max': [group1_data.max(), group2_data.max()]
            })
            
            st.dataframe(stats_df)
            
            # V칳sledek Leveneova testu
            st.markdown("**Levene콢v test rovnosti rozptyl콢:**")
            st.markdown(f"- Statistika: {levene_stat:.4f}")
            st.markdown(f"- p-hodnota: {levene_p:.4f}")
            if levene_p < 0.05:
                st.markdown("- Z치v캩r: Rozptyly nejsou stejn칠 (pou쬴t Welch콢v t-test)")
            else:
                st.markdown("- Z치v캩r: Rozptyly jsou p콏ibli쬹캩 stejn칠 (pou쬴t standardn칤 t-test)")
            
            # V칳sledek t-testu
            st.markdown("**T-test:**")
            st.markdown(f"- t-statistika: {t_stat:.4f}")
            st.markdown(f"- p-hodnota: {p_value:.4f}")
            
            if p_value < 0.05:
                st.markdown("**Z치v캩r: Zam칤t치me nulovou hypot칠zu (p < 0.05)**")
                st.markdown(f"Pr콢m캩ry sloupce *{num_col}* se statisticky v칳znamn캩 li코칤 mezi skupinami *{group1}* a *{group2}*")
                
                # Velikost efektu (Cohen's d)
                pooled_std = np.sqrt((group1_data.var() * (len(group1_data) - 1) + 
                                    group2_data.var() * (len(group2_data) - 1)) / 
                                    (len(group1_data) + len(group2_data) - 2))
                cohen_d = abs(group1_data.mean() - group2_data.mean()) / pooled_std
                
                st.markdown(f"**Velikost efektu (Cohen's d):** {cohen_d:.4f}")
                if cohen_d < 0.2:
                    st.markdown("Interpretace: Velmi mal칳 efekt")
                elif cohen_d < 0.5:
                    st.markdown("Interpretace: Mal칳 efekt")
                elif cohen_d < 0.8:
                    st.markdown("Interpretace: St콏edn칤 efekt")
                else:
                    st.markdown("Interpretace: Velk칳 efekt")
            else:
                st.markdown("**Z치v캩r: Nem콢쬰me zam칤tnout nulovou hypot칠zu (p 곤 0.05)**")
                st.markdown(f"Nem치me dostatek d콢kaz콢, 쬰 pr콢m캩ry sloupce *{num_col}* se li코칤 mezi skupinami *{group1}* a *{group2}*")
        
        elif t_test_type == "P치rov칳 t-test":
            if len(eda.numeric_cols) < 2:
                st.warning("Pro p치rov칳 t-test jsou pot콏eba alespo켿 2 numerick칠 sloupce")
                return
            
            col1, col2 = st.columns(2)
            
            with col1:
                first_col = st.selectbox("Vyberte prvn칤 prom캩nnou (p콏ed)", eda.numeric_cols, key="paired_first")
            
            with col2:
                second_col = st.selectbox("Vyberte druhou prom캩nnou (po)", 
                                        [col for col in eda.numeric_cols if col != first_col], 
                                        key="paired_second")
            
            # Odstran캩n칤 chyb캩j칤c칤ch hodnot (mus칤 m칤t oba sloupce hodnoty)
            paired_data = data[[first_col, second_col]].dropna()
            
            if len(paired_data) < 3:
                st.error("Nedostatek p치rovan칳ch hodnot pro t-test")
                return
            
            # Proveden칤 p치rov칠ho t-testu
            t_stat, p_value = stats.ttest_rel(paired_data[first_col], paired_data[second_col])
            
            # Vizualizace rozlo쬰n칤 obou prom캩nn칳ch
            fig1 = px.histogram(
                paired_data,
                x=[first_col, second_col],
                barmode='overlay',
                histnorm='probability density',
                title=f"Distribuce {first_col} a {second_col}"
            )
            
            # P콏id치n칤 pr콢m캩r콢
            fig1.add_vline(x=paired_data[first_col].mean(), line_dash="dash", line_color="blue", 
                         annotation_text=f"Pr콢m캩r {first_col}")
            fig1.add_vline(x=paired_data[second_col].mean(), line_dash="dash", line_color="red", 
                         annotation_text=f"Pr콢m캩r {second_col}")
            
            # Scatter plot pro p치rovan칠 hodnoty
            fig2 = px.scatter(
                paired_data,
                x=first_col,
                y=second_col,
                title=f"P치rovan칠 hodnoty {first_col} vs {second_col}"
            )
            
            # P콏id치n칤 diagon치ln칤 캜치ry (x=y)
            fig2.add_trace(go.Scatter(
                x=[paired_data[[first_col, second_col]].min().min(), 
                   paired_data[[first_col, second_col]].max().max()],
                y=[paired_data[[first_col, second_col]].min().min(), 
                   paired_data[[first_col, second_col]].max().max()],
                mode='lines',
                line=dict(color='black', dash='dash'),
                name='x=y'
            ))
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.plotly_chart(fig1, use_container_width=True)
            
            with col2:
                st.plotly_chart(fig2, use_container_width=True)
            
            # V칳sledky testu
            st.subheader("V칳sledky p치rov칠ho t-testu")
            
            # Z치kladn칤 statistiky
            mean_diff = paired_data[first_col].mean() - paired_data[second_col].mean()
            
            st.markdown("**Z치kladn칤 statistiky:**")
            stats_df = pd.DataFrame({
                'Prom캩nn치': [first_col, second_col, "Rozd칤l (A-B)"],
                'Pr콢m캩r': [paired_data[first_col].mean(), 
                          paired_data[second_col].mean(),
                          mean_diff],
                'Sm캩r. odchylka': [paired_data[first_col].std(), 
                                 paired_data[second_col].std(),
                                 (paired_data[first_col] - paired_data[second_col]).std()]
            })
            
            st.dataframe(stats_df)
            
            # V칳sledek t-testu
            st.markdown("**P치rov칳 t-test:**")
            st.markdown(f"- t-statistika: {t_stat:.4f}")
            st.markdown(f"- p-hodnota: {p_value:.4f}")
            
            if p_value < 0.05:
                st.markdown("**Z치v캩r: Zam칤t치me nulovou hypot칠zu (p < 0.05)**")
                if mean_diff > 0:
                    st.markdown(f"*{first_col}* je statisticky v칳znamn캩 **v캩t코칤 ne** *{second_col}*")
                else:
                    st.markdown(f"*{first_col}* je statisticky v칳znamn캩 **men코칤 ne** *{second_col}*")
                
                # Velikost efektu (Cohen's d pro p치rov칠 testy)
                diff = paired_data[first_col] - paired_data[second_col]
                cohen_d = abs(diff.mean()) / diff.std()
                
                st.markdown(f"**Velikost efektu (Cohen's d):** {cohen_d:.4f}")
                if cohen_d < 0.2:
                    st.markdown("Interpretace: Velmi mal칳 efekt")
                elif cohen_d < 0.5:
                    st.markdown("Interpretace: Mal칳 efekt")
                elif cohen_d < 0.8:
                    st.markdown("Interpretace: St콏edn칤 efekt")
                else:
                    st.markdown("Interpretace: Velk칳 efekt")
            else:
                st.markdown("**Z치v캩r: Nem콢쬰me zam칤tnout nulovou hypot칠zu (p 곤 0.05)**")
                st.markdown(f"Nem치me dostatek d콢kaz콢, 쬰 se *{first_col}* a *{second_col}* li코칤")
    
    elif test_type == "ANOVA":
        # ANOVA test
        st.subheader("Jednofaktorov치 ANOVA")
        
        if len(eda.numeric_cols) == 0:
            st.warning("Pro ANOVA test jsou pot콏eba numerick칠 sloupce")
            return
        
        if len(eda.categorical_cols) == 0:
            st.warning("Pro ANOVA test jsou pot콏eba kategorick칠 sloupce jako faktory")
            return
        
        # V칳b캩r numeric a kategori치ln칤ho sloupce
        num_col = st.selectbox("Vyberte numerick칳 sloupec (z치visl치 prom캩nn치)", eda.numeric_cols)
        cat_col = st.selectbox("Vyberte kategorick칳 sloupec (faktor)", eda.categorical_cols)
        
        # P콏칤prava dat pro ANOVA
        anova_data = data[[num_col, cat_col]].dropna()
        
        if len(anova_data) < 3:
            st.error("Nedostatek dat pro ANOVA test")
            return
        
        # Kontrola, zda m치me alespo켿 dv캩 skupiny
        groups = anova_data[cat_col].unique()
        if len(groups) < 2:
            st.error("Pro ANOVA test pot콏ebujete alespo켿 2 skupiny")
            return
        
        # P콏eveden칤 dat do form치tu vhodn칠ho pro ANOVA
        anova_groups = [anova_data[anova_data[cat_col] == group][num_col].values for group in groups]
        
        # Proveden칤 ANOVA testu
        f_stat, p_value = stats.f_oneway(*anova_groups)
        
        # Vizualizace - box plot
        fig = px.box(
            anova_data,
            x=cat_col,
            y=num_col,
            title=f"Porovn치n칤 {num_col} podle {cat_col}",
            points="all"
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # V칳sledky testu
        st.subheader("V칳sledky ANOVA testu")
        
        # Z치kladn칤 statistiky podle skupin
        group_stats = anova_data.groupby(cat_col)[num_col].agg(['count', 'mean', 'std']).reset_index()
        st.markdown("**Statistiky podle skupin:**")
        st.dataframe(group_stats)
        
        # V칳sledek ANOVA
        st.markdown("**ANOVA:**")
        st.markdown(f"- F-statistika: {f_stat:.4f}")
        st.markdown(f"- p-hodnota: {p_value:.4f}")
        
        if p_value < 0.05:
            st.markdown("**Z치v캩r: Zam칤t치me nulovou hypot칠zu (p < 0.05)**")
            st.markdown(f"Existuje statisticky v칳znamn칳 rozd칤l v *{num_col}* mezi skupinami *{cat_col}*")
            
            # Post-hoc test (Tukey's HSD)
            from statsmodels.stats.multicomp import pairwise_tukeyhsd
            
            posthoc = pairwise_tukeyhsd(anova_data[num_col], anova_data[cat_col], alpha=0.05)
            
            st.markdown("**Post-hoc test (Tukey HSD):**")
            # P콏evod objektu posthoc na DataFrame
            posthoc_df = pd.DataFrame(data=posthoc._results_table.data[1:], columns=posthoc._results_table.data[0])
            st.dataframe(posthoc_df)
            
            # Interpretace v칳sledk콢 post-hoc testu
            st.markdown("**Interpretace post-hoc testu:**")
            significant_pairs = posthoc_df[posthoc_df['reject'] == True]
            if len(significant_pairs) > 0:
                for _, row in significant_pairs.iterrows():
                    st.markdown(f"- Skupiny *{row['group1']}* a *{row['group2']}* se statisticky v칳znamn캩 li코칤 (p < 0.05)")
            else:
                st.markdown("- 콯치dn칠 p치ry skupin nevykazuj칤 statisticky v칳znamn칠 rozd칤ly v post-hoc testu")
        else:
            st.markdown("**Z치v캩r: Nem콢쬰me zam칤tnout nulovou hypot칠zu (p 곤 0.05)**")
            st.markdown(f"Nem치me dostatek d콢kaz콢, 쬰 se *{num_col}* li코칤 mezi skupinami *{cat_col}*")
    
    elif test_type == "Chi-kvadr치t":
        # Chi-kvadr치t test
        st.subheader("Chi-kvadr치t test")
        
        if len(eda.categorical_cols) < 2:
            st.warning("Pro Chi-kvadr치t test jsou pot콏eba alespo켿 2 kategorick칠 sloupce")
            return
        
        # V칳b캩r dvou kategorick칳ch sloupc콢
        col1, col2 = st.columns(2)
        
        with col1:
            first_cat = st.selectbox("Vyberte prvn칤 kategorick칳 sloupec", eda.categorical_cols, key="chi_first")
        
        with col2:
            second_cat = st.selectbox("Vyberte druh칳 kategorick칳 sloupec", 
                                    [col for col in eda.categorical_cols if col != first_cat], 
                                    key="chi_second")
        
        # P콏칤prava dat pro chi-kvadr치t test
        chi_data = data[[first_cat, second_cat]].dropna()
        
        if len(chi_data) < 10:
            st.error("Nedostatek dat pro Chi-kvadr치t test")
            return
        
        # Vytvo콏en칤 kontingen캜n칤 tabulky
        contingency_table = pd.crosstab(chi_data[first_cat], chi_data[second_cat])
        
        # Kontrola 캜etnost칤
        if (contingency_table < 5).any().any():
            st.warning("N캩kter칠 bu켿ky maj칤 o캜ek치vanou 캜etnost m칠n캩 ne 5, co m콢쬰 ovlivnit v칳sledky testu")
        
        # Proveden칤 chi-kvadr치t testu
        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
        
        # Vizualizace - heatmapa kontingen캜n칤 tabulky
        fig = px.imshow(
            contingency_table,
            title=f"Kontingen캜n칤 tabulka: {first_cat} vs {second_cat}",
            labels=dict(x=second_cat, y=first_cat, color="캛etnost")
        )
        
        # P콏idat hodnoty do bun캩k
        for i in range(contingency_table.shape[0]):
            for j in range(contingency_table.shape[1]):
                fig.add_annotation(
                    x=j,
                    y=i,
                    text=str(contingency_table.iloc[i, j]),
                    showarrow=False,
                    font=dict(color="white" if contingency_table.iloc[i, j] > contingency_table.values.mean() else "black")
                )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Vizualizace - sloupcov칳 graf
        proportions = pd.crosstab(
            chi_data[first_cat], 
            chi_data[second_cat], 
            normalize='index'
        ).reset_index().melt(
            id_vars=first_cat,
            var_name=second_cat,
            value_name='Proportion'
        )
        
        fig2 = px.bar(
            proportions,
            x=first_cat,
            y='Proportion',
            color=second_cat,
            title=f"Rozlo쬰n칤 {second_cat}",
            labels={'Proportion': 'Pod칤l'}
        )
        
        fig2.update_layout(yaxis_tickformat='.0%')
        
        st.plotly_chart(fig2, use_container_width=True)
        
        # V칳sledky testu
        st.subheader("V칳sledky Chi-kvadr치t testu")
        
        # Kontingen캜n칤 tabulka
        st.markdown("**Kontingen캜n칤 tabulka (캜etnosti):**")
        st.dataframe(contingency_table)
        
        # O캜ek치van칠 캜etnosti
        st.markdown("**O캜ek치van칠 캜etnosti za p콏edpokladu nez치vislosti:**")
        expected_df = pd.DataFrame(
            expected, 
            index=contingency_table.index, 
            columns=contingency_table.columns
        )
        st.dataframe(expected_df.round(2))
        
        # V칳sledek chi-kvadr치t testu
        st.markdown("**Chi-kvadr치t test:**")
        st.markdown(f"- Chi-kvadr치t statistika: {chi2:.4f}")
        st.markdown(f"- Stupn캩 volnosti: {dof}")
        st.markdown(f"- p-hodnota: {p_value:.4f}")
        
        if p_value < 0.05:
            st.markdown("**Z치v캩r: Zam칤t치me nulovou hypot칠zu (p < 0.05)**")
            st.markdown(f"Existuje statisticky v칳znamn치 asociace mezi *{first_cat}* a *{second_cat}*")
            
            # M칤ra asociace - Cramer's V
            n = chi_data.shape[0]
            min_dim = min(contingency_table.shape) - 1
            cramer_v = np.sqrt(chi2 / (n * min_dim))
            
            st.markdown(f"**S칤la asociace (Cramer's V):** {cramer_v:.4f}")
            if cramer_v < 0.1:
                st.markdown("Interpretace: Zanedbateln치 asociace")
            elif cramer_v < 0.3:
                st.markdown("Interpretace: Slab치 asociace")
            elif cramer_v < 0.5:
                st.markdown("Interpretace: St콏edn칤 asociace")
            else:
                st.markdown("Interpretace: Siln치 asociace")
        else:
            st.markdown("**Z치v캩r: Nem콢쬰me zam칤tnout nulovou hypot칠zu (p 곤 0.05)**")
            st.markdown(f"Nem치me dostatek d콢kaz콢, 쬰 existuje asociace mezi *{first_cat}* a *{second_cat}*")

def zobraz_navrhy_uprav():
    st.header("N치vrhy 칰prav dat")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # P콏칤prava n치vrh콢 칰prav
    st.subheader("N치vrhy transformac칤 dat")
    
    # Detekce ze코ikmen칤 v numerick칳ch sloupc칤ch
    skewed_columns = []
    for col in eda.numeric_cols:
        clean_data = data[col].dropna()
        if len(clean_data) >= 5:
            skewness = stats.skew(clean_data)
            if abs(skewness) > 1:
                skewed_columns.append({
                    'column': col,
                    'skewness': skewness,
                    'type': 'positive' if skewness > 0 else 'negative'
                })
    
    if skewed_columns:
        st.markdown("### Ze코ikmen칠 sloupce")
        st.markdown("N치sleduj칤c칤 sloupce maj칤 zna캜n캩 ze코ikmenou distribuci, kter치 m콢쬰 ovlivnit statistick칠 anal칳zy:")
        
        skewed_df = pd.DataFrame(skewed_columns)
        st.dataframe(skewed_df)
        
        # Uk치zka transformac칤
        if len(skewed_columns) > 0:
            selected_col = st.selectbox(
                "Vyberte sloupec pro n치hled transformac칤",
                [col['column'] for col in skewed_columns]
            )
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**P콢vodn칤 distribuce**")
                fig = px.histogram(
                    data[selected_col].dropna(),
                    title=f"P콢vodn칤 distribuce: {selected_col}",
                    histnorm='probability density'
                )
                st.plotly_chart(fig, use_container_width=True)
            
            # N치vrhy transformac칤
            with col2:
                # Identifikace typu ze코ikmen칤
                skewness = data[selected_col].skew()
                
                if skewness > 1:  # Pravostrann캩 ze코ikmen칠
                    st.markdown("**Logaritmick치 transformace**")
                    
                    # P콏evod na kladn칠 hodnoty pro logaritmickou transformaci
                    min_val = data[selected_col].min()
                    offset = 0 if min_val > 0 else abs(min_val) + 1
                    log_data = np.log(data[selected_col] + offset)
                    
                    fig = px.histogram(
                        log_data.dropna(),
                        title=f"Log transformace: log({selected_col} + {offset})",
                        histnorm='probability density'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.code(f"""
# Logaritmick치 transformace
min_val = data['{selected_col}'].min()
offset = 0 if min_val > 0 else abs(min_val) + 1
data['{selected_col}_log'] = np.log(data['{selected_col}'] + offset)
                    """)
                    
                    st.markdown("**Odmocninov치 transformace**")
                    sqrt_data = np.sqrt(data[selected_col] + offset)
                    
                    fig = px.histogram(
                        sqrt_data.dropna(),
                        title=f"Odmocninov치 transformace: sqrt({selected_col} + {offset})",
                        histnorm='probability density'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.code(f"""
# Odmocninov치 transformace
min_val = data['{selected_col}'].min()
offset = 0 if min_val > 0 else abs(min_val) + 1
data['{selected_col}_sqrt'] = np.sqrt(data['{selected_col}'] + offset)
                    """)
                    
                elif skewness < -1:  # Levostrann캩 ze코ikmen칠
                    st.markdown("**Kvadratick치 transformace**")
                    
                    square_data = data[selected_col] ** 2
                    
                    fig = px.histogram(
                        square_data.dropna(),
                        title=f"Kvadratick치 transformace: {selected_col}^2",
                        histnorm='probability density'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.code(f"""
# Kvadratick치 transformace
data['{selected_col}_squared'] = data['{selected_col}'] ** 2
                    """)
    
    # Chyb캩j칤c칤 hodnoty
    st.markdown("### 콎e코en칤 chyb캩j칤c칤ch hodnot")
    
    if not hasattr(eda, 'missing_analysis'):
        eda.analyze_missing_values()
    
    missing_cols = eda.missing_analysis[eda.missing_analysis['Missing Values'] > 0]
    
    if len(missing_cols) > 0:
        missing_df = missing_cols.reset_index()
        missing_df.columns = ['Sloupec', 'Chyb캩j칤c칤 hodnoty', 'Procento chyb캩j칤c칤ch']
        
        st.dataframe(missing_df)
        
        st.markdown("**Doporu캜en칠 techniky imputace:**")
        
        for _, row in missing_df.iterrows():
            col_name = row['Sloupec']
            missing_pct = row['Procento chyb캩j칤c칤ch']
            
            if missing_pct > 50:
                st.markdown(f"- **{col_name}** ({missing_pct:.1f}% chyb캩j칤c칤ch): Zva쬾e odstran캩n칤 sloupce")
            elif col_name in eda.numeric_cols:
                st.markdown(f"- **{col_name}** ({missing_pct:.1f}% chyb캩j칤c칤ch): Imputace medi치nem nebo pr콢m캩rem")
                st.code(f"""
# Imputace medi치nem
data['{col_name}'] = data['{col_name}'].fillna(data['{col_name}'].median())

# NEBO: Imputace pr콢m캩rem
# data['{col_name}'] = data['{col_name}'].fillna(data['{col_name}'].mean())
                """)
            elif col_name in eda.categorical_cols:
                st.markdown(f"- **{col_name}** ({missing_pct:.1f}% chyb캩j칤c칤ch): Imputace nej캜ast캩j코칤 hodnotou nebo novou kategori칤 'Chyb캩j칤c칤'")
                st.code(f"""
# Imputace nej캜ast캩j코칤 hodnotou
data['{col_name}'] = data['{col_name}'].fillna(data['{col_name}'].mode()[0])

# NEBO: Vytvo콏en칤 nov칠 kategorie pro chyb캩j칤c칤 hodnoty
# data['{col_name}'] = data['{col_name}'].fillna('Chyb캩j칤c칤')
                """)
    else:
        st.success("V datasetu nebyly nalezeny 쮂멳n칠 chyb캩j칤c칤 hodnoty!")
    
    # N치vrh nov칳ch p콏칤znak콢 pro kategorick칠 sloupce
    st.markdown("### N치vrhy k칩dov치n칤 kategorick칳ch prom캩nn칳ch")
    
    if len(eda.categorical_cols) > 0:
        cat_cols_info = []
        for col in eda.categorical_cols:
            unique_values = data[col].nunique()
            cat_cols_info.append({
                'column': col,
                'unique_values': unique_values
            })
        
        cat_cols_df = pd.DataFrame(cat_cols_info)
        st.dataframe(cat_cols_df)
        
        for col in eda.categorical_cols:
            unique_values = data[col].nunique()
            
            st.markdown(f"**{col}** ({unique_values} unik치tn칤ch hodnot):")
            
            if unique_values == 2:
                st.markdown("Doporu캜en칤: Bin치rn칤 k칩dov치n칤 (0/1)")
                st.code(f"""
# Bin치rn칤 k칩dov치n칤
data['{col}_binary'] = data['{col}'].map({{'{data[col].unique()[0]}': 0, '{data[col].unique()[1]}': 1}})
                """)
            elif 2 < unique_values <= 10:
                st.markdown("Doporu캜en칤: One-hot encoding")
                st.code(f"""
# One-hot encoding
data_encoded = pd.get_dummies(data['{col}'], prefix='{col}')
data = pd.concat([data, data_encoded], axis=1)
                """)
            else:
                st.markdown("Doporu캜en칤: Target encoding nebo Frequency encoding")
                st.code(f"""
# Frequency encoding
frequency_map = data['{col}'].value_counts(normalize=True).to_dict()
data['{col}_freq'] = data['{col}'].map(frequency_map)

# Target encoding (pokud m치te c칤lovou prom캩nnou)
target_means = data.groupby('{col}')['target_variable'].mean().to_dict()
data['{col}_target'] = data['{col}'].map(target_means)
                """)
    
    # N치vrhy pro odlehl칠 hodnoty
    st.markdown("### 콎e코en칤 odlehl칳ch hodnot")
    
    if not hasattr(eda, 'outlier_summary'):
        eda.detect_outliers()
    
    if hasattr(eda, 'outlier_summary') and len(eda.outlier_summary) > 0:
        outlier_data = []
        for col, info in eda.outlier_summary.items():
            outlier_data.append({
                'column': col,
                'outlier_count': info['count'],
                'outlier_percent': info['percent']
            })
        
        outlier_df = pd.DataFrame(outlier_data)
        st.dataframe(outlier_df)
        
        for col, info in eda.outlier_summary.items():
            if info['percent'] > 5:
                st.markdown(f"**{col}** ({info['percent']:.1f}% odlehl칳ch hodnot): Zva쬾e transformaci dat")
            elif info['percent'] > 1:
                st.markdown(f"**{col}** ({info['percent']:.1f}% odlehl칳ch hodnot): O콏칤znut칤 (winsorizing)")
                st.code(f"""
# O콏칤znut칤 (winsorizing)
lower_bound = {info['lower_bound']:.4f}
upper_bound = {info['upper_bound']:.4f}
data['{col}_winsorized'] = data['{col}'].clip(lower_bound, upper_bound)
                """)
            else:
                st.markdown(f"**{col}** ({info['percent']:.1f}% odlehl칳ch hodnot): Odstran캩n칤 nebo ozna캜en칤 jako outlier")
                st.code(f"""
# Ozna캜en칤 odlehl칳ch hodnot
lower_bound = {info['lower_bound']:.4f}
upper_bound = {info['upper_bound']:.4f}
data['{col}_is_outlier'] = ((data['{col}'] < lower_bound) | (data['{col}'] > upper_bound))

# Alternativn캩: Odstran캩n칤 odlehl칳ch hodnot
# data_clean = data[~((data['{col}'] < lower_bound) | (data['{col}'] > upper_bound))]
                """)
    else:
        st.success("V datasetu nebyly nalezeny 쮂멳n칠 v칳razn칠 odlehl칠 hodnoty!")

def zobraz_rychle_modelovani():
    st.header("Rychl칠 modelov치n칤")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.numeric_cols) < 2:
        st.warning("Pro modelov치n칤 jsou pot콏eba alespo켿 2 numerick칠 sloupce.")
        return
    
    # Nastaven칤 modelu
    st.subheader("Nastaven칤 modelov치n칤")
    
    # V칳b캩r c칤lov칠 prom캩nn칠
    target_options = eda.numeric_cols + eda.categorical_cols
    target_col = st.selectbox("Vyberte c칤lovou prom캩nnou", target_options)
    
    # V칳b캩r p콏칤znak콢
    feature_cols = st.multiselect(
        "Vyberte p콏칤znaky pro model",
        [col for col in eda.numeric_cols if col != target_col],
        default=[col for col in eda.numeric_cols if col != target_col][:min(5, len(eda.numeric_cols))]
    )
    
    # V칳b캩r typu modelu
    is_classification = target_col in eda.categorical_cols
    
    if is_classification:
        model_type = st.selectbox(
            "Vyberte typ modelu",
            ["Logistick치 regrese", "Random Forest", "SVM"]
        )
    else:
        model_type = st.selectbox(
            "Vyberte typ modelu",
            ["Line치rn칤 regrese", "Random Forest", "SVM"]
        )
    
    # Nastaven칤 velikosti testovac칤ho datasetu
    test_size = st.slider("Velikost testovac칤ho datasetu", 0.1, 0.5, 0.2, 0.05)
    
    # Tla캜칤tko pro tr칠nov치n칤 modelu
    train_button = st.button("Tr칠novat model")
    
    if train_button:
        if len(feature_cols) == 0:
            st.error("Vyberte alespo켿 jeden p콏칤znak pro model")
            return
        
        with st.spinner("Prob칤h치 tr칠nov치n칤 modelu..."):
            from sklearn.model_selection import train_test_split
            from sklearn.preprocessing import StandardScaler
            
            # P콏칤prava dat
            X = data[feature_cols].copy()
            y = data[target_col].copy()
            
            # Odstran캩n칤 chyb캩j칤c칤ch hodnot
            X = X.fillna(X.mean())
            
            # Pro klasifikaci pot콏ebujeme kategorick칠 c칤le
            if is_classification:
                # Pokud c칤l obsahuje chyb캩j칤c칤 hodnoty, odstran칤me je
                valid_idx = y.notna()
                X = X[valid_idx]
                y = y[valid_idx]
            else:
                # Pro regresi tak칠 odstran칤me chyb캩j칤c칤 hodnoty v c칤li
                valid_idx = y.notna()
                X = X[valid_idx]
                y = y[valid_idx]
            
            if len(X) < 50:
                st.error("Nedostatek dat pro tr칠nov치n칤 modelu (m칠n캩 ne 50 platn칳ch 콏치dk콢)")
                return
            
            # Rozd캩len칤 na tr칠novac칤 a testovac칤 data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            
            # Standardizace dat
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # V칳b캩r a tr칠nink modelu
            if is_classification:
                from sklearn.linear_model import LogisticRegression
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.svm import SVC
                from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
                
                if model_type == "Logistick치 regrese":
                    model = LogisticRegression(max_iter=1000, random_state=42)
                elif model_type == "Random Forest":
                    model = RandomForestClassifier(n_estimators=100, random_state=42)
                else:  # SVM
                    model = SVC(probability=True, random_state=42)
                
                # Tr칠nov치n칤 modelu
                model.fit(X_train_scaled, y_train)
                
                # Predikce
                y_train_pred = model.predict(X_train_scaled)
                y_test_pred = model.predict(X_test_scaled)
                
                # Vyhodnocen칤
                train_accuracy = accuracy_score(y_train, y_train_pred)
                test_accuracy = accuracy_score(y_test, y_test_pred)
                
                # Zobrazen칤 v칳sledk콢
                st.subheader("V칳sledky klasifika캜n칤ho modelu")
                
                col1, col2 = st.columns(2)
                col1.metric("P콏esnost na tr칠novac칤ch datech", f"{train_accuracy:.4f}")
                col2.metric("P콏esnost na testovac칤ch datech", f"{test_accuracy:.4f}")
                
                # Matice z치m캩n
                st.markdown("**Matice z치m캩n**")
                cm = confusion_matrix(y_test, y_test_pred)
                cm_df = pd.DataFrame(cm, 
                                   index=[f'Skute캜n치 {i}' for i in sorted(y.unique())], 
                                   columns=[f'Predikce {i}' for i in sorted(y.unique())])
                
                fig = px.imshow(
                    cm,
                    labels=dict(x="Predikovan치 t콏칤da", y="Skute캜n치 t콏칤da", color="Po캜et"),
                    x=[f'Predikce {i}' for i in sorted(y.unique())],
                    y=[f'Skute캜n치 {i}' for i in sorted(y.unique())],
                    title="Matice z치m캩n"
                )
                
                for i in range(len(cm)):
                    for j in range(len(cm[i])):
                        fig.add_annotation(
                            x=j, y=i,
                            text=str(cm[i, j]),
                            showarrow=False,
                            font=dict(color="white" if cm[i, j] > cm.mean() else "black")
                        )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Klasifika캜n칤 report
                st.markdown("**Klasifika캜n칤 report**")
                report = classification_report(y_test, y_test_pred, output_dict=True)
                report_df = pd.DataFrame(report).T
                st.dataframe(report_df)
                
            else:
                from sklearn.linear_model import LinearRegression
                from sklearn.ensemble import RandomForestRegressor
                from sklearn.svm import SVR
                from sklearn.metrics import mean_squared_error, r2_score
                
                if model_type == "Line치rn칤 regrese":
                    model = LinearRegression()
                elif model_type == "Random Forest":
                    model = RandomForestRegressor(n_estimators=100, random_state=42)
                else:  # SVM
                    model = SVR()
                
                # Tr칠nov치n칤 modelu
                model.fit(X_train_scaled, y_train)
                
                # Predikce
                y_train_pred = model.predict(X_train_scaled)
                y_test_pred = model.predict(X_test_scaled)
                
                # Vyhodnocen칤
                train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                train_r2 = r2_score(y_train, y_train_pred)
                test_r2 = r2_score(y_test, y_test_pred)
                
                # Zobrazen칤 v칳sledk콢
                st.subheader("V칳sledky regresn칤ho modelu")
                
                col1, col2 = st.columns(2)
                col1.metric("RMSE na tr칠novac칤ch datech", f"{train_rmse:.4f}")
                col2.metric("RMSE na testovac칤ch datech", f"{test_rmse:.4f}")
                
                col1, col2 = st.columns(2)
                col1.metric("R na tr칠novac칤ch datech", f"{train_r2:.4f}")
                col2.metric("R na testovac칤ch datech", f"{test_r2:.4f}")
                
                # Scatter plot predikovan칳ch vs. skute캜n칳ch hodnot
                plot_data = pd.DataFrame({
                    'Skute캜n칠 hodnoty': y_test,
                    'Predikovan칠 hodnoty': y_test_pred
                })
                
                fig = px.scatter(
                    plot_data,
                    x='Skute캜n칠 hodnoty',
                    y='Predikovan칠 hodnoty',
                    title="Predikovan칠 vs. skute캜n칠 hodnoty"
                )
                
                # P콏id치n칤 diagon치ln칤 캜치ry (ide치ln칤 predikce)
                fig.add_trace(go.Scatter(
                    x=[plot_data['Skute캜n칠 hodnoty'].min(), plot_data['Skute캜n칠 hodnoty'].max()],
                    y=[plot_data['Skute캜n칠 hodnoty'].min(), plot_data['Skute캜n칠 hodnoty'].max()],
                    mode='lines',
                    line=dict(color='red', dash='dash'),
                    name='Ide치ln칤 predikce'
                ))
                
                st.plotly_chart(fig, use_container_width=True)
            
            # D콢le쬴tost p콏칤znak콢 (pro modely, kter칠 to podporuj칤)
            if hasattr(model, 'feature_importances_') or hasattr(model, 'coef_'):
                st.subheader("D콢le쬴tost p콏칤znak콢")
                
                if hasattr(model, 'feature_importances_'):
                    importances = model.feature_importances_
                else:  # Linear model coefficients
                    importances = np.abs(model.coef_)
                    if importances.ndim > 1:  # Pro multiclass logistickou regresi
                        importances = np.mean(np.abs(importances), axis=0)
                
                importance_df = pd.DataFrame({
                    'P콏칤znak': feature_cols,
                    'D콢le쬴tost': importances
                }).sort_values('D콢le쬴tost', ascending=False)
                
                fig = px.bar(
                    importance_df,
                    x='D콢le쬴tost',
                    y='P콏칤znak',
                    orientation='h',
                    title="D콢le쬴tost p콏칤znak콢"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(importance_df)
                
                # Nejd콢le쬴t캩j코칤 p콏칤znaky
                top_features = importance_df.head(3)['P콏칤znak'].tolist()
                st.markdown(f"**Nejd콢le쬴t캩j코칤 p콏칤znaky:** {', '.join(top_features)}")
            
            # Uk치zka k칩du pro pou쬴t칤 modelu
            st.subheader("K칩d pro tr칠nov치n칤 podobn칠ho modelu")
            
            code_tab1, code_tab2 = st.tabs(["Python", "R"])
            
            with code_tab1:
                python_code = f"""
# Python k칩d pro tr칠nov치n칤 {model_type}

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
"""
                # P콏id치n칤 importu podle typu modelu
                if is_classification:
                    if model_type == "Logistick치 regrese":
                        python_code += "from sklearn.linear_model import LogisticRegression\n"
                        python_code += "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n"
                        python_code += f"# Definice modelu\nmodel = LogisticRegression(max_iter=1000, random_state=42)\n"
                    elif model_type == "Random Forest":
                        python_code += "from sklearn.ensemble import RandomForestClassifier\n"
                        python_code += "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n"
                        python_code += f"# Definice modelu\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n"
                    else:  # SVM
                        python_code += "from sklearn.svm import SVC\n"
                        python_code += "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n"
                        python_code += f"# Definice modelu\nmodel = SVC(probability=True, random_state=42)\n"
                else:
                    if model_type == "Line치rn칤 regrese":
                        python_code += "from sklearn.linear_model import LinearRegression\n"
                        python_code += "from sklearn.metrics import mean_squared_error, r2_score\n\n"
                        python_code += f"# Definice modelu\nmodel = LinearRegression()\n"
                    elif model_type == "Random Forest":
                        python_code += "from sklearn.ensemble import RandomForestRegressor\n"
                        python_code += "from sklearn.metrics import mean_squared_error, r2_score\n\n"
                        python_code += f"# Definice modelu\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\n"
                    else:  # SVM
                        python_code += "from sklearn.svm import SVR\n"
                        python_code += "from sklearn.metrics import mean_squared_error, r2_score\n\n"
                        python_code += f"# Definice modelu\nmodel = SVR()\n"
                
                # P콏칤prava dat
                python_code += f"""
# P콏칤prava dat
feature_cols = {feature_cols}
X = data[feature_cols].copy()
y = data['{target_col}'].copy()

# O코et콏en칤 chyb캩j칤c칤ch hodnot
X = X.fillna(X.mean())
valid_idx = y.notna()
X = X[valid_idx]
y = y[valid_idx]

# Rozd캩len칤 dat
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size={test_size}, random_state=42)

# Standardizace
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Tr칠nov치n칤 modelu
model.fit(X_train_scaled, y_train)

# Predikce
y_train_pred = model.predict(X_train_scaled)
y_test_pred = model.predict(X_test_scaled)
"""
                
                # K칩d pro vyhodnocen칤
                if is_classification:
                    python_code += """
# Vyhodnocen칤 klasifikace
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"P콏esnost na tr칠novac칤ch datech: {train_accuracy:.4f}")
print(f"P콏esnost na testovac칤ch datech: {test_accuracy:.4f}")
print("\\nKlasifika캜n칤 report:")
print(classification_report(y_test, y_test_pred))
print("\\nMatice z치m캩n:")
print(confusion_matrix(y_test, y_test_pred))
"""
                else:
                    python_code += """
# Vyhodnocen칤 regrese
train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
train_r2 = r2_score(y_train, y_train_pred)
test_r2 = r2_score(y_test, y_test_pred)

print(f"RMSE na tr칠novac칤ch datech: {train_rmse:.4f}")
print(f"RMSE na testovac칤ch datech: {test_rmse:.4f}")
print(f"R na tr칠novac칤ch datech: {train_r2:.4f}")
print(f"R na testovac칤ch datech: {test_r2:.4f}")
"""
                
                st.code(python_code, language="python")
            
            with code_tab2:
                r_code = f"""
# R k칩d pro tr칠nov치n칤 {model_type}

library(tidyverse)
library(caret)
"""
                # P콏id치n칤 importu podle typu modelu
                if is_classification:
                    if model_type == "Logistick치 regrese":
                        r_code += "# Logistick치 regrese\n\n"
                    elif model_type == "Random Forest":
                        r_code += "library(randomForest)\n\n"
                    else:  # SVM
                        r_code += "library(e1071)\n\n"
                else:
                    if model_type == "Line치rn칤 regrese":
                        r_code += "# Line치rn칤 regrese\n\n"
                    elif model_type == "Random Forest":
                        r_code += "library(randomForest)\n\n"
                    else:  # SVM
                        r_code += "library(e1071)\n\n"
                
                # P콏칤prava dat
                r_code += f"""
# P콏칤prava dat
feature_cols <- c({', '.join([f'"{col}"' for col in feature_cols])})
target_col <- "{target_col}"

# V칳b캩r dat
model_data <- data %>% 
  select(all_of(c(feature_cols, target_col))) %>%
  na.omit()  # Odstran캩n칤 콏치dk콢 s chyb캩j칤c칤mi hodnotami

# Rozd캩len칤 dat
set.seed(42)
train_idx <- createDataPartition(model_data[[target_col]], p = {1-test_size}, list = FALSE)
train_data <- model_data[train_idx, ]
test_data <- model_data[-train_idx, ]

# P콏칤prava formulace modelu
formula <- as.formula(paste(target_col, "~", paste(feature_cols, collapse = " + ")))
"""
                
                # Tr칠nov치n칤 modelu
                if is_classification:
                    if model_type == "Logistick치 regrese":
                        r_code += """
# Tr칠nov치n칤 logistick칠 regrese
model <- glm(formula, family = binomial(link = 'logit'), data = train_data)

# Predikce
train_prob <- predict(model, train_data, type = "response")
test_prob <- predict(model, test_data, type = "response")
train_pred <- ifelse(train_prob > 0.5, 1, 0)
test_pred <- ifelse(test_prob > 0.5, 1, 0)
"""
                    elif model_type == "Random Forest":
                        r_code += """
# Tr칠nov치n칤 Random Forest
model <- randomForest(formula, data = train_data)

# Predikce
train_pred <- predict(model, train_data)
test_pred <- predict(model, test_data)
"""
                    else:  # SVM
                        r_code += """
# Tr칠nov치n칤 SVM
model <- svm(formula, data = train_data, probability = TRUE)

# Predikce
train_pred <- predict(model, train_data)
test_pred <- predict(model, test_data)
"""
                else:
                    if model_type == "Line치rn칤 regrese":
                        r_code += """
# Tr칠nov치n칤 line치rn칤 regrese
model <- lm(formula, data = train_data)

# Predikce
train_pred <- predict(model, train_data)
test_pred <- predict(model, test_data)
"""
                    elif model_type == "Random Forest":
                        r_code += """
# Tr칠nov치n칤 Random Forest
model <- randomForest(formula, data = train_data)

# Predikce
train_pred <- predict(model, train_data)
test_pred <- predict(model, test_data)
"""
                    else:  # SVM
                        r_code += """
# Tr칠nov치n칤 SVM
model <- svm(formula, data = train_data)

# Predikce
train_pred <- predict(model, train_data)
test_pred <- predict(model, test_data)
"""
                
                # K칩d pro vyhodnocen칤
                if is_classification:
                    r_code += """
# Vyhodnocen칤 klasifikace
library(caret)
train_cm <- confusionMatrix(as.factor(train_pred), as.factor(train_data[[target_col]]))
test_cm <- confusionMatrix(as.factor(test_pred), as.factor(test_data[[target_col]]))

print("P콏esnost na tr칠novac칤ch datech:")
print(train_cm$overall['Accuracy'])
print("P콏esnost na testovac칤ch datech:")
print(test_cm$overall['Accuracy'])
print("Matice z치m캩n (test):")
print(test_cm$table)
"""
                else:
                    r_code += """
# Vyhodnocen칤 regrese
library(Metrics)
train_rmse <- rmse(train_data[[target_col]], train_pred)
test_rmse <- rmse(test_data[[target_col]], test_pred)
train_r2 <- cor(train_data[[target_col]], train_pred)^2
test_r2 <- cor(test_data[[target_col]], test_pred)^2

print(paste("RMSE na tr칠novac칤ch datech:", round(train_rmse, 4)))
print(paste("RMSE na testovac칤ch datech:", round(test_rmse, 4)))
print(paste("R na tr칠novac칤ch datech:", round(train_r2, 4)))
print(paste("R na testovac칤ch datech:", round(test_r2, 4)))
"""
                
                st.code(r_code, language="r")

def zobraz_casove_rady():
    st.header("Anal칳za 캜asov칳ch 콏ad")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # Kontrola, zda m치me sloupec s datem
    if len(eda.datetime_cols) == 0:
        st.warning("Pro anal칳zu 캜asov칳ch 콏ad je pot콏eba sloupec s datem.")
        
        # Nab칤dnout mo쬹ost konverze sloupce na datum
        st.subheader("Konverze sloupce na datum")
        
        col_to_convert = st.selectbox(
            "Vyberte sloupec pro konverzi na datum",
            data.columns
        )
        
        if st.button("Konvertovat na datum"):
            try:
                data[col_to_convert] = pd.to_datetime(data[col_to_convert])
                st.session_state.data = data
                # Aktualizace eda objektu s nov칳m typem sloupce
                st.session_state.eda = EDA(data)
                st.success(f"Sloupec {col_to_convert} byl 칰sp캩코n캩 konvertov치n na datum")
                st.rerun()
            except:
                st.error(f"Nelze konvertovat sloupec {col_to_convert} na datum")
        
        return
    
    # Nastaven칤 anal칳zy 캜asov칳ch 콏ad
    st.subheader("Nastaven칤 anal칳zy")
    
    # V칳b캩r datumov칠ho sloupce
    date_col = st.selectbox("Vyberte sloupec s datem", eda.datetime_cols)
    
    # V칳b캩r hodnoty, kterou chceme analyzovat
    if len(eda.numeric_cols) == 0:
        st.warning("Pro anal칳zu 캜asov칳ch 콏ad pot콏ebujete alespo켿 jeden numerick칳 sloupec")
        return
    
    value_col = st.selectbox("Vyberte hodnotu pro anal칳zu", eda.numeric_cols)
    
    # Nastaven칤 agregace
    agg_method = st.radio(
        "Metoda agregace",
        ["Suma", "Pr콢m캩r", "Medi치n", "Min", "Max"],
        horizontal=True
    )
    
    # Nastaven칤 periody
    time_period = st.radio(
        "캛asov치 perioda",
        ["Den", "T칳den", "M캩s칤c", "Kvart치l", "Rok"],
        horizontal=True
    )
    
    # Mapov치n칤 metody agregace na pandas funkce
    agg_map = {
        "Suma": "sum",
        "Pr콢m캩r": "mean",
        "Medi치n": "median",
        "Min": "min",
        "Max": "max"
    }
    
    # Mapov치n칤 캜asov칠 periody na pandas frekvence
    period_map = {
        "Den": "D",
        "T칳den": "W",
        "M캩s칤c": "M",
        "Kvart치l": "Q",
        "Rok": "Y"
    }
    
    # Tla캜칤tko pro spu코t캩n칤 anal칳zy
    run_analysis = st.button("Spustit anal칳zu 캜asov칳ch 콏ad")
    
    if run_analysis:
        with st.spinner("Prob칤h치 anal칳za..."):
            # P콏칤prava dat
            time_series_data = data[[date_col, value_col]].copy()
            time_series_data[date_col] = pd.to_datetime(time_series_data[date_col])
            time_series_data = time_series_data.dropna()
            
            if len(time_series_data) < 3:
                st.error("Nedostatek dat pro anal칳zu 캜asov칳ch 콏ad")
                return
            
            # Set콏칤d캩n칤 podle data
            time_series_data = time_series_data.sort_values(date_col)
            
            # Agregace dat podle zvolen칠 periody
            aggregated_data = time_series_data.set_index(date_col).resample(period_map[time_period])[value_col].agg(agg_map[agg_method])
            
            # Vytvo콏en칤 dataframe pro vizualizaci
            ts_df = aggregated_data.reset_index()
            ts_df.columns = ['Datum', 'Hodnota']
            
            # Zobrazen칤 v칳sledk콢
            st.subheader("Anal칳za 캜asov칳ch 콏ad")
            
            # 캛asov치 콏ada
            fig = px.line(
                ts_df,
                x='Datum',
                y='Hodnota',
                title=f"{value_col} podle {time_period.lower()}콢 ({agg_method.lower()})",
                markers=True
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # V칳po캜et zm캩n (mezim캩s칤캜n칤, meziro캜n칤)
            if len(ts_df) > 1:
                # P콏id치n칤 sloupce s procentu치ln칤 zm캩nou
                ts_df['Zm캩na (%)'] = ts_df['Hodnota'].pct_change() * 100
                
                # Vizualizace zm캩n
                fig = px.bar(
                    ts_df.dropna(),
                    x='Datum',
                    y='Zm캩na (%)',
                    title=f"Zm캩na {value_col} ({agg_method.lower()}) v %",
                    color='Zm캩na (%)',
                    color_continuous_scale=['red', 'white', 'green'],
                    range_color=[-max(abs(ts_df['Zm캩na (%)'].dropna())), max(abs(ts_df['Zm캩na (%)'].dropna()))]
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # Anal칳za sez칩nnosti, pokud m치me dostatek dat
            if len(ts_df) >= 12:  # Alespo켿 rok dat pro sez칩nnost
                from statsmodels.tsa.seasonal import seasonal_decompose
                
                try:
                    # P콏eveden칤 zp캩t na 캜asovou 콏adu
                    ts = ts_df.set_index('Datum')['Hodnota']
                    
                    # Dekompozice 캜asov칠 콏ady
                    result = seasonal_decompose(ts, model='additive')
                    
                    # Vizualizace dekompozice
                    trend = result.trend.reset_index()
                    trend.columns = ['Datum', 'Hodnota']
                    trend['Komponenta'] = 'Trend'
                    
                    seasonal = result.seasonal.reset_index()
                    seasonal.columns = ['Datum', 'Hodnota']
                    seasonal['Komponenta'] = 'Sez칩nnost'
                    
                    residual = result.resid.reset_index()
                    residual.columns = ['Datum', 'Hodnota']
                    residual['Komponenta'] = 'Reziduum'
                    
                    observed = ts.reset_index()
                    observed.columns = ['Datum', 'Hodnota']
                    observed['Komponenta'] = 'Pozorovan칠'
                    
                    decomp_df = pd.concat([observed, trend, seasonal, residual])
                    
                    st.subheader("Dekompozice 캜asov칠 콏ady")
                    
                    # Vizualizace dekompozice v samostatn칳ch grafech
                    for component in ['Pozorovan칠', 'Trend', 'Sez칩nnost', 'Reziduum']:
                        fig = px.line(
                            decomp_df[decomp_df['Komponenta'] == component],
                            x='Datum',
                            y='Hodnota',
                            title=f"Komponenta: {component}",
                            markers=True
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                    
                    # S칤la trendu a sez칩nnosti
                    trend_strength = 1 - np.var(result.resid) / np.var(result.observed - result.seasonal)
                    seasonal_strength = 1 - np.var(result.resid) / np.var(result.observed - result.trend)
                    
                    col1, col2 = st.columns(2)
                    col1.metric("S칤la trendu", f"{trend_strength:.4f}")
                    col2.metric("S칤la sez칩nnosti", f"{seasonal_strength:.4f}")
                    
                    # Interpretace
                    st.markdown("**Interpretace:**")
                    if trend_strength > 0.7:
                        st.markdown("- Data vykazuj칤 **siln칳 trend**")
                    elif trend_strength > 0.4:
                        st.markdown("- Data vykazuj칤 **st콏edn칤 trend**")
                    else:
                        st.markdown("- Data vykazuj칤 **slab칳 nebo 쮂멳n칳 trend**")
                        
                    if seasonal_strength > 0.6:
                        st.markdown("- Data vykazuj칤 **silnou sez칩nn칤 slo쬶u**")
                    elif seasonal_strength > 0.3:
                        st.markdown("- Data vykazuj칤 **st콏edn칤 sez칩nn칤 slo쬶u**")
                    else:
                        st.markdown("- Data vykazuj칤 **slabou nebo 쮂멳nou sez칩nn칤 slo쬶u**")
                    
                except Exception as e:
                    st.error(f"Chyba p콏i dekompozici 캜asov칠 콏ady: {str(e)}")
            
            # Zobrazen칤 tabulky s daty
            st.subheader("Agregovan치 data")
            st.dataframe(ts_df)
            
            # Mo쬹ost st치hnout data
            csv = ts_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="St치hnout jako CSV",
                data=csv,
                file_name=f'time_series_{value_col}_{time_period.lower()}.csv',
                mime='text/csv',
            )

def zobraz_cross_tabulky():
    st.header("Cross tabulky")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.categorical_cols) < 2:
        st.warning("Pro cross tabulky jsou pot콏eba alespo켿 2 kategorick칠 sloupce")
        return
    
    # Nastaven칤 cross tabulky
    st.subheader("Nastaven칤 cross tabulky")
    
    # V칳b캩r kategorick칳ch sloupc콢
    col1, col2 = st.columns(2)
    
    with col1:
        row_var = st.selectbox("Vyberte prom캩nnou pro 콏치dky", eda.categorical_cols, key="row_var")
    
    with col2:
        col_var = st.selectbox("Vyberte prom캩nnou pro sloupce", 
                             [col for col in eda.categorical_cols if col != row_var], 
                             key="col_var")
    
    # V칳b캩r typu cross tabulky
    cross_type = st.radio(
        "Typ cross tabulky",
        ["캛etnosti", "콎치dkov치 %", "Sloupcov치 %", "Celkov치 %"],
        horizontal=True
    )
    
    # Mapov치n칤 typu cross tabulky na normalize parametr pandas crosstab
    normalize_map = {
        "캛etnosti": None,
        "콎치dkov치 %": "index",
        "Sloupcov치 %": "columns",
        "Celkov치 %": "all"
    }
    
    # Tla캜칤tko pro vytvo콏en칤 cross tabulky
    create_cross = st.button("Vytvo콏it cross tabulku")
    
    if create_cross:
        try:
            # P콏칤prava dat
            cross_data = data[[row_var, col_var]].dropna()
            
            if len(cross_data) < 1:
                st.error("Nedostatek dat pro vytvo콏en칤 cross tabulky")
                return
            
            # Vytvo콏en칤 cross tabulky - opraven칠 pro normalizaci
            if cross_type == "캛etnosti":
                # Pro 캜etnosti nepou쮂셨at normalize parametr v콢bec
                cross_tab = pd.crosstab(
                    cross_data[row_var], 
                    cross_data[col_var],
                    margins=True,
                    margins_name="Celkem"
                )
            else:
                # Pro procentu치ln칤 tabulky pou쮂셦 spr치vn칳 normalize parametr
                cross_tab = pd.crosstab(
                    cross_data[row_var], 
                    cross_data[col_var],
                    normalize=normalize_map[cross_type],
                    margins=True,
                    margins_name="Celkem"
                )
            
            # P콏evod na procenta u procentu치ln칤ch tabulek
            if cross_type != "캛etnosti":
                cross_tab = cross_tab * 100
            
            # Vizualizace cross tabulky
            st.subheader(f"Cross tabulka: {row_var} vs {col_var} ({cross_type})")
            
            # Tabulka
            if cross_type == "캛etnosti":
                st.dataframe(cross_tab.style.format(precision=0))
            else:
                st.dataframe(cross_tab.style.format("{:.1f}%"))
            
            # Heatmapa - bezpe캜n칠 odstran캩n칤 Celkem s kontrolou existence
            try:
                # Vytvo콏en칤 kopie pro vizualizaci bez Celkem
                if 'Celkem' in cross_tab.index and 'Celkem' in cross_tab.columns:
                    cross_tab_viz = cross_tab.drop('Celkem', axis=0).drop('Celkem', axis=1)
                elif 'Celkem' in cross_tab.index:
                    cross_tab_viz = cross_tab.drop('Celkem', axis=0)
                elif 'Celkem' in cross_tab.columns:
                    cross_tab_viz = cross_tab.drop('Celkem', axis=1)
                else:
                    cross_tab_viz = cross_tab.copy()
                
                # Kontrola, zda m치me data pro vizualizaci
                if cross_tab_viz.empty:
                    st.warning("Nedostatek dat pro vizualizaci")
                    return
                
                fig = px.imshow(
                    cross_tab_viz,
                    labels=dict(x=col_var, y=row_var, color="Hodnota"),
                    title=f"Cross tabulka: {row_var} vs {col_var}",
                    color_continuous_scale='blues'
                )
                
                # P콏id치n칤 textov칳ch popisk콢 do bun캩k
                for i in range(len(cross_tab_viz.index)):
                    for j in range(len(cross_tab_viz.columns)):
                        value = cross_tab_viz.iloc[i, j]
                        text = f"{value:.1f}%" if cross_type != "캛etnosti" else f"{value:.0f}"
                        fig.add_annotation(
                            x=j,
                            y=i,
                            text=text,
                            showarrow=False,
                            font=dict(color="white" if value > cross_tab_viz.values.mean() else "black")
                        )
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Chyba p콏i vytv치콏en칤 heatmapy: {str(e)}")
            
            # Zobrazen칤 grafu - sloupcov칳
            try:
                if cross_type == "캛etnosti":
                    # P콏eveden칤 tabulky na long form치t pro Plotly
                    cross_tab_long = cross_tab.reset_index().melt(
                        id_vars=row_var,
                        value_vars=[col for col in cross_tab.columns if col != 'Celkem'],
                        var_name=col_var,
                        value_name='캛etnost'
                    )
                    
                    fig = px.bar(
                        cross_tab_long,
                        x=row_var,
                        y='캛etnost',
                        color=col_var,
                        title=f"Sloupcov칳 graf: {row_var} vs {col_var}",
                        barmode='group'
                    )
                else:
                    # Pro procentu치ln칤 tabulky
                    cross_tab_long = cross_tab.reset_index().melt(
                        id_vars=row_var,
                        value_vars=[col for col in cross_tab.columns if col != 'Celkem'],
                        var_name=col_var,
                        value_name='Procento'
                    )
                    
                    fig = px.bar(
                        cross_tab_long,
                        x=row_var,
                        y='Procento',
                        color=col_var,
                        title=f"Sloupcov칳 graf: {row_var} vs {col_var}",
                        barmode='group'
                    )
                    
                    fig.update_layout(yaxis_ticksuffix='%')
                
                st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Chyba p콏i vytv치콏en칤 sloupcov칠ho grafu: {str(e)}")
            
            # Chi-kvadr치t test (pouze pro tabulky 캜etnost칤)
            if cross_type == "캛etnosti":
                try:
                    # Bezpe캜n칠 odstran캩n칤 Celkem pro statistick칠 testy
                    chi2_tab = cross_tab.copy()
                    if 'Celkem' in chi2_tab.index:
                        chi2_tab = chi2_tab.drop('Celkem', axis=0)
                    if 'Celkem' in chi2_tab.columns:
                        chi2_tab = chi2_tab.drop('Celkem', axis=1)
                    
                    # Chi-kvadr치t test
                    from scipy.stats import chi2_contingency
                    
                    chi2, p, dof, expected = chi2_contingency(chi2_tab)
                    
                    st.subheader("Test z치vislosti (Chi-kvadr치t)")
                    
                    if (expected < 5).any().any():
                        st.warning("O캜ek치van칠 캜etnosti jsou v n캩kter칳ch bu켿k치ch men코칤 ne 5, co m콢쬰 ovlivnit v칳sledky testu")
                    
                    st.markdown(f"**Chi-kvadr치t statistika:** {chi2:.4f}")
                    st.markdown(f"**Stupn캩 volnosti:** {dof}")
                    st.markdown(f"**p-hodnota:** {p:.4f}")
                    
                    if p < 0.05:
                        st.markdown(f"**Z치v캩r:** Existuje statisticky v칳znamn치 souvislost mezi prom캩nn칳mi {row_var} a {col_var} (p < 0.05)")
                        
                        # Cramerovo V (s칤la asociace)
                        n = chi2_tab.values.sum()
                        min_dim = min(chi2_tab.shape) - 1
                        cramer_v = np.sqrt(chi2 / (n * min_dim))
                        
                        st.markdown(f"**S칤la asociace (Cramerovo V):** {cramer_v:.4f}")
                        
                        if cramer_v < 0.1:
                            st.markdown("Interpretace: Zanedbateln치 asociace")
                        elif cramer_v < 0.3:
                            st.markdown("Interpretace: Slab치 asociace")
                        elif cramer_v < 0.5:
                            st.markdown("Interpretace: St콏edn칤 asociace")
                        else:
                            st.markdown("Interpretace: Siln치 asociace")
                    else:
                        st.markdown(f"**Z치v캩r:** Neexistuje statisticky v칳znamn치 souvislost mezi prom캩nn칳mi {row_var} a {col_var} (p 곤 0.05)")
                except Exception as e:
                    st.error(f"Chyba p콏i prov치d캩n칤 Chi-kvadr치t testu: {str(e)}")
        
        except Exception as e:
            st.error(f"Chyba p콏i vytv치콏en칤 cross tabulky: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

def zobraz_kpi_dashboard():
    st.header("KPI Dashboard")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    # 칔vodn칤 informace
    st.markdown("""
    Tento dashboard umo쮄갓je vizualizovat kl칤캜ov칠 ukazatele v칳konnosti (KPI) z va코ich dat. 
    M콢쬰te definovat vlastn칤 metriky a sledovat je v p콏ehledn칠m dashboardu.
    """)
    
    # Nastaven칤 KPI
    st.subheader("Definice KPI")
    
    with st.expander("P콏idat nov칠 KPI", expanded=True):
        # V칳b캩r sloupce
        kpi_col = st.selectbox("Vyberte sloupec pro KPI", eda.numeric_cols)
        
        # V칳b캩r agrega캜n칤 funkce
        kpi_agg = st.selectbox(
            "Vyberte agrega캜n칤 funkci",
            ["Suma", "Pr콢m캩r", "Medi치n", "Min", "Max", "Po캜et"]
        )
        
        # N치zev KPI
        kpi_name = st.text_input("N치zev KPI", value=f"{kpi_agg} {kpi_col}")
        
        # Barva KPI
        kpi_color = st.selectbox(
            "Barva KPI",
            ["Fialov치", "콯lut치", "Oran쬺v치", "Zelen치"]
        )
        
        # Mapov치n칤 barvy na HTML k칩d
        color_map = {
            "Fialov치": OICT_COLORS['purple'],
            "콯lut치": OICT_COLORS['yellow'],
            "Oran쬺v치": OICT_COLORS['orange'],
            "Zelen치": OICT_COLORS['green']
        }
        
        # C칤lov치 hodnota
        target_value = st.number_input("C칤lov치 hodnota (nepovinn칠)", value=0.0)
        
        # P콏id치n칤 KPI do session_state
        if st.button("P콏idat KPI"):
            if 'kpis' not in st.session_state:
                st.session_state.kpis = []
            
            # V칳po캜et hodnoty KPI
            if kpi_agg == "Suma":
                kpi_value = data[kpi_col].sum()
            elif kpi_agg == "Pr콢m캩r":
                kpi_value = data[kpi_col].mean()
            elif kpi_agg == "Medi치n":
                kpi_value = data[kpi_col].median()
            elif kpi_agg == "Min":
                kpi_value = data[kpi_col].min()
            elif kpi_agg == "Max":
                kpi_value = data[kpi_col].max()
            elif kpi_agg == "Po캜et":
                kpi_value = data[kpi_col].count()
            
            # P콏id치n칤 KPI do seznamu
            st.session_state.kpis.append({
                'name': kpi_name,
                'column': kpi_col,
                'aggregation': kpi_agg,
                'value': kpi_value,
                'target': target_value,
                'color': color_map[kpi_color]
            })
            
            st.success(f"KPI '{kpi_name}' 칰sp캩코n캩 p콏id치no")
            st.rerun()
    
    # Zobrazen칤 KPI v dashboardu
    if 'kpis' in st.session_state and len(st.session_state.kpis) > 0:
        st.subheader("KPI Dashboard")
        
        # Rozd캩len칤 do 콏치dk콢 po 4 KPI
        kpi_per_row = 4
        kpis = st.session_state.kpis
        
        for i in range(0, len(kpis), kpi_per_row):
            cols = st.columns(min(kpi_per_row, len(kpis) - i))
            
            for j, col in enumerate(cols):
                if i + j < len(kpis):
                    kpi = kpis[i + j]
                    
                    # Form치tov치n칤 hodnoty
                    if isinstance(kpi['value'], (int, np.integer)):
                        value_text = f"{kpi['value']:,}"
                    else:
                        value_text = f"{kpi['value']:.2f}"
                    
                    # V칳po캜et procentu치ln칤ho rozd칤lu od c칤le
                    if kpi['target'] != 0:
                        diff_pct = (kpi['value'] - kpi['target']) / abs(kpi['target']) * 100
                        diff_text = f"{diff_pct:+.1f}%"
                    else:
                        diff_text = "N/A"
                    
                    col.markdown(f"""
                    <div style="background-color: white; border-radius: 10px; padding: 15px; text-align: center; border-top: 5px solid {kpi['color']}; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
                        <h3 style="margin-bottom: 5px; color: #333;">{kpi['name']}</h3>
                        <div style="font-size: 24px; font-weight: bold; margin: 10px 0; color: {kpi['color']};">{value_text}</div>
                        <div style="color: #666; font-size: 14px;">C칤l: {kpi['target']}</div>
                        <div style="color: {'green' if kpi['value'] >= kpi['target'] else 'red'}; font-size: 14px;">{diff_text}</div>
                    </div>
                    """, unsafe_allow_html=True)
        
        # Graf 
        if len(kpis) > 1:
            st.subheader("Srovn치n칤 KPI")
            
            # P콏칤prava dat pro graf
            kpi_df = pd.DataFrame([{
                'KPI': kpi['name'],
                'Hodnota': kpi['value'],
                'C칤l': kpi['target'],
                'Rozd칤l': kpi['value'] - kpi['target'],
                'Procento c칤le': (kpi['value'] / kpi['target'] * 100) if kpi['target'] != 0 else 0
            } for kpi in kpis])
            
            # Sloupcov칳 graf
            fig = px.bar(
                kpi_df,
                x='KPI',
                y='Hodnota',
                title="Hodnoty KPI",
                color='KPI',
                color_discrete_sequence=[kpi['color'] for kpi in kpis]
            )
            
            # P콏id치n칤 c칤lov칳ch hodnot jako horizont치ln칤 캜치ry
            for i, kpi in enumerate(kpis):
                if kpi['target'] != 0:
                    fig.add_shape(
                        type="line",
                        xref="x",
                        yref="y",
                        x0=i - 0.4,
                        x1=i + 0.4,
                        y0=kpi['target'],
                        y1=kpi['target'],
                        line=dict(color="red", width=2, dash="dash")
                    )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Procento pln캩n칤 c칤l콢
            if any(kpi['target'] != 0 for kpi in kpis):
                fig = px.bar(
                    kpi_df[kpi_df['C칤l'] != 0],
                    x='KPI',
                    y='Procento c칤le',
                    title="Procento pln캩n칤 c칤l콢",
                    color='KPI',
                    color_discrete_sequence=[kpi['color'] for kpi in kpis if kpi['target'] != 0]
                )
                
                # P콏id치n칤 referen캜n칤 캜치ry pro 100%
                fig.add_shape(
                    type="line",
                    x0=-0.5,
                    x1=len(kpis) - 0.5,
                    y0=100,
                    y1=100,
                    line=dict(color="black", width=2, dash="dash")
                )
                
                fig.update_layout(yaxis_ticksuffix='%')
                
                st.plotly_chart(fig, use_container_width=True)
        
        # Odstran캩n칤 KPI
        if st.button("Vymazat v코echny KPI"):
            st.session_state.kpis = []
            st.success("V코echny KPI byly odstran캩ny")
            st.rerun()
    else:
        st.info("Zat칤m nejsou definov치ny 쮂멳n칠 KPI. Pou쬴jte sekci 'P콏idat nov칠 KPI' pro vytvo콏en칤 dashboardu.")

def zobraz_kohortni_analyza():
    st.header("Kohortn칤 anal칳za")
    
    data = st.session_state.data
    eda = st.session_state.eda
    
    # Bezpe캜nostn칤 kontrola
    if data is None or eda is None:
        st.warning("콯치dn치 data nebyla nahr치na. Pros칤m, nejprve nahrajte data.")
        return
    
    if len(eda.datetime_cols) == 0:
        st.warning("Pro kohortn칤 anal칳zu je pot콏eba alespo켿 jeden sloupec s datem.")
        return
    
    # Nastaven칤 kohortn칤 anal칳zy
    st.subheader("Nastaven칤 kohortn칤 anal칳zy")
    
    # V칳b캩r datumov칠ho sloupce pro kohortn칤 definici
    cohort_date_col = st.selectbox(
        "Vyberte sloupec s datem pro definici kohorty (nap콏. datum registrace)",
        eda.datetime_cols,
        key="cohort_date_col"
    )
    
    # V칳b캩r datumov칠ho sloupce pro ud치lost
    event_date_col = st.selectbox(
        "Vyberte sloupec s datem ud치losti",
        [col for col in eda.datetime_cols if col != cohort_date_col],
        key="event_date_col"
    )
    
    # V칳b캩r ID sloupce
    id_options = ["Vyberte ID sloupec"] + list(data.columns)
    id_col = st.selectbox("Vyberte sloupec s unik치tn칤m ID u쬴vatele/z치kazn칤ka", id_options)
    
    if id_col == "Vyberte ID sloupec":
        st.warning("Pro kohortn칤 anal칳zu je pot콏eba sloupec s ID u쬴vatele/z치kazn칤ka")
        return
    
    # V칳b캩r hodnoty pro kohortn칤 anal칳zu
    value_options = ["Po캜et unik치tn칤ch ID"] + eda.numeric_cols
    value_col = st.selectbox("Vyberte hodnotu pro anal칳zu", value_options)
    
    # 캛asov치 perioda pro skupiny kohort
    cohort_period = st.radio(
        "캛asov치 perioda pro kohortn칤 skupiny",
        ["Denn칤", "T칳denn칤", "M캩s칤캜n칤", "Kvart치ln칤"],
        horizontal=True,
        index=2  # V칳choz칤 je m캩s칤캜n칤
    )
    
    # 캛asov치 perioda pro zobrazen칤 retence
    retention_period = st.radio(
        "캛asov치 perioda pro zobrazen칤 retence",
        ["Denn칤", "T칳denn칤", "M캩s칤캜n칤", "Kvart치ln칤"],
        horizontal=True,
        index=2  # V칳choz칤 je m캩s칤캜n칤
    )
    
    # Tla캜칤tko pro spu코t캩n칤 anal칳zy
    run_cohort = st.button("Spustit kohortn칤 anal칳zu")
    
    if run_cohort:
        with st.spinner("Prob칤h치 kohortn칤 anal칳za..."):
            try:
                # Kopie dat a p콏evod datum콢
                cohort_data = data[[id_col, cohort_date_col, event_date_col]].copy()
                
                if value_col != "Po캜et unik치tn칤ch ID":
                    cohort_data[value_col] = data[value_col]
                
                # P콏evod na datetime
                cohort_data[cohort_date_col] = pd.to_datetime(cohort_data[cohort_date_col])
                cohort_data[event_date_col] = pd.to_datetime(cohort_data[event_date_col])
                
                # Odstran캩n칤 chyb캩j칤c칤ch hodnot
                cohort_data = cohort_data.dropna(subset=[id_col, cohort_date_col, event_date_col])
                
                # Mapov치n칤 period na pandas frekvence
                period_map = {
                    "Denn칤": "D",
                    "T칳denn칤": "W",
                    "M캩s칤캜n칤": "M",
                    "Kvart치ln칤": "Q"
                }
                
                # Vytvo콏en칤 kohortn칤 periody pro prvn칤 ud치lost
                if cohort_period == "Denn칤":
                    cohort_data['Cohort'] = cohort_data[cohort_date_col].dt.date
                elif cohort_period == "T칳denn칤":
                    cohort_data['Cohort'] = cohort_data[cohort_date_col].dt.to_period('W').dt.start_time.dt.date
                elif cohort_period == "M캩s칤캜n칤":
                    cohort_data['Cohort'] = cohort_data[cohort_date_col].dt.to_period('M').dt.start_time.dt.date
                elif cohort_period == "Kvart치ln칤":
                    cohort_data['Cohort'] = cohort_data[cohort_date_col].dt.to_period('Q').dt.start_time.dt.date
                
                # V칳po캜et obdob칤 mezi datem kohorty a datem ud치losti
                if retention_period == "Denn칤":
                    cohort_data['Period'] = ((cohort_data[event_date_col] - cohort_data[cohort_date_col]).dt.days).astype(int)
                elif retention_period == "T칳denn칤":
                    cohort_data['Period'] = ((cohort_data[event_date_col] - cohort_data[cohort_date_col]).dt.days // 7).astype(int)
                elif retention_period == "M캩s칤캜n칤":
                    cohort_data['Period'] = ((cohort_data[event_date_col].dt.year - cohort_data[cohort_date_col].dt.year) * 12 +
                                           (cohort_data[event_date_col].dt.month - cohort_data[cohort_date_col].dt.month)).astype(int)
                elif retention_period == "Kvart치ln칤":
                    cohort_data['Period'] = ((cohort_data[event_date_col].dt.year - cohort_data[cohort_date_col].dt.year) * 4 +
                                           (cohort_data[event_date_col].dt.quarter - cohort_data[cohort_date_col].dt.quarter)).astype(int)
                
                # Filtrace period v캩t코칤ch nebo rovn칳ch 0 (ud치lost nem콢쬰 nastat p콏ed prvn칤m datem)
                cohort_data = cohort_data[cohort_data['Period'] >= 0]
                
                # Vytvo콏en칤 tabulky kohort
                if value_col == "Po캜et unik치tn칤ch ID":
                    # Kohortn칤 tabulka bude po캜칤tat unik치tn칤 ID
                    cohort_counts = cohort_data.groupby(['Cohort', 'Period'])[id_col].nunique().reset_index()
                    cohort_counts.columns = ['Cohort', 'Period', 'Count']
                else:
                    # Kohortn칤 tabulka bude agregovat hodnotu
                    cohort_counts = cohort_data.groupby(['Cohort', 'Period'])[value_col].sum().reset_index()
                    cohort_counts.columns = ['Cohort', 'Period', 'Count']
                
                # Vytvo콏en칤 pivotn칤 tabulky
                cohort_pivot = cohort_counts.pivot_table(index='Cohort', columns='Period', values='Count')
                
                # V칳po캜et kohortn칤ch velikost칤 (po캜et v prvn칤m obdob칤)
                cohort_sizes = cohort_pivot[0].copy()
                
                # V칳po캜et retence jako procenta p콢vodn칤 kohorty
                retention_pivot = cohort_pivot.divide(cohort_sizes, axis=0) * 100
                
                # Zobrazen칤 v칳sledk콢
                st.subheader("V칳sledky kohortn칤 anal칳zy")
                
                # Heatmapa retence
                fig = px.imshow(
                    retention_pivot,
                    labels=dict(x="Obdob칤", y="Kohorta", color="Retence (%)"),
                    color_continuous_scale='blues',
                    title=f"Retence podle kohorty (v %)"
                )
                
                # P콏id치n칤 hodnot do bun캩k
                for i in range(len(retention_pivot.index)):
                    for j in range(len(retention_pivot.columns)):
                        if not pd.isna(retention_pivot.iloc[i, j]):
                            fig.add_annotation(
                                x=j,
                                y=i,
                                text=f"{retention_pivot.iloc[i, j]:.1f}%",
                                showarrow=False,
                                font=dict(color="white" if retention_pivot.iloc[i, j] > 50 else "black")
                            )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Graf pr콢m캩rn칠 retence podle obdob칤
                avg_retention = retention_pivot.mean(axis=0)
                
                fig = px.line(
                    x=avg_retention.index,
                    y=avg_retention.values,
                    markers=True,
                    labels={'x': 'Obdob칤', 'y': 'Pr콢m캩rn치 retence (%)'},
                    title="Pr콢m캩rn치 retence podle obdob칤"
                )
                
                fig.update_layout(yaxis_ticksuffix='%')
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Tabulka s velikostmi kohort
                st.subheader("Velikosti kohort")
                
                cohort_sizes_df = pd.DataFrame({
                    'Kohorta': cohort_sizes.index,
                    'Po캜et': cohort_sizes.values
                })
                
                fig = px.bar(
                    cohort_sizes_df,
                    x='Kohorta',
                    y='Po캜et',
                    title="Velikosti kohort",
                    color_discrete_sequence=[OICT_COLORS['purple']]
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Tabulky s daty
                st.subheader("Tabulka retence (%)")
                st.dataframe(retention_pivot.style.format("{:.1f}%"))
                
                st.subheader("Tabulka absolutn칤ch hodnot")
                st.dataframe(cohort_pivot.style.format("{:.0f}"))
                
                # Mo쬹ost st치hnout data
                csv = retention_pivot.reset_index().to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="St치hnout tabulku retence jako CSV",
                    data=csv,
                    file_name=f'cohort_retention.csv',
                    mime='text/csv',
                )
                
            except Exception as e:
                st.error(f"Chyba p콏i kohortn칤 anal칳ze: {str(e)}")
                import traceback
                st.error(traceback.format_exc())

def vytvor_html_report(data, eda):
    """
    Vytvo콏칤 HTML report s v칳sledky anal칳zy
    """
    import datetime
    
    html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>EDA Report</title>
        <style>
            body {{
                font-family: Arial, sans-serif;
                margin: 30px;
                line-height: 1.6;
                color: #333;
            }}
            .header {{
                text-align: center;
                margin-bottom: 30px;
                border-bottom: 2px solid #574494;
                padding-bottom: 10px;
            }}
            .logo {{
                background-color: #574494;
                color: white;
                padding: 5px 15px;
                border-radius: 4px;
                font-weight: bold;
                font-size: 24px;
                display: inline-block;
                margin-bottom: 10px;
            }}
            h1, h2, h3 {{
                color: #574494;
            }}
            table {{
                border-collapse: collapse;
                width: 100%;
                margin-bottom: 20px;
            }}
            th, td {{
                border: 1px solid #ddd;
                padding: 8px;
                text-align: left;
            }}
            th {{
                background-color: #f2f2f2;
                font-weight: bold;
            }}
            .section {{
                margin-bottom: 30px;
                border-bottom: 1px solid #eee;
                padding-bottom: 20px;
            }}
            .insights {{
                background-color: #f8f8f8;
                padding: 15px;
                border-radius: 5px;
                margin-bottom: 20px;
            }}
            .footer {{
                margin-top: 50px;
                text-align: center;
                color: #666;
                font-size: 14px;
                border-top: 1px solid #eee;
                padding-top: 20px;
            }}
        </style>
    </head>
    <body>
        <div class="header">
            <div class="logo">oict.</div>
            <h1>Report pr콢zkumn칠 anal칳zy dat</h1>
            <p>Vygenerov치no: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M")}</p>
        </div>
        
        <div class="section">
            <h2>P콏ehled datasetu</h2>
            <p>Tento dataset obsahuje {data.shape[0]} 콏치dk콢 a {data.shape[1]} sloupc콢.</p>
            <p>Typy sloupc콢:</p>
            <ul>
                <li>Numerick칠 sloupce: {len(eda.numeric_cols)}</li>
                <li>Kategorick칠 sloupce: {len(eda.categorical_cols)}</li>
                <li>Datum/캜as sloupce: {len(eda.datetime_cols)}</li>
            </ul>
            
            <h3>Uk치zka dat</h3>
            {data.head().to_html()}
        </div>
        
        <div class="section">
            <h2>Kl칤캜ov칠 poznatky</h2>
            <div class="insights">
                <ul>
    """
    
    # P콏id치n칤 poznatk콢
    for insight in eda.generate_insights():
        html += f"<li>{insight}</li>\n"
    
    html += """
                </ul>
            </div>
        </div>
    """
    
    # Sekce chyb캩j칤c칤ch hodnot
    if hasattr(eda, 'missing_analysis'):
        missing_cols = eda.missing_analysis[eda.missing_analysis['Missing Values'] > 0]
        html += f"""
        <div class="section">
            <h2>Anal칳za chyb캩j칤c칤ch hodnot</h2>
            <p>Celkov칠 chyb캩j칤c칤 hodnoty: {eda.data.isnull().sum().sum()} z {eda.rows * eda.cols} bun캩k ({(eda.data.isnull().sum().sum() / (eda.rows * eda.cols) * 100):.2f}%)</p>
        """
        
        if len(missing_cols) > 0:
            html += f"""
            <h3>Sloupce s chyb캩j칤c칤mi hodnotami ({len(missing_cols)})</h3>
            {missing_cols.to_html()}
            """
        else:
            html += "<p>Nebyly zji코t캩ny 쮂멳n칠 chyb캩j칤c칤 hodnoty.</p>"
        
        html += "</div>"
    
    # Sekce korelac칤
    if hasattr(eda, 'correlation_matrix'):
        html += f"""
        <div class="section">
            <h2>Anal칳za korelac칤</h2>
        """
        
        if hasattr(eda, 'high_correlations') and len(eda.high_correlations) > 0:
            html += f"""
            <h3>Vysok칠 korelace (|r| 곤 0.7)</h3>
            {eda.high_correlations.to_html()}
            """
        else:
            html += "<p>Nebyly zji코t캩ny 쮂멳n칠 vysok칠 korelace.</p>"
        
        html += "</div>"
    
    # Sekce odlehl칳ch hodnot
    if hasattr(eda, 'outlier_summary') and len(eda.outlier_summary) > 0:
        html += f"""
        <div class="section">
            <h2>Anal칳za odlehl칳ch hodnot</h2>
            <h3>Sloupce s odlehl칳mi hodnotami</h3>
            <table>
                <tr>
                    <th>Sloupec</th>
                    <th>Po캜et odlehl칳ch hodnot</th>
                    <th>Procento</th>
                </tr>
        """
        
        for col, info in eda.outlier_summary.items():
            html += f"""
            <tr>
                <td>{col}</td>
                <td>{info['count']}</td>
                <td>{info['percent']:.2f}%</td>
            </tr>
            """
        
        html += """
            </table>
        </div>
        """
    
    # Pati캜ka
    html += """
        <div class="footer">
            <p>Powered by OICT</p>
            <p>춸 2023 Vytvo콏eno s 仇벒잺</p>
        </div>
    </body>
    </html>
    """
    
    return html

if __name__ == "__main__":
    main()